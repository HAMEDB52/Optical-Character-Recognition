{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# load datset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def extract_and_verify_dataset(tar_path=\"/content/IIIT5K-Word_V3.0.tar\"):\n",
        "    \"\"\"Extract the IIIT5K dataset and verify its structure\"\"\"\n",
        "    # Create output directory\n",
        "    output_dir = \"iiit5k_dataset\"\n",
        "    if os.path.exists(output_dir):\n",
        "        print(f\"Removing existing directory: {output_dir}\")\n",
        "        shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "    # Extract the tar file\n",
        "    print(f\"Extracting {tar_path} to {output_dir}...\")\n",
        "    try:\n",
        "        with tarfile.open(tar_path, \"r\") as tar:\n",
        "            tar.extractall(output_dir)\n",
        "        print(\"Extraction completed successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting file: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Function to print directory structure\n",
        "    def print_directory_structure(path, prefix=\"\"):\n",
        "        if not os.path.exists(path):\n",
        "            return\n",
        "\n",
        "        items = os.listdir(path)\n",
        "        items.sort()\n",
        "\n",
        "        for i, item in enumerate(items):\n",
        "            is_last = i == len(items) - 1\n",
        "            item_path = os.path.join(path, item)\n",
        "\n",
        "            # Print item\n",
        "            print(f\"{prefix}{'└── ' if is_last else '├── '}{item}\")\n",
        "\n",
        "            # If it's a directory, recurse\n",
        "            if os.path.isdir(item_path):\n",
        "                new_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
        "                print_directory_structure(item_path, new_prefix)\n",
        "\n",
        "    # Print the directory structure\n",
        "    print(\"\\nDataset directory structure:\")\n",
        "    print(\"=\"*50)\n",
        "    print_directory_structure(output_dir)\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Verify critical components\n",
        "    print(\"\\nVerifying critical dataset components:\")\n",
        "\n",
        "    # Look for train/test directories\n",
        "    train_dir = None\n",
        "    test_dir = None\n",
        "    gt_file = None\n",
        "\n",
        "    # Search for train directory (could be named various ways)\n",
        "    for root, dirs, files in os.walk(output_dir):\n",
        "        for dir_name in dirs:\n",
        "            if \"train\" in dir_name.lower() and not any(x in dir_name.lower() for x in [\"test\", \"val\"]):\n",
        "                train_dir = os.path.join(root, dir_name)\n",
        "                print(f\"✓ Found train directory: {train_dir}\")\n",
        "\n",
        "        for dir_name in dirs:\n",
        "            if \"test\" in dir_name.lower() and not any(x in dir_name.lower() for x in [\"train\", \"val\"]):\n",
        "                test_dir = os.path.join(root, dir_name)\n",
        "                print(f\"✓ Found test directory: {test_dir}\")\n",
        "\n",
        "        for file in files:\n",
        "            if \"gt\" in file.lower() and file.endswith((\".mat\", \".txt\")):\n",
        "                gt_file = os.path.join(root, file)\n",
        "                print(f\"✓ Found ground truth file: {gt_file}\")\n",
        "\n",
        "    # Check for image files\n",
        "    train_images = 0\n",
        "    test_images = 0\n",
        "\n",
        "    if train_dir and os.path.exists(train_dir):\n",
        "        train_images = len([f for f in os.listdir(train_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        print(f\"✓ Found {train_images} training images\")\n",
        "\n",
        "    if test_dir and os.path.exists(test_dir):\n",
        "        test_images = len([f for f in os.listdir(test_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        print(f\"✓ Found {test_images} test images\")\n",
        "\n",
        "    # Create a verification report\n",
        "    report = {\n",
        "        \"base_dir\": output_dir,\n",
        "        \"train_dir\": train_dir,\n",
        "        \"test_dir\": test_dir,\n",
        "        \"gt_file\": gt_file,\n",
        "        \"train_count\": train_images,\n",
        "        \"test_count\": test_images\n",
        "    }\n",
        "\n",
        "    print(\"\\nDataset verification report:\")\n",
        "    print(\"=\"*50)\n",
        "    for key, value in report.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    return report\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*50)\n",
        "    print(\"IIIT5K DATASET EXTRACTION AND VERIFICATION\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Check if the tar file exists\n",
        "    tar_file = \"IIIT5K-Word_V3.0.tar\"\n",
        "    if not os.path.exists(tar_file):\n",
        "        print(f\"\\nERROR: '{tar_file}' not found in current directory!\")\n",
        "        print(\"Please place the IIIT5K-Word_V3.0.tar file in this directory and run again.\")\n",
        "        print(\"Current directory contents:\")\n",
        "        for item in os.listdir(\".\"):\n",
        "            print(f\"- {item}\")\n",
        "        exit(1)\n",
        "\n",
        "    # Extract and verify\n",
        "    report = extract_and_verify_dataset(tar_file)\n",
        "\n",
        "    if report:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"NEXT STEPS FOR OCR TRAINING CODE\")\n",
        "        print(\"=\"*50)\n",
        "        print(\"To use this dataset in the OCR training code, update the dataset paths as follows:\")\n",
        "\n",
        "        # Generate code snippet for dataset configuration\n",
        "        print(\"\\nIn your OCR training code, use these paths:\")\n",
        "        print(\"```python\")\n",
        "        print(f\"# Dataset root directory\")\n",
        "        print(f\"DATASET_ROOT = r'{os.path.abspath(report['base_dir'])}'\")\n",
        "\n",
        "        if report['train_dir']:\n",
        "            print(f\"TRAIN_DIR = r'{os.path.abspath(report['train_dir'])}'\")\n",
        "        if report['test_dir']:\n",
        "            print(f\"TEST_DIR = r'{os.path.abspath(report['test_dir'])}'\")\n",
        "        if report['gt_file']:\n",
        "            print(f\"GT_FILE = r'{os.path.abspath(report['gt_file'])}'\")\n",
        "\n",
        "        print(\"```\")\n",
        "        print(\"\\nThis information will help configure the dataset loader correctly.\")\n",
        "        print(\"Based on common IIIT5K structure, here's how to implement the dataset loader:\")\n",
        "\n",
        "        # Provide specific dataset loader implementation\n",
        "        print(\"\\n```python\")\n",
        "        print(\"class IIIT5KDataset(Dataset):\")\n",
        "        print(\"    def __init__(self, root_dir, split='train', img_height=32, img_width=100):\")\n",
        "        print(\"        self.root_dir = root_dir\")\n",
        "        print(\"        self.img_height = img_height\")\n",
        "        print(\"        self.img_width = img_width\")\n",
        "        print(\"        \")\n",
        "        print(\"        # Load ground truth\")\n",
        "        print(\"        gt_path = os.path.join(root_dir, 'gt.mat')  # Or the actual path from above\")\n",
        "        print(\"        # In practice, you'd use scipy.io.loadmat for .mat files\")\n",
        "        print(\"        # For demonstration, we'll assume a text-based GT\")\n",
        "        print(\"        \")\n",
        "        print(\"        self.samples = []\")\n",
        "        print(\"        data_dir = os.path.join(root_dir, 'train' if split == 'train' else 'test')\")\n",
        "        print(\"        gt_file = os.path.join(root_dir, f'gt_{split}.txt')\")\n",
        "        print(\"        \")\n",
        "        print(\"        # Parse ground truth file\")\n",
        "        print(\"        with open(gt_file, 'r') as f:\")\n",
        "        print(\"            for line in f:\")\n",
        "        print(\"                parts = line.strip().split(' ')\")\n",
        "        print(\"                img_name = parts[0]\")\n",
        "        print(\"                text = ' '.join(parts[1:])\")\n",
        "        print(\"                self.samples.append((os.path.join(data_dir, img_name), text))\")\n",
        "        print(\"        \")\n",
        "        print(\"        # Character set for English OCR\")\n",
        "        print(\"        self.char_set = string.ascii_uppercase + string.digits + ' '\")\n",
        "        print(\"        self.char_to_idx = {char: idx for idx, char in enumerate(self.char_set)}\")\n",
        "        print(\"        self.idx_to_char = {idx: char for idx, char in enumerate(self.char_set)}\")\n",
        "        print(\"        \")\n",
        "        print(\"        # Transformations\")\n",
        "        print(\"        self.transform = T.Compose([\")\n",
        "        print(\"            T.Resize((img_height, img_width)),\")\n",
        "        print(\"            T.Grayscale(),\")\n",
        "        print(\"            T.ToTensor(),\")\n",
        "        print(\"        ])\")\n",
        "        print(\"    \")\n",
        "        print(\"    def __len__(self):\")\n",
        "        print(\"        return len(self.samples)\")\n",
        "        print(\"    \")\n",
        "        print(\"    def __getitem__(self, idx):\")\n",
        "        print(\"        img_path, text = self.samples[idx]\")\n",
        "        print(\"        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\")\n",
        "        print(\"        \")\n",
        "        print(\"        # Convert text to indices\")\n",
        "        print(\"        text_indices = [self.char_to_idx.get(c.upper(), 0) for c in text if c.upper() in self.char_set]\")\n",
        "        print(\"        \")\n",
        "        print(\"        # Convert to tensor\")\n",
        "        print(\"        img_tensor = self.transform(Image.fromarray(img))\")\n",
        "        print(\"        text_tensor = torch.tensor(text_indices, dtype=torch.long)\")\n",
        "        print(\"        \")\n",
        "        print(\"        return img_tensor, text_tensor, len(text_indices)\")\n",
        "        print(\"```\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_B4jejSrgui",
        "outputId": "95a8b512-5557-4ff9-a2af-6b57b31de33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "IIIT5K DATASET EXTRACTION AND VERIFICATION\n",
            "==================================================\n",
            "\n",
            "ERROR: 'IIIT5K-Word_V3.0.tar' not found in current directory!\n",
            "Please place the IIIT5K-Word_V3.0.tar file in this directory and run again.\n",
            "Current directory contents:\n",
            "- .config\n",
            "- sample_data\n",
            "Extracting IIIT5K-Word_V3.0.tar to iiit5k_dataset...\n",
            "Error extracting file: [Errno 2] No such file or directory: 'IIIT5K-Word_V3.0.tar'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deep_ocr_custom_split.py\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "import scipy.io\n",
        "import random\n",
        "\n",
        "# ======================\n",
        "# 1. MODIFIED DATASET CLASS WITH CUSTOM SPLIT\n",
        "# ======================\n",
        "class CustomSplitIIIT5KDataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', img_height=32, img_width=128,\n",
        "                 train_samples=4500, test_samples=500, random_seed=42):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.iiit5k_dir = os.path.join(root_dir, \"IIIT5K\")\n",
        "\n",
        "        # Set random seed for reproducible splits\n",
        "        random.seed(random_seed)\n",
        "        np.random.seed(random_seed)\n",
        "\n",
        "        # ✅ STEP 1: Define vocabulary FIRST (critical fix!)\n",
        "        self.chars = string.ascii_letters + string.digits + \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
        "        self.char_to_idx = {char: idx + 1 for idx, char in enumerate(self.chars)}\n",
        "        self.idx_to_char = {idx + 1: char for idx, char in enumerate(self.chars)}\n",
        "        self.idx_to_char[0] = '<BLANK>'\n",
        "        self.num_classes = len(self.chars) + 1  # 95 + 1\n",
        "\n",
        "        print(f\"Creating custom dataset split with {train_samples} train, {test_samples} test samples...\")\n",
        "\n",
        "        # Load all data from both original train and test sets\n",
        "        all_samples = []\n",
        "\n",
        "        # Load original train data\n",
        "        train_mat_file = os.path.join(self.iiit5k_dir, \"traindata.mat\")\n",
        "        train_data_dir = os.path.join(self.iiit5k_dir, \"train\")\n",
        "        if os.path.exists(train_mat_file):\n",
        "            all_samples.extend(self._load_mat_data(train_mat_file, train_data_dir, \"train\"))\n",
        "\n",
        "        # Load original test data\n",
        "        test_mat_file = os.path.join(self.iiit5k_dir, \"testdata.mat\")\n",
        "        test_data_dir = os.path.join(self.iiit5k_dir, \"test\")\n",
        "        if os.path.exists(test_mat_file):\n",
        "            all_samples.extend(self._load_mat_data(test_mat_file, test_data_dir, \"test\"))\n",
        "\n",
        "        print(f\"Total samples loaded: {len(all_samples)}\")\n",
        "\n",
        "        # Shuffle all samples for random split\n",
        "        random.shuffle(all_samples)\n",
        "\n",
        "        # Create custom train/test split\n",
        "        total_needed = train_samples + test_samples\n",
        "        if len(all_samples) < total_needed:\n",
        "            print(f\"⚠️ Warning: Only {len(all_samples)} samples available, but {total_needed} requested\")\n",
        "            train_samples = min(train_samples, len(all_samples) - test_samples)\n",
        "            test_samples = len(all_samples) - train_samples\n",
        "\n",
        "        if split == 'train':\n",
        "            self.samples = all_samples[:train_samples]\n",
        "            print(f\"✅ Created training set with {len(self.samples)} samples\")\n",
        "        else:  # test\n",
        "            self.samples = all_samples[train_samples:train_samples + test_samples]\n",
        "            print(f\"✅ Created test set with {len(self.samples)} samples\")\n",
        "\n",
        "        if self.samples:\n",
        "            sample_texts = [t for _, t in self.samples[:10]]\n",
        "            lengths = [len(t) for _, t in self.samples]\n",
        "            print(f\"Sample texts: {sample_texts}\")\n",
        "            print(f\"Text lengths: min={min(lengths)}, max={max(lengths)}, avg={np.mean(lengths):.1f}\")\n",
        "            print(f\"Vocabulary size: {self.num_classes}\")\n",
        "\n",
        "        # Image transform\n",
        "        self.transform = T.Compose([\n",
        "            T.ToPILImage(),\n",
        "            T.Resize((img_height, img_width), antialias=True),\n",
        "            T.Grayscale(),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize((0.5,), (0.5,))  # [-1, 1]\n",
        "        ])\n",
        "\n",
        "    def _load_mat_data(self, mat_file, data_dir, original_split):\n",
        "        \"\"\"Load data from .mat file and return list of (img_path, text) tuples\"\"\"\n",
        "        samples = []\n",
        "\n",
        "        try:\n",
        "            mat_data = scipy.io.loadmat(mat_file)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load {mat_file}: {e}\")\n",
        "            return samples\n",
        "\n",
        "        data_key = f\"{original_split}data\"\n",
        "        if data_key not in mat_data:\n",
        "            available = [k for k in mat_data.keys() if not k.startswith('__')]\n",
        "            print(f\"❌ Key '{data_key}' not found in {mat_file}. Available: {available}\")\n",
        "            return samples\n",
        "\n",
        "        data = mat_data[data_key]\n",
        "        N = data.shape[1] if data.shape[0] == 1 else data.shape[0]\n",
        "        print(f\"Processing {N} samples from {original_split} data...\")\n",
        "\n",
        "        for i in range(N):\n",
        "            try:\n",
        "                sample = data[0, i] if data.shape[0] == 1 else data[i, 0]\n",
        "\n",
        "                # Extract image path\n",
        "                img_name = self._safe_extract_string(sample[0])\n",
        "                if not img_name:\n",
        "                    img_filename = f\"sample_{i}.png\"\n",
        "                else:\n",
        "                    img_filename = os.path.basename(img_name.strip())\n",
        "                img_path = os.path.join(data_dir, img_filename)\n",
        "\n",
        "                # Extract text\n",
        "                text = self._safe_extract_string(sample[3])\n",
        "                text = self._clean_text(text)\n",
        "\n",
        "                if os.path.exists(img_path) and 1 <= len(text) <= 23:\n",
        "                    samples.append((img_path, text))\n",
        "\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def _safe_extract_string(self, data):\n",
        "        \"\"\"Robustly extract string from .mat field (handles str, numeric array, object array)\"\"\"\n",
        "        try:\n",
        "            if isinstance(data, str):\n",
        "                return data.strip()\n",
        "\n",
        "            if isinstance(data, np.ndarray):\n",
        "                # Case 1: Numeric array (ASCII codes)\n",
        "                if np.issubdtype(data.dtype, np.number):\n",
        "                    chars = []\n",
        "                    for c in data.flatten():\n",
        "                        try:\n",
        "                            c_int = int(c)\n",
        "                            if 32 <= c_int <= 126:  # Printable ASCII\n",
        "                                chars.append(chr(c_int))\n",
        "                        except (ValueError, TypeError):\n",
        "                            continue\n",
        "                    return ''.join(chars).strip()\n",
        "\n",
        "                # Case 2: String array (U/S dtype)\n",
        "                elif data.dtype.kind in ['U', 'S']:\n",
        "                    return str(data.flatten()[0]).strip() if data.size > 0 else \"\"\n",
        "\n",
        "                # Case 3: Object array (common in scipy.io.loadmat)\n",
        "                elif data.dtype == np.object_:\n",
        "                    item = data.item() if data.size == 1 else data[0]\n",
        "                    if isinstance(item, str):\n",
        "                        return item.strip()\n",
        "                    return self._safe_extract_string(item)\n",
        "\n",
        "            return str(data).strip()\n",
        "        except Exception as e:\n",
        "            return \"\"\n",
        "\n",
        "    def _clean_text(self, text):\n",
        "        \"\"\"Keep only valid characters in full ASCII set\"\"\"\n",
        "        return ''.join(c for c in text if c in self.chars).strip()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, text = self.samples[idx]\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            print(f\"⚠️ Warning: Failed to load image {img_path}, using blank\")\n",
        "            img = np.ones((self.img_height, self.img_width), dtype=np.uint8) * 255\n",
        "\n",
        "        text_indices = [self.char_to_idx[char] for char in text if char in self.char_to_idx]\n",
        "        img_tensor = self.transform(img)\n",
        "        return img_tensor, text_indices, text\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 2. DEEP CRNN MODEL (UNCHANGED)\n",
        "# ======================\n",
        "class DeepCRNN(nn.Module):\n",
        "    def __init__(self, img_height=32, num_classes=96, hidden_size=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d((2, 1), (2, 1)),\n",
        "            nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(), nn.MaxPool2d((2, 1), (2, 1)),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(), nn.MaxPool2d((2, 1), (2, 1)),\n",
        "        )\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=512,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=2,\n",
        "            bidirectional=True,\n",
        "            batch_first=False,\n",
        "            dropout=0.3\n",
        "        )\n",
        "        self.classifier = nn.Linear(hidden_size * 2, num_classes)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv = self.cnn(x)  # [B, 512, 1, W]\n",
        "        b, c, h, w = conv.size()\n",
        "        conv = conv.view(b, c * h, w).permute(2, 0, 1)  # [W, B, 512]\n",
        "        rnn_out, _ = self.rnn(conv)\n",
        "        rnn_out = self.dropout(rnn_out)\n",
        "        output = self.classifier(rnn_out)\n",
        "        return F.log_softmax(output, dim=2)\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 3. CTC UTILITIES (UNCHANGED)\n",
        "# ======================\n",
        "def ctc_collate_fn(batch):\n",
        "    images, text_indices_list, raw_texts = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "    targets = []\n",
        "    target_lengths = []\n",
        "    for text_indices in text_indices_list:\n",
        "        if len(text_indices) > 0:\n",
        "            targets.extend(text_indices)\n",
        "            target_lengths.append(len(text_indices))\n",
        "        else:\n",
        "            targets.append(0)\n",
        "            target_lengths.append(1)\n",
        "    return images, torch.tensor(targets), torch.tensor(target_lengths), raw_texts\n",
        "\n",
        "def ctc_decode(log_probs, idx_to_char, blank_idx=0):\n",
        "    \"\"\"Greedy CTC decoding\"\"\"\n",
        "    seq_len, batch_size, num_classes = log_probs.shape\n",
        "    predictions = []\n",
        "    for b in range(batch_size):\n",
        "        pred_indices = log_probs[:, b, :].argmax(dim=1).cpu().numpy()\n",
        "        decoded = []\n",
        "        prev_idx = blank_idx\n",
        "        for idx in pred_indices:\n",
        "            if idx != blank_idx and idx != prev_idx:\n",
        "                if idx in idx_to_char and idx_to_char[idx] != '<BLANK>':\n",
        "                    decoded.append(idx_to_char[idx])\n",
        "            prev_idx = idx\n",
        "        predictions.append(''.join(decoded))\n",
        "    return predictions\n",
        "\n",
        "def calculate_metrics(pred_texts, true_texts):\n",
        "    \"\"\"Calculate word and character accuracy\"\"\"\n",
        "    if not pred_texts or not true_texts:\n",
        "        return 0.0, 0.0\n",
        "    word_acc = sum(p == t for p, t in zip(pred_texts, true_texts)) / len(true_texts)\n",
        "    total_chars = sum(max(len(p), len(t)) for p, t in zip(pred_texts, true_texts))\n",
        "    correct_chars = sum(p[i] == t[i] for p, t in zip(pred_texts, true_texts) for i in range(min(len(p), len(t))))\n",
        "    char_acc = correct_chars / total_chars if total_chars > 0 else 0.0\n",
        "    return word_acc, char_acc\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 4. TRAINING LOOP WITH CUSTOM SPLIT\n",
        "# ======================\n",
        "def train_deep_ocr_custom_split():\n",
        "    print(\"🚀 DEEP OCR TRAINING WITH CUSTOM SPLIT (4500 train, 500 test)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # CONFIGURATION - Updated based on your dataset structure\n",
        "    dataset_root = \"/content/iiit5k_dataset\"  # Your extracted dataset path\n",
        "\n",
        "    # Verify dataset exists\n",
        "    print(f\"🔍 Checking dataset root: {dataset_root}\")\n",
        "    print(f\"📁 Path exists: {os.path.exists(dataset_root)}\")\n",
        "\n",
        "    if not os.path.exists(dataset_root):\n",
        "        # Try alternative paths\n",
        "        alternative_paths = [\"./iiit5k_dataset\", \"/content/iiit5k_dataset\"]\n",
        "        for alt_path in alternative_paths:\n",
        "            if os.path.exists(alt_path):\n",
        "                dataset_root = alt_path\n",
        "                print(f\"✅ Found dataset at alternative path: {dataset_root}\")\n",
        "                break\n",
        "        else:\n",
        "            print(f\"❌ Dataset root not found at any location\")\n",
        "            print(\"💡 Checked paths:\")\n",
        "            for path in [\"/content/iiit5k_dataset\"] + alternative_paths:\n",
        "                print(f\"   {path}: {'✅' if os.path.exists(path) else '❌'}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"✅ Dataset root found: {dataset_root}\")\n",
        "\n",
        "    # Verify IIIT5K subdirectory structure\n",
        "    iiit5k_path = os.path.join(dataset_root, \"IIIT5K\")\n",
        "    print(f\"🔍 Checking IIIT5K path: {iiit5k_path}\")\n",
        "    print(f\"📁 IIIT5K exists: {os.path.exists(iiit5k_path)}\")\n",
        "\n",
        "    if os.path.exists(iiit5k_path):\n",
        "        contents = os.listdir(iiit5k_path)\n",
        "        print(f\"📊 IIIT5K contents: {contents}\")\n",
        "\n",
        "        # Check required files\n",
        "        required_items = ['train', 'test', 'traindata.mat', 'testdata.mat']\n",
        "        missing_items = [item for item in required_items if item not in contents]\n",
        "\n",
        "        if missing_items:\n",
        "            print(f\"❌ Missing required items: {missing_items}\")\n",
        "            return None\n",
        "        else:\n",
        "            print(\"✅ All required dataset components found!\")\n",
        "    else:\n",
        "        print(f\"❌ IIIT5K subdirectory not found at: {iiit5k_path}\")\n",
        "        return None\n",
        "\n",
        "    batch_size = 32\n",
        "    num_epochs = 250\n",
        "    learning_rate = 1e-3\n",
        "    train_samples = 4500\n",
        "    test_samples = 500\n",
        "\n",
        "    print(f\"Custom split: {train_samples} train, {test_samples} test\")\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "    print(f\"Epochs: {num_epochs}\")\n",
        "    print(f\"Learning rate: {learning_rate}\")\n",
        "\n",
        "    # Load datasets with custom split\n",
        "    print(\"\\nCreating custom split datasets...\")\n",
        "    try:\n",
        "        train_dataset = CustomSplitIIIT5KDataset(\n",
        "            dataset_root, 'train', 32, 128, train_samples, test_samples\n",
        "        )\n",
        "        test_dataset = CustomSplitIIIT5KDataset(\n",
        "            dataset_root, 'test', 32, 128, train_samples, test_samples\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Dataset creation failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    if len(train_dataset) == 0 or len(test_dataset) == 0:\n",
        "        print(\"❌ No valid data loaded.\")\n",
        "        return None\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                              collate_fn=ctc_collate_fn, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                             collate_fn=ctc_collate_fn, num_workers=0)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"\\nDevice: {device}\")\n",
        "\n",
        "    model = DeepCRNN(32, train_dataset.num_classes).to(device)\n",
        "    criterion = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(f\"Training batches: {len(train_loader)}\")\n",
        "    print(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "    best_word_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_word_acc = 0.0\n",
        "        num_train_batches = 0\n",
        "\n",
        "        print(f\"\\n📈 Epoch {epoch+1}/{num_epochs}\")\n",
        "        pbar = tqdm(train_loader, desc=\"Training\")\n",
        "        for images, targets, target_lengths, raw_texts in pbar:\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            target_lengths = target_lengths.to(device)\n",
        "\n",
        "            log_probs = model(images)\n",
        "            input_lengths = torch.full((images.size(0),), log_probs.size(0), device=device, dtype=torch.long)\n",
        "            loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Log every 20 batches (adjusted for potentially more batches)\n",
        "            if num_train_batches % 20 == 0:\n",
        "                pred_texts = ctc_decode(log_probs.cpu(), train_dataset.idx_to_char)\n",
        "                word_acc, _ = calculate_metrics(pred_texts, raw_texts)\n",
        "                train_word_acc += word_acc\n",
        "                pbar.set_postfix({\"loss\": f\"{loss.item():.3f}\", \"word_acc\": f\"{word_acc:.3f}\"})\n",
        "\n",
        "            num_train_batches += 1\n",
        "\n",
        "        scheduler.step()\n",
        "        train_loss /= num_train_batches\n",
        "        train_word_acc /= (num_train_batches // 20 + 1)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds, val_truths = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, targets, target_lengths, raw_texts in test_loader:\n",
        "                images = images.to(device)\n",
        "                log_probs = model(images)\n",
        "                pred_texts = ctc_decode(log_probs.cpu(), test_dataset.idx_to_char)\n",
        "                val_preds.extend(pred_texts)\n",
        "                val_truths.extend(raw_texts)\n",
        "\n",
        "        val_word_acc, val_char_acc = calculate_metrics(val_preds, val_truths)\n",
        "\n",
        "        print(f\"\\n📊 Epoch {epoch+1} Summary:\")\n",
        "        print(f\"  Training Loss: {train_loss:.4f}\")\n",
        "        print(f\"  Training Word Acc: {train_word_acc:.4f}\")\n",
        "        print(f\"  Validation Word Acc: {val_word_acc:.4f}\")\n",
        "        print(f\"  Validation Char Acc: {val_char_acc:.4f}\")\n",
        "        print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        if val_word_acc > best_word_acc:\n",
        "            best_word_acc = val_word_acc\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'val_word_acc': val_word_acc,\n",
        "                'idx_to_char': train_dataset.idx_to_char,\n",
        "                'num_classes': train_dataset.num_classes\n",
        "            }, 'deep_ocr_custom_split_model.pth')\n",
        "            print(f\"  ✅ New best model saved! Word Acc: {best_word_acc:.4f}\")\n",
        "\n",
        "        # Sample predictions\n",
        "        print(f\"\\n🎯 Sample predictions:\")\n",
        "        indices = np.random.choice(len(val_preds), min(5, len(val_preds)), replace=False)\n",
        "        for i in indices:\n",
        "            print(f\"  True: '{val_truths[i]}' | Pred: '{val_preds[i]}'\")\n",
        "\n",
        "    print(f\"\\n🎉 Training completed!\")\n",
        "    print(f\"Best validation word accuracy: {best_word_acc:.4f}\")\n",
        "    return best_word_acc\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 5. MAIN EXECUTION\n",
        "# ======================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"⚡ DEEP OCR SYSTEM WITH CUSTOM SPLIT\")\n",
        "    print(\"=\" * 50)\n",
        "    choice = input(\"\\nChoose option:\\n1. Train with custom split (4500 train, 500 test)\\n2. Exit\\nChoice: \")\n",
        "    if choice == \"1\":\n",
        "        accuracy = train_deep_ocr_custom_split()\n",
        "        if accuracy is not None:\n",
        "            print(f\"\\n🏆 Final result: {accuracy:.4f} word accuracy\")\n",
        "        else:\n",
        "            print(\"\\n❌ Training failed. Check error messages above.\")\n",
        "    else:\n",
        "        print(\"Goodbye! 👋\")"
      ],
      "metadata": {
        "id": "EdESf4YIL-vO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e5d969-0c35-4977-cf97-72cd12c8bb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚡ DEEP OCR SYSTEM WITH CUSTOM SPLIT\n",
            "==================================================\n",
            "\n",
            "Choose option:\n",
            "1. Train with custom split (4500 train, 500 test)\n",
            "2. Exit\n",
            "Choice: 1\n",
            "🚀 DEEP OCR TRAINING WITH CUSTOM SPLIT (4500 train, 500 test)\n",
            "============================================================\n",
            "🔍 Checking dataset root: /content/iiit5k_dataset\n",
            "📁 Path exists: True\n",
            "✅ Dataset root found: /content/iiit5k_dataset\n",
            "🔍 Checking IIIT5K path: /content/iiit5k_dataset/IIIT5K\n",
            "📁 IIIT5K exists: True\n",
            "📊 IIIT5K contents: ['test', 'traindata.mat', 'trainCharBound.mat', 'testCharBound.mat', 'train', 'README', 'lexicon.txt', 'testdata.mat']\n",
            "✅ All required dataset components found!\n",
            "Custom split: 4500 train, 500 test\n",
            "Batch size: 32\n",
            "Epochs: 250\n",
            "Learning rate: 0.001\n",
            "\n",
            "Creating custom split datasets...\n",
            "Creating custom dataset split with 4500 train, 500 test samples...\n",
            "Processing 2000 samples from train data...\n",
            "Processing 3000 samples from test data...\n",
            "Total samples loaded: 5000\n",
            "✅ Created training set with 4500 samples\n",
            "Sample texts: ['YOU', 'SBI', 'MEDICINE', 'MARRY', 'YOURSELF', 'CAN', 'THIS', '21', 'VOLTS', 'WAVERLEY']\n",
            "Text lengths: min=1, max=22, avg=5.0\n",
            "Vocabulary size: 95\n",
            "Creating custom dataset split with 4500 train, 500 test samples...\n",
            "Processing 2000 samples from train data...\n",
            "Processing 3000 samples from test data...\n",
            "Total samples loaded: 5000\n",
            "✅ Created test set with 500 samples\n",
            "Sample texts: ['PACK', '1800BUYKWIK', 'DAY', 'INDIA', 'INDIA', 'INDIA', 'LINY', 'GREAT', 'FOUNDRY', 'SOLVE']\n",
            "Text lengths: min=1, max=19, avg=5.0\n",
            "Vocabulary size: 95\n",
            "\n",
            "Device: cuda\n",
            "Model parameters: 5,580,255\n",
            "Training batches: 141\n",
            "Test batches: 16\n",
            "\n",
            "📈 Epoch 1/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:10<00:00, 13.73it/s, loss=3.593, word_acc=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 1 Summary:\n",
            "  Training Loss: 4.1951\n",
            "  Training Word Acc: 0.0000\n",
            "  Validation Word Acc: 0.0000\n",
            "  Validation Char Acc: 0.0000\n",
            "  Learning Rate: 0.001000\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SALT' | Pred: ''\n",
            "  True: 'BIG' | Pred: ''\n",
            "  True: 'DANGERS' | Pred: ''\n",
            "  True: 'THE' | Pred: ''\n",
            "  True: 'INVERCARGILL' | Pred: ''\n",
            "\n",
            "📈 Epoch 2/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 17.10it/s, loss=3.409, word_acc=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 2 Summary:\n",
            "  Training Loss: 3.5359\n",
            "  Training Word Acc: 0.0000\n",
            "  Validation Word Acc: 0.0000\n",
            "  Validation Char Acc: 0.0000\n",
            "  Learning Rate: 0.001000\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'AN' | Pred: ''\n",
            "  True: 'WISTERIA' | Pred: ''\n",
            "  True: 'MELIN' | Pred: ''\n",
            "  True: 'EASTWOOD' | Pred: ''\n",
            "  True: 'PRODAJA' | Pred: ''\n",
            "\n",
            "📈 Epoch 3/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.42it/s, loss=3.725, word_acc=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 3 Summary:\n",
            "  Training Loss: 3.4614\n",
            "  Training Word Acc: 0.0000\n",
            "  Validation Word Acc: 0.0000\n",
            "  Validation Char Acc: 0.0028\n",
            "  Learning Rate: 0.001000\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '20' | Pred: ''\n",
            "  True: 'SADLER' | Pred: ''\n",
            "  True: 'SBI' | Pred: ''\n",
            "  True: 'WHETLEY' | Pred: ''\n",
            "  True: 'WINSLET' | Pred: ''\n",
            "\n",
            "📈 Epoch 4/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.44it/s, loss=3.281, word_acc=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 4 Summary:\n",
            "  Training Loss: 3.3220\n",
            "  Training Word Acc: 0.0000\n",
            "  Validation Word Acc: 0.0020\n",
            "  Validation Char Acc: 0.0439\n",
            "  Learning Rate: 0.000999\n",
            "  ✅ New best model saved! Word Acc: 0.0020\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'POSSOBILITIES' | Pred: 'C'\n",
            "  True: 'THE' | Pred: 'O'\n",
            "  True: 'DIAZ' | Pred: 'C'\n",
            "  True: 'IN' | Pred: 'I'\n",
            "  True: 'HOUSE' | Pred: 'C'\n",
            "\n",
            "📈 Epoch 5/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.74it/s, loss=3.131, word_acc=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 5 Summary:\n",
            "  Training Loss: 3.1153\n",
            "  Training Word Acc: 0.0000\n",
            "  Validation Word Acc: 0.0060\n",
            "  Validation Char Acc: 0.0587\n",
            "  Learning Rate: 0.000999\n",
            "  ✅ New best model saved! Word Acc: 0.0060\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '15' | Pred: '1'\n",
            "  True: 'DAY' | Pred: 'O'\n",
            "  True: 'LIFES' | Pred: 'IE'\n",
            "  True: 'BLOOM' | Pred: 'C'\n",
            "  True: 'BANK' | Pred: 'TE'\n",
            "\n",
            "📈 Epoch 6/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.34it/s, loss=2.840, word_acc=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 6 Summary:\n",
            "  Training Loss: 2.8810\n",
            "  Training Word Acc: 0.0000\n",
            "  Validation Word Acc: 0.0380\n",
            "  Validation Char Acc: 0.0986\n",
            "  Learning Rate: 0.000999\n",
            "  ✅ New best model saved! Word Acc: 0.0380\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ZAJAZD' | Pred: '3E'\n",
            "  True: 'REGENCY' | Pred: 'CN'\n",
            "  True: 'WISTERIA' | Pred: 'B'\n",
            "  True: 'GO' | Pred: 'C'\n",
            "  True: 'OLD' | Pred: 'O'\n",
            "\n",
            "📈 Epoch 7/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.26it/s, loss=2.467, word_acc=0.050]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 7 Summary:\n",
            "  Training Loss: 2.5441\n",
            "  Training Word Acc: 0.0336\n",
            "  Validation Word Acc: 0.0520\n",
            "  Validation Char Acc: 0.1608\n",
            "  Learning Rate: 0.000998\n",
            "  ✅ New best model saved! Word Acc: 0.0520\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'LOVE' | Pred: 'TE'\n",
            "  True: 'NEWS' | Pred: 'RES'\n",
            "  True: 'HANDY' | Pred: 'AN'\n",
            "  True: 'CREATE' | Pred: 'CEE'\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "\n",
            "📈 Epoch 8/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.16it/s, loss=2.317, word_acc=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 8 Summary:\n",
            "  Training Loss: 2.2180\n",
            "  Training Word Acc: 0.0352\n",
            "  Validation Word Acc: 0.0660\n",
            "  Validation Char Acc: 0.2010\n",
            "  Learning Rate: 0.000997\n",
            "  ✅ New best model saved! Word Acc: 0.0660\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'VAL' | Pred: 'IAD'\n",
            "  True: 'BALE' | Pred: 'BAE'\n",
            "  True: 'NORTH' | Pred: 'AOE'\n",
            "  True: 'FOSTER' | Pred: 'BOSER'\n",
            "  True: 'REGENCY' | Pred: 'AEE'\n",
            "\n",
            "📈 Epoch 9/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.37it/s, loss=1.798, word_acc=0.050]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 9 Summary:\n",
            "  Training Loss: 1.8886\n",
            "  Training Word Acc: 0.0570\n",
            "  Validation Word Acc: 0.0860\n",
            "  Validation Char Acc: 0.2450\n",
            "  Learning Rate: 0.000997\n",
            "  ✅ New best model saved! Word Acc: 0.0860\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '2' | Pred: '2'\n",
            "  True: 'CIUDAD' | Pred: 'CCA'\n",
            "  True: '23' | Pred: '2'\n",
            "  True: 'THIS' | Pred: 'THS'\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "\n",
            "📈 Epoch 10/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 17.07it/s, loss=1.298, word_acc=0.050]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 10 Summary:\n",
            "  Training Loss: 1.5832\n",
            "  Training Word Acc: 0.1000\n",
            "  Validation Word Acc: 0.1880\n",
            "  Validation Char Acc: 0.4065\n",
            "  Learning Rate: 0.000996\n",
            "  ✅ New best model saved! Word Acc: 0.1880\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'MASTERFILE' | Pred: 'TAEETE'\n",
            "  True: 'TARKOWSKI' | Pred: 'TARROWS'\n",
            "  True: 'PORTABLE' | Pred: 'PORAPE'\n",
            "  True: 'GRASSROOTSMARKETING' | Pred: 'WTNTN'\n",
            "  True: 'BADGES' | Pred: 'BALCES'\n",
            "\n",
            "📈 Epoch 11/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.40it/s, loss=1.255, word_acc=0.200]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 11 Summary:\n",
            "  Training Loss: 1.3036\n",
            "  Training Word Acc: 0.2477\n",
            "  Validation Word Acc: 0.2680\n",
            "  Validation Char Acc: 0.4927\n",
            "  Learning Rate: 0.000995\n",
            "  ✅ New best model saved! Word Acc: 0.2680\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'KARI' | Pred: 'RRT'\n",
            "  True: 'COMPARISON' | Pred: 'CONWATISOM'\n",
            "  True: '5' | Pred: 'S'\n",
            "  True: 'DAY' | Pred: 'DAY'\n",
            "  True: 'REBELLION' | Pred: 'MWSION'\n",
            "\n",
            "📈 Epoch 12/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.32it/s, loss=1.287, word_acc=0.400]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 12 Summary:\n",
            "  Training Loss: 1.0790\n",
            "  Training Word Acc: 0.3234\n",
            "  Validation Word Acc: 0.3320\n",
            "  Validation Char Acc: 0.5334\n",
            "  Learning Rate: 0.000994\n",
            "  ✅ New best model saved! Word Acc: 0.3320\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'VIEWERS' | Pred: 'WENERS'\n",
            "  True: 'A' | Pred: 'A'\n",
            "  True: 'INTO' | Pred: 'IO'\n",
            "  True: 'VAL' | Pred: 'VAL'\n",
            "  True: 'DIVIDE' | Pred: 'HIDE'\n",
            "\n",
            "📈 Epoch 13/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.32it/s, loss=0.623, word_acc=0.300]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 13 Summary:\n",
            "  Training Loss: 0.8823\n",
            "  Training Word Acc: 0.3891\n",
            "  Validation Word Acc: 0.3820\n",
            "  Validation Char Acc: 0.5659\n",
            "  Learning Rate: 0.000993\n",
            "  ✅ New best model saved! Word Acc: 0.3820\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ONLY' | Pred: 'ONY'\n",
            "  True: 'NO' | Pred: 'WON'\n",
            "  True: 'PENANG' | Pred: 'PENANG'\n",
            "  True: 'INDIA' | Pred: 'INDA'\n",
            "  True: '77' | Pred: '7'\n",
            "\n",
            "📈 Epoch 14/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 17.15it/s, loss=0.363, word_acc=0.750]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 14 Summary:\n",
            "  Training Loss: 0.7480\n",
            "  Training Word Acc: 0.5273\n",
            "  Validation Word Acc: 0.4760\n",
            "  Validation Char Acc: 0.6542\n",
            "  Learning Rate: 0.000992\n",
            "  ✅ New best model saved! Word Acc: 0.4760\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'LOVE' | Pred: 'TOA'\n",
            "  True: 'MONTGOMERY' | Pred: 'MONIGOMBENY'\n",
            "  True: 'FAILTE' | Pred: 'CALLTE'\n",
            "  True: 'GOODWILL' | Pred: 'COODYILL'\n",
            "  True: 'NORTH' | Pred: 'MORTH'\n",
            "\n",
            "📈 Epoch 15/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.31it/s, loss=0.674, word_acc=0.400]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 15 Summary:\n",
            "  Training Loss: 0.6570\n",
            "  Training Word Acc: 0.5188\n",
            "  Validation Word Acc: 0.4740\n",
            "  Validation Char Acc: 0.6711\n",
            "  Learning Rate: 0.000991\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'LOADING' | Pred: 'CEBING'\n",
            "  True: 'BANKNORTH' | Pred: 'BANKNORIH'\n",
            "  True: 'FAILTE' | Pred: 'TAILIE'\n",
            "  True: 'DENZEL' | Pred: 'DENEET'\n",
            "  True: 'MASTERFILE' | Pred: 'IAEAIE'\n",
            "\n",
            "📈 Epoch 16/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.26it/s, loss=0.500, word_acc=0.400]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 16 Summary:\n",
            "  Training Loss: 0.5703\n",
            "  Training Word Acc: 0.5109\n",
            "  Validation Word Acc: 0.5080\n",
            "  Validation Char Acc: 0.7029\n",
            "  Learning Rate: 0.000990\n",
            "  ✅ New best model saved! Word Acc: 0.5080\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'THE' | Pred: 'THC'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'DUKES' | Pred: 'DUKES'\n",
            "  True: 'FIRE' | Pred: 'FIRE'\n",
            "  True: 'SADLER' | Pred: 'SODNER'\n",
            "\n",
            "📈 Epoch 17/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.22it/s, loss=0.221, word_acc=0.700]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 17 Summary:\n",
            "  Training Loss: 0.4905\n",
            "  Training Word Acc: 0.6578\n",
            "  Validation Word Acc: 0.5580\n",
            "  Validation Char Acc: 0.7150\n",
            "  Learning Rate: 0.000989\n",
            "  ✅ New best model saved! Word Acc: 0.5580\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PHONE' | Pred: 'PHON'\n",
            "  True: 'IS' | Pred: 'T5'\n",
            "  True: 'DEMONS' | Pred: 'DENONS'\n",
            "  True: 'FOR' | Pred: 'FOR'\n",
            "  True: 'HOME' | Pred: 'HOME'\n",
            "\n",
            "📈 Epoch 18/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.90it/s, loss=0.553, word_acc=0.500]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 18 Summary:\n",
            "  Training Loss: 0.4226\n",
            "  Training Word Acc: 0.6211\n",
            "  Validation Word Acc: 0.5900\n",
            "  Validation Char Acc: 0.7270\n",
            "  Learning Rate: 0.000987\n",
            "  ✅ New best model saved! Word Acc: 0.5900\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CANDIDATE' | Pred: 'CANOMOATE'\n",
            "  True: 'ASIA' | Pred: 'ASIA'\n",
            "  True: 'SALMON' | Pred: 'CLOS'\n",
            "  True: 'BE' | Pred: '38'\n",
            "  True: 'AHEAD' | Pred: 'AHEAD'\n",
            "\n",
            "📈 Epoch 19/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.19it/s, loss=0.495, word_acc=0.650]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 19 Summary:\n",
            "  Training Loss: 0.3666\n",
            "  Training Word Acc: 0.6828\n",
            "  Validation Word Acc: 0.6100\n",
            "  Validation Char Acc: 0.7432\n",
            "  Learning Rate: 0.000986\n",
            "  ✅ New best model saved! Word Acc: 0.6100\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SPACE' | Pred: 'SPACE'\n",
            "  True: 'ANGELS' | Pred: 'ANGELS'\n",
            "  True: 'YOURE' | Pred: 'YOURE'\n",
            "  True: 'INDIASBIN' | Pred: 'INDIAISBIN'\n",
            "  True: 'DAY' | Pred: '1'\n",
            "\n",
            "📈 Epoch 20/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.27it/s, loss=0.866, word_acc=0.300]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 20 Summary:\n",
            "  Training Loss: 0.3277\n",
            "  Training Word Acc: 0.7172\n",
            "  Validation Word Acc: 0.6000\n",
            "  Validation Char Acc: 0.7383\n",
            "  Learning Rate: 0.000984\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PRODAJA' | Pred: 'PIODBIA'\n",
            "  True: 'DIRECTLY' | Pred: 'DIRECTLY'\n",
            "  True: 'USER' | Pred: 'USER'\n",
            "  True: 'WISHES' | Pred: 'WISHES'\n",
            "  True: 'TO' | Pred: 'TO'\n",
            "\n",
            "📈 Epoch 21/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.19it/s, loss=0.391, word_acc=0.850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 21 Summary:\n",
            "  Training Loss: 0.2957\n",
            "  Training Word Acc: 0.7664\n",
            "  Validation Word Acc: 0.6340\n",
            "  Validation Char Acc: 0.7524\n",
            "  Learning Rate: 0.000983\n",
            "  ✅ New best model saved! Word Acc: 0.6340\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ALSO' | Pred: 'ALSD'\n",
            "  True: 'LINY' | Pred: 'LINW'\n",
            "  True: 'LOW' | Pred: 'LOW'\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "  True: 'US' | Pred: 'US'\n",
            "\n",
            "📈 Epoch 22/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.83it/s, loss=0.229, word_acc=0.750]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 22 Summary:\n",
            "  Training Loss: 0.2764\n",
            "  Training Word Acc: 0.7383\n",
            "  Validation Word Acc: 0.6100\n",
            "  Validation Char Acc: 0.7393\n",
            "  Learning Rate: 0.000981\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '8839660' | Pred: '8839660'\n",
            "  True: 'DEMONS' | Pred: 'DEWONS'\n",
            "  True: 'IN' | Pred: 'IN'\n",
            "  True: 'HOME' | Pred: 'HOTIE'\n",
            "  True: 'METER' | Pred: 'METER'\n",
            "\n",
            "📈 Epoch 23/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.84it/s, loss=0.574, word_acc=0.750]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 23 Summary:\n",
            "  Training Loss: 0.2338\n",
            "  Training Word Acc: 0.7812\n",
            "  Validation Word Acc: 0.6440\n",
            "  Validation Char Acc: 0.7622\n",
            "  Learning Rate: 0.000979\n",
            "  ✅ New best model saved! Word Acc: 0.6440\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CAMP' | Pred: 'CAMP'\n",
            "  True: 'TRINITYLEEDS' | Pred: 'THMILGLES'\n",
            "  True: 'MEANS' | Pred: 'MEANS'\n",
            "  True: 'ABOUT' | Pred: 'ABOUT'\n",
            "  True: '95' | Pred: '95'\n",
            "\n",
            "📈 Epoch 24/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.89it/s, loss=0.226, word_acc=0.850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 24 Summary:\n",
            "  Training Loss: 0.2065\n",
            "  Training Word Acc: 0.8719\n",
            "  Validation Word Acc: 0.6560\n",
            "  Validation Char Acc: 0.7688\n",
            "  Learning Rate: 0.000977\n",
            "  ✅ New best model saved! Word Acc: 0.6560\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'THIS' | Pred: 'THIS'\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "  True: 'DIRECTION' | Pred: 'DIRECTION'\n",
            "  True: 'DIVIDE' | Pred: 'PIVIDE'\n",
            "  True: 'WILT' | Pred: 'WILT'\n",
            "\n",
            "📈 Epoch 25/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.79it/s, loss=0.207, word_acc=0.850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 25 Summary:\n",
            "  Training Loss: 0.1719\n",
            "  Training Word Acc: 0.8523\n",
            "  Validation Word Acc: 0.6760\n",
            "  Validation Char Acc: 0.7935\n",
            "  Learning Rate: 0.000976\n",
            "  ✅ New best model saved! Word Acc: 0.6760\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'LIFES' | Pred: 'LFES'\n",
            "  True: 'LETS' | Pred: 'LETS'\n",
            "  True: '101' | Pred: '101'\n",
            "  True: 'MARZO' | Pred: 'MARZO'\n",
            "  True: 'CFN' | Pred: 'CFN'\n",
            "\n",
            "📈 Epoch 26/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.70it/s, loss=0.121, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 26 Summary:\n",
            "  Training Loss: 0.1650\n",
            "  Training Word Acc: 0.8430\n",
            "  Validation Word Acc: 0.6880\n",
            "  Validation Char Acc: 0.7810\n",
            "  Learning Rate: 0.000974\n",
            "  ✅ New best model saved! Word Acc: 0.6880\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'MASTERFILE' | Pred: 'TOTERILE'\n",
            "  True: 'IMPERIAL' | Pred: 'TMPENAN'\n",
            "  True: 'BEGIN' | Pred: 'BEGIN'\n",
            "  True: 'MOTION' | Pred: 'MOTION'\n",
            "  True: 'STATE' | Pred: 'STATE'\n",
            "\n",
            "📈 Epoch 27/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.44it/s, loss=0.102, word_acc=0.800]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 27 Summary:\n",
            "  Training Loss: 0.1435\n",
            "  Training Word Acc: 0.8344\n",
            "  Validation Word Acc: 0.6840\n",
            "  Validation Char Acc: 0.8051\n",
            "  Learning Rate: 0.000971\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'I' | Pred: 'I'\n",
            "  True: '3D' | Pred: '9D'\n",
            "  True: 'YOU' | Pred: 'YOU'\n",
            "  True: 'MOBILE' | Pred: 'MOBILE'\n",
            "  True: 'LINY' | Pred: 'LINY'\n",
            "\n",
            "📈 Epoch 28/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.07it/s, loss=0.328, word_acc=0.650]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 28 Summary:\n",
            "  Training Loss: 0.1308\n",
            "  Training Word Acc: 0.8000\n",
            "  Validation Word Acc: 0.6540\n",
            "  Validation Char Acc: 0.7935\n",
            "  Learning Rate: 0.000969\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ABOUT' | Pred: 'ABOUT'\n",
            "  True: '23' | Pred: '23'\n",
            "  True: 'INDIA' | Pred: 'LANA'\n",
            "  True: 'MONTGOMERY' | Pred: 'MONIGOMIERY'\n",
            "  True: 'AHEAD' | Pred: 'AHEAD'\n",
            "\n",
            "📈 Epoch 29/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.16it/s, loss=0.049, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 29 Summary:\n",
            "  Training Loss: 0.1207\n",
            "  Training Word Acc: 0.8961\n",
            "  Validation Word Acc: 0.7020\n",
            "  Validation Char Acc: 0.7887\n",
            "  Learning Rate: 0.000967\n",
            "  ✅ New best model saved! Word Acc: 0.7020\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'VIEW' | Pred: 'VIEW'\n",
            "  True: 'PARKING' | Pred: 'PARKING'\n",
            "  True: 'MIRREN' | Pred: 'MIRREN'\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "  True: 'BLUBBER' | Pred: 'BTUBBER'\n",
            "\n",
            "📈 Epoch 30/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.34it/s, loss=0.040, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 30 Summary:\n",
            "  Training Loss: 0.1086\n",
            "  Training Word Acc: 0.8883\n",
            "  Validation Word Acc: 0.6920\n",
            "  Validation Char Acc: 0.8036\n",
            "  Learning Rate: 0.000965\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'EASTWOOD' | Pred: 'EASTYOOD'\n",
            "  True: 'HEFNER' | Pred: 'HEFNER'\n",
            "  True: 'KELLIMAR' | Pred: 'LEHAMAMAN'\n",
            "  True: '02' | Pred: '02'\n",
            "  True: 'ON' | Pred: 'ON'\n",
            "\n",
            "📈 Epoch 31/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.54it/s, loss=0.127, word_acc=0.850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 31 Summary:\n",
            "  Training Loss: 0.1137\n",
            "  Training Word Acc: 0.9070\n",
            "  Validation Word Acc: 0.6620\n",
            "  Validation Char Acc: 0.7770\n",
            "  Learning Rate: 0.000963\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BOGART' | Pred: 'BOGART'\n",
            "  True: 'TOUCHDOWN' | Pred: 'FOUGPDOT'\n",
            "  True: 'AN' | Pred: 'AN'\n",
            "  True: 'VIEW' | Pred: 'WIES'\n",
            "  True: 'PRICES' | Pred: 'PRICES'\n",
            "\n",
            "📈 Epoch 32/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:09<00:00, 15.15it/s, loss=0.069, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 32 Summary:\n",
            "  Training Loss: 0.0972\n",
            "  Training Word Acc: 0.8961\n",
            "  Validation Word Acc: 0.6740\n",
            "  Validation Char Acc: 0.7915\n",
            "  Learning Rate: 0.000960\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BOGART' | Pred: 'BOGART'\n",
            "  True: 'STATE' | Pred: 'STATE'\n",
            "  True: 'NSERIES' | Pred: 'NSERIES'\n",
            "  True: 'MARILYN' | Pred: 'MARILYN'\n",
            "  True: 'KELLIMAR' | Pred: 'LEHMMAN'\n",
            "\n",
            "📈 Epoch 33/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.01it/s, loss=0.032, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 33 Summary:\n",
            "  Training Loss: 0.0873\n",
            "  Training Word Acc: 0.8766\n",
            "  Validation Word Acc: 0.6940\n",
            "  Validation Char Acc: 0.7880\n",
            "  Learning Rate: 0.000958\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'VALE' | Pred: 'VALE'\n",
            "  True: 'MASS' | Pred: 'MASS'\n",
            "  True: 'RD' | Pred: 'RD'\n",
            "  True: '3D' | Pred: 'BR'\n",
            "  True: 'BIG' | Pred: 'BIG'\n",
            "\n",
            "📈 Epoch 34/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.10it/s, loss=0.106, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 34 Summary:\n",
            "  Training Loss: 0.0779\n",
            "  Training Word Acc: 0.9172\n",
            "  Validation Word Acc: 0.6740\n",
            "  Validation Char Acc: 0.7834\n",
            "  Learning Rate: 0.000955\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CARING' | Pred: 'CARING'\n",
            "  True: 'DIRECTION' | Pred: 'DIRECTION'\n",
            "  True: 'THIS' | Pred: 'THIS'\n",
            "  True: 'COLA' | Pred: 'COLA'\n",
            "  True: 'CHECKMATE' | Pred: 'CHECKMATE'\n",
            "\n",
            "📈 Epoch 35/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.66it/s, loss=0.118, word_acc=0.850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 35 Summary:\n",
            "  Training Loss: 0.0766\n",
            "  Training Word Acc: 0.8875\n",
            "  Validation Word Acc: 0.7140\n",
            "  Validation Char Acc: 0.8024\n",
            "  Learning Rate: 0.000952\n",
            "  ✅ New best model saved! Word Acc: 0.7140\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SURVEY' | Pred: 'SURVEY'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'FUTURE' | Pred: 'FUTURE'\n",
            "  True: 'TWENTY' | Pred: 'INENTY'\n",
            "  True: 'RESET' | Pred: 'RESET'\n",
            "\n",
            "📈 Epoch 36/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.92it/s, loss=0.103, word_acc=0.750]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 36 Summary:\n",
            "  Training Loss: 0.0624\n",
            "  Training Word Acc: 0.8984\n",
            "  Validation Word Acc: 0.7040\n",
            "  Validation Char Acc: 0.8221\n",
            "  Learning Rate: 0.000950\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'IS' | Pred: 'IES'\n",
            "  True: 'EASTWOOD' | Pred: 'EASTWOOD'\n",
            "  True: 'BOGART' | Pred: 'BOGART'\n",
            "  True: 'RD' | Pred: 'RD'\n",
            "  True: 'CHRYSLER' | Pred: 'CHRVSLER'\n",
            "\n",
            "📈 Epoch 37/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.11it/s, loss=0.017, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 37 Summary:\n",
            "  Training Loss: 0.0593\n",
            "  Training Word Acc: 0.9414\n",
            "  Validation Word Acc: 0.7060\n",
            "  Validation Char Acc: 0.8153\n",
            "  Learning Rate: 0.000947\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SPACE' | Pred: 'SPACE'\n",
            "  True: 'AND' | Pred: 'AND'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'TWITTERCOMAPLUSK' | Pred: 'WILECOMLEPLOST'\n",
            "  True: 'HOME' | Pred: 'FOME'\n",
            "\n",
            "📈 Epoch 38/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.10it/s, loss=0.046, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 38 Summary:\n",
            "  Training Loss: 0.0514\n",
            "  Training Word Acc: 0.9430\n",
            "  Validation Word Acc: 0.7220\n",
            "  Validation Char Acc: 0.8024\n",
            "  Learning Rate: 0.000944\n",
            "  ✅ New best model saved! Word Acc: 0.7220\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'FRIENDS' | Pred: 'FRIENDS'\n",
            "  True: 'EN' | Pred: 'EN'\n",
            "  True: 'LOSE' | Pred: 'LOSE'\n",
            "  True: 'FOSTER' | Pred: 'FOSTER'\n",
            "  True: 'WISHES' | Pred: 'WISHES'\n",
            "\n",
            "📈 Epoch 39/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.86it/s, loss=0.078, word_acc=0.750]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 39 Summary:\n",
            "  Training Loss: 0.0513\n",
            "  Training Word Acc: 0.9297\n",
            "  Validation Word Acc: 0.7140\n",
            "  Validation Char Acc: 0.8143\n",
            "  Learning Rate: 0.000941\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TOUCHDOWN' | Pred: 'TOUGHDOUT'\n",
            "  True: 'SAVE' | Pred: 'SAVE'\n",
            "  True: 'RIGHT' | Pred: 'RIGHT'\n",
            "  True: 'DENZEL' | Pred: 'DENZET'\n",
            "  True: 'HEIGHT' | Pred: 'HEIGHT'\n",
            "\n",
            "📈 Epoch 40/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.13it/s, loss=0.020, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 40 Summary:\n",
            "  Training Loss: 0.0569\n",
            "  Training Word Acc: 0.9195\n",
            "  Validation Word Acc: 0.6920\n",
            "  Validation Char Acc: 0.8055\n",
            "  Learning Rate: 0.000938\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BLOOM' | Pred: 'OBIOOM'\n",
            "  True: 'IN' | Pred: 'IN'\n",
            "  True: 'GRAHAMS' | Pred: 'CRAHOINTE'\n",
            "  True: 'BE' | Pred: 'BE'\n",
            "  True: 'TELL' | Pred: 'TELL'\n",
            "\n",
            "📈 Epoch 41/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.09it/s, loss=0.071, word_acc=0.850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 41 Summary:\n",
            "  Training Loss: 0.0446\n",
            "  Training Word Acc: 0.9187\n",
            "  Validation Word Acc: 0.7040\n",
            "  Validation Char Acc: 0.8033\n",
            "  Learning Rate: 0.000935\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'HOME' | Pred: 'HOME'\n",
            "  True: 'ACTRESS' | Pred: 'ACTRESS'\n",
            "  True: 'PITT' | Pred: 'PITT'\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "  True: 'LA' | Pred: 'L'\n",
            "\n",
            "📈 Epoch 42/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.14it/s, loss=0.092, word_acc=0.700]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 42 Summary:\n",
            "  Training Loss: 0.0547\n",
            "  Training Word Acc: 0.8883\n",
            "  Validation Word Acc: 0.7040\n",
            "  Validation Char Acc: 0.8138\n",
            "  Learning Rate: 0.000932\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'HOMICIDE' | Pred: 'HOMICIDE'\n",
            "  True: 'DOLLARS' | Pred: 'DELARS'\n",
            "  True: '25' | Pred: '25'\n",
            "  True: 'VALE' | Pred: 'VALE'\n",
            "  True: '4865' | Pred: '4365'\n",
            "\n",
            "📈 Epoch 43/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.96it/s, loss=0.126, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 43 Summary:\n",
            "  Training Loss: 0.0607\n",
            "  Training Word Acc: 0.9406\n",
            "  Validation Word Acc: 0.6940\n",
            "  Validation Char Acc: 0.8010\n",
            "  Learning Rate: 0.000929\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ASHTON' | Pred: 'ASHTON'\n",
            "  True: 'A' | Pred: 'A'\n",
            "  True: '95' | Pred: '95'\n",
            "  True: 'ACTRESS' | Pred: 'ACTRESS'\n",
            "  True: 'HOME' | Pred: 'HOME'\n",
            "\n",
            "📈 Epoch 44/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.27it/s, loss=0.018, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 44 Summary:\n",
            "  Training Loss: 0.0435\n",
            "  Training Word Acc: 0.9648\n",
            "  Validation Word Acc: 0.7160\n",
            "  Validation Char Acc: 0.8121\n",
            "  Learning Rate: 0.000925\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ON' | Pred: 'ON'\n",
            "  True: 'SLATE' | Pred: 'SLATE'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'TO' | Pred: 'TO'\n",
            "  True: 'HEIGHT' | Pred: 'HEIGHT'\n",
            "\n",
            "📈 Epoch 45/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.11it/s, loss=0.056, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 45 Summary:\n",
            "  Training Loss: 0.0380\n",
            "  Training Word Acc: 0.9289\n",
            "  Validation Word Acc: 0.7200\n",
            "  Validation Char Acc: 0.8205\n",
            "  Learning Rate: 0.000922\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'MCKINNEY' | Pred: 'MEKINNEY'\n",
            "  True: 'VALE' | Pred: 'VALE'\n",
            "  True: 'TOTAL' | Pred: 'TOTAL'\n",
            "  True: 'FRUIT' | Pred: 'FUIN'\n",
            "  True: 'SALMON' | Pred: 'CATLOS'\n",
            "\n",
            "📈 Epoch 46/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.19it/s, loss=0.029, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 46 Summary:\n",
            "  Training Loss: 0.0379\n",
            "  Training Word Acc: 0.9234\n",
            "  Validation Word Acc: 0.7120\n",
            "  Validation Char Acc: 0.8152\n",
            "  Learning Rate: 0.000919\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BLANKES' | Pred: 'BLANKES'\n",
            "  True: 'SAVE' | Pred: 'SAVE'\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "  True: 'MATRIX' | Pred: 'MATRIX'\n",
            "  True: 'HOUSE' | Pred: 'HIOUSE'\n",
            "\n",
            "📈 Epoch 47/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.89it/s, loss=0.068, word_acc=0.850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 47 Summary:\n",
            "  Training Loss: 0.0302\n",
            "  Training Word Acc: 0.9422\n",
            "  Validation Word Acc: 0.7460\n",
            "  Validation Char Acc: 0.8247\n",
            "  Learning Rate: 0.000915\n",
            "  ✅ New best model saved! Word Acc: 0.7460\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PHONE' | Pred: 'PHONE'\n",
            "  True: 'PET' | Pred: 'PET'\n",
            "  True: 'CHIC' | Pred: 'CHIC'\n",
            "  True: 'TERMINAL' | Pred: 'TERNNEL'\n",
            "  True: 'JUKEBOX' | Pred: 'JUKEBOX'\n",
            "\n",
            "📈 Epoch 48/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.45it/s, loss=0.068, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 48 Summary:\n",
            "  Training Loss: 0.0290\n",
            "  Training Word Acc: 0.9523\n",
            "  Validation Word Acc: 0.6980\n",
            "  Validation Char Acc: 0.8093\n",
            "  Learning Rate: 0.000912\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'IS' | Pred: 'IS'\n",
            "  True: 'CITROEN' | Pred: 'CITROEN'\n",
            "  True: 'INVERCARGILL' | Pred: 'INVEREARGIL'\n",
            "  True: '1989' | Pred: '1989'\n",
            "  True: 'THE' | Pred: 'TH'\n",
            "\n",
            "📈 Epoch 49/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.15it/s, loss=0.015, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 49 Summary:\n",
            "  Training Loss: 0.0561\n",
            "  Training Word Acc: 0.9297\n",
            "  Validation Word Acc: 0.6960\n",
            "  Validation Char Acc: 0.8114\n",
            "  Learning Rate: 0.000908\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BLOOM' | Pred: 'OBIOOM'\n",
            "  True: 'LOUIS' | Pred: 'LGLIIS'\n",
            "  True: 'REVERSE' | Pred: 'REVERSE'\n",
            "  True: '560' | Pred: '560'\n",
            "  True: 'WISHES' | Pred: 'WISHES'\n",
            "\n",
            "📈 Epoch 50/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.31it/s, loss=0.076, word_acc=0.800]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 50 Summary:\n",
            "  Training Loss: 0.0548\n",
            "  Training Word Acc: 0.9242\n",
            "  Validation Word Acc: 0.7060\n",
            "  Validation Char Acc: 0.8048\n",
            "  Learning Rate: 0.000905\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'STATE' | Pred: 'STATE'\n",
            "  True: 'PARKING' | Pred: 'PARKING'\n",
            "  True: 'MARILYN' | Pred: 'NARILYN'\n",
            "  True: 'FOR' | Pred: 'FOR'\n",
            "  True: 'INTO' | Pred: 'INTO'\n",
            "\n",
            "📈 Epoch 51/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 17.01it/s, loss=0.024, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 51 Summary:\n",
            "  Training Loss: 0.0449\n",
            "  Training Word Acc: 0.9547\n",
            "  Validation Word Acc: 0.7060\n",
            "  Validation Char Acc: 0.7990\n",
            "  Learning Rate: 0.000901\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'WISHES' | Pred: 'WISHES'\n",
            "  True: 'CFN' | Pred: 'CFN'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'CITY' | Pred: 'CITY'\n",
            "  True: 'MANCHURIAN' | Pred: 'IANICHURLAN'\n",
            "\n",
            "📈 Epoch 52/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.50it/s, loss=0.012, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 52 Summary:\n",
            "  Training Loss: 0.0353\n",
            "  Training Word Acc: 0.9492\n",
            "  Validation Word Acc: 0.6920\n",
            "  Validation Char Acc: 0.7969\n",
            "  Learning Rate: 0.000897\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'DOT' | Pred: 'DOT'\n",
            "  True: 'FEW' | Pred: 'FEW'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'TO' | Pred: 'TO'\n",
            "  True: 'ON' | Pred: 'ON'\n",
            "\n",
            "📈 Epoch 53/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.09it/s, loss=0.003, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 53 Summary:\n",
            "  Training Loss: 0.0249\n",
            "  Training Word Acc: 0.9648\n",
            "  Validation Word Acc: 0.7360\n",
            "  Validation Char Acc: 0.8249\n",
            "  Learning Rate: 0.000893\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ECO' | Pred: 'ECO'\n",
            "  True: 'AHEAD' | Pred: 'AHEAD'\n",
            "  True: 'REEVES' | Pred: 'REEVES'\n",
            "  True: 'HOMICIDE' | Pred: 'HOMICIDE'\n",
            "  True: 'DOLLARS' | Pred: 'DLLARS'\n",
            "\n",
            "📈 Epoch 54/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.27it/s, loss=0.055, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 54 Summary:\n",
            "  Training Loss: 0.0341\n",
            "  Training Word Acc: 0.9563\n",
            "  Validation Word Acc: 0.7000\n",
            "  Validation Char Acc: 0.8146\n",
            "  Learning Rate: 0.000889\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TOLL' | Pred: 'TOLL'\n",
            "  True: 'TIME' | Pred: 'TE'\n",
            "  True: 'ONLY' | Pred: 'ONLY'\n",
            "  True: 'DIVIDE' | Pred: 'DIVIDE'\n",
            "  True: 'AHEAD' | Pred: 'AHEAD'\n",
            "\n",
            "📈 Epoch 55/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.73it/s, loss=0.014, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 55 Summary:\n",
            "  Training Loss: 0.0395\n",
            "  Training Word Acc: 0.9313\n",
            "  Validation Word Acc: 0.6880\n",
            "  Validation Char Acc: 0.8032\n",
            "  Learning Rate: 0.000885\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'MASTERFILE' | Pred: 'TRIASSTERFILE'\n",
            "  True: 'HOMICIDE' | Pred: 'HOMICIDE'\n",
            "  True: 'YOUR' | Pred: 'YOUS'\n",
            "  True: 'IMAX' | Pred: 'INDAK'\n",
            "  True: 'BORDER' | Pred: 'BORDER'\n",
            "\n",
            "📈 Epoch 56/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.50it/s, loss=0.024, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 56 Summary:\n",
            "  Training Loss: 0.0332\n",
            "  Training Word Acc: 0.9742\n",
            "  Validation Word Acc: 0.7000\n",
            "  Validation Char Acc: 0.8226\n",
            "  Learning Rate: 0.000881\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'ISTANBUL' | Pred: 'ISTANBU'\n",
            "  True: 'ON' | Pred: 'ON'\n",
            "  True: 'YOU' | Pred: 'YOU'\n",
            "  True: 'EXPENDABLES' | Pred: 'EXRENOABLES'\n",
            "\n",
            "📈 Epoch 57/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:09<00:00, 14.95it/s, loss=0.004, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 57 Summary:\n",
            "  Training Loss: 0.0337\n",
            "  Training Word Acc: 0.9648\n",
            "  Validation Word Acc: 0.7220\n",
            "  Validation Char Acc: 0.8174\n",
            "  Learning Rate: 0.000877\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'VEER' | Pred: 'VEER'\n",
            "  True: 'KARI' | Pred: 'KAT'\n",
            "  True: 'FLAVOR' | Pred: 'FLAVO'\n",
            "  True: 'MASTERFILE' | Pred: 'TLASTERFILE'\n",
            "  True: 'AN' | Pred: 'AN'\n",
            "\n",
            "📈 Epoch 58/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.90it/s, loss=0.035, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 58 Summary:\n",
            "  Training Loss: 0.0225\n",
            "  Training Word Acc: 0.9586\n",
            "  Validation Word Acc: 0.7260\n",
            "  Validation Char Acc: 0.8240\n",
            "  Learning Rate: 0.000873\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'MOOD' | Pred: 'MOOD'\n",
            "  True: 'WISTERIA' | Pred: 'HETERA'\n",
            "  True: 'SWEET' | Pred: 'SNEEY'\n",
            "  True: 'CHANDIGARH' | Pred: 'CHANDIGARI'\n",
            "  True: 'MELIN' | Pred: 'MELIN'\n",
            "\n",
            "📈 Epoch 59/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.73it/s, loss=0.018, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 59 Summary:\n",
            "  Training Loss: 0.0221\n",
            "  Training Word Acc: 0.9703\n",
            "  Validation Word Acc: 0.7040\n",
            "  Validation Char Acc: 0.8162\n",
            "  Learning Rate: 0.000869\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PHONE' | Pred: 'PHONE'\n",
            "  True: 'BACK' | Pred: 'BACK'\n",
            "  True: 'JUKEBOX' | Pred: 'JUKEBOX'\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "  True: '3D' | Pred: '83'\n",
            "\n",
            "📈 Epoch 60/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.42it/s, loss=0.052, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 60 Summary:\n",
            "  Training Loss: 0.0255\n",
            "  Training Word Acc: 0.9602\n",
            "  Validation Word Acc: 0.6920\n",
            "  Validation Char Acc: 0.8046\n",
            "  Learning Rate: 0.000864\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'WITH' | Pred: 'WITH'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'DAY' | Pred: 'DAY'\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "  True: 'AND' | Pred: 'AND'\n",
            "\n",
            "📈 Epoch 61/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.92it/s, loss=0.007, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 61 Summary:\n",
            "  Training Loss: 0.0185\n",
            "  Training Word Acc: 0.9570\n",
            "  Validation Word Acc: 0.7120\n",
            "  Validation Char Acc: 0.8146\n",
            "  Learning Rate: 0.000860\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "  True: 'CAN' | Pred: 'CAN'\n",
            "  True: '208' | Pred: '208'\n",
            "  True: 'PULP' | Pred: 'PULP'\n",
            "  True: 'FOR' | Pred: 'FOR'\n",
            "\n",
            "📈 Epoch 62/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.85it/s, loss=0.039, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 62 Summary:\n",
            "  Training Loss: 0.0265\n",
            "  Training Word Acc: 0.9758\n",
            "  Validation Word Acc: 0.6940\n",
            "  Validation Char Acc: 0.7958\n",
            "  Learning Rate: 0.000856\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'NIN' | Pred: 'ILIIL'\n",
            "  True: 'TOUCHDOWN' | Pred: 'TDUGHDOWE'\n",
            "  True: 'AND' | Pred: 'AND'\n",
            "  True: 'NOVO' | Pred: 'NOVO'\n",
            "  True: 'NOSTOPPING' | Pred: 'NOSTOPPIN'\n",
            "\n",
            "📈 Epoch 63/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.32it/s, loss=0.044, word_acc=0.850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 63 Summary:\n",
            "  Training Loss: 0.0312\n",
            "  Training Word Acc: 0.9187\n",
            "  Validation Word Acc: 0.6860\n",
            "  Validation Char Acc: 0.8044\n",
            "  Learning Rate: 0.000851\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ALSO' | Pred: 'ALSO'\n",
            "  True: 'MASS' | Pred: 'MASS'\n",
            "  True: 'SHOP' | Pred: 'SLHOP'\n",
            "  True: 'NOW' | Pred: 'NO'\n",
            "  True: 'LOVE' | Pred: 'ZO'\n",
            "\n",
            "📈 Epoch 64/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.45it/s, loss=0.002, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 64 Summary:\n",
            "  Training Loss: 0.0262\n",
            "  Training Word Acc: 0.9727\n",
            "  Validation Word Acc: 0.7060\n",
            "  Validation Char Acc: 0.8016\n",
            "  Learning Rate: 0.000847\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CHIC' | Pred: 'CHIC'\n",
            "  True: 'VEGETARIAN' | Pred: 'UECATARLAN'\n",
            "  True: 'TAXI' | Pred: 'TAXI'\n",
            "  True: 'OLD' | Pred: 'OLD'\n",
            "  True: 'JULY' | Pred: 'JULY'\n",
            "\n",
            "📈 Epoch 65/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.96it/s, loss=0.042, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 65 Summary:\n",
            "  Training Loss: 0.0198\n",
            "  Training Word Acc: 0.9563\n",
            "  Validation Word Acc: 0.7140\n",
            "  Validation Char Acc: 0.8143\n",
            "  Learning Rate: 0.000842\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ATM' | Pred: 'ATM'\n",
            "  True: 'MELIN' | Pred: 'MELIN'\n",
            "  True: 'LOADING' | Pred: 'CEADING'\n",
            "  True: 'OLD' | Pred: 'OID'\n",
            "  True: 'CHECKMATE' | Pred: 'CHECKMATE'\n",
            "\n",
            "📈 Epoch 66/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.95it/s, loss=0.002, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 66 Summary:\n",
            "  Training Loss: 0.0167\n",
            "  Training Word Acc: 0.9922\n",
            "  Validation Word Acc: 0.7060\n",
            "  Validation Char Acc: 0.8109\n",
            "  Learning Rate: 0.000838\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'NEWS' | Pred: 'NEWS'\n",
            "  True: 'SURREY' | Pred: 'SUREY'\n",
            "  True: 'INDIAN' | Pred: 'INDIAN'\n",
            "  True: 'AN' | Pred: 'AN'\n",
            "  True: 'COM' | Pred: 'COM'\n",
            "\n",
            "📈 Epoch 67/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.99it/s, loss=0.018, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 67 Summary:\n",
            "  Training Loss: 0.0162\n",
            "  Training Word Acc: 0.9766\n",
            "  Validation Word Acc: 0.7020\n",
            "  Validation Char Acc: 0.8103\n",
            "  Learning Rate: 0.000833\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PHOENIX' | Pred: 'PHOENY'\n",
            "  True: 'YOU' | Pred: 'YOU'\n",
            "  True: 'YOU' | Pred: 'YOU'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "\n",
            "📈 Epoch 68/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.45it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 68 Summary:\n",
            "  Training Loss: 0.0245\n",
            "  Training Word Acc: 0.9883\n",
            "  Validation Word Acc: 0.6980\n",
            "  Validation Char Acc: 0.7998\n",
            "  Learning Rate: 0.000828\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'AS' | Pred: 'AS'\n",
            "  True: 'FUNNY' | Pred: 'FUNY'\n",
            "  True: 'MURDER' | Pred: 'MURDER'\n",
            "  True: 'UNIVERSITY' | Pred: 'UNVERSTY'\n",
            "  True: 'AND' | Pred: 'AND'\n",
            "\n",
            "📈 Epoch 69/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.79it/s, loss=0.023, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 69 Summary:\n",
            "  Training Loss: 0.0323\n",
            "  Training Word Acc: 0.9508\n",
            "  Validation Word Acc: 0.6920\n",
            "  Validation Char Acc: 0.8074\n",
            "  Learning Rate: 0.000824\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TOM' | Pred: 'TOA'\n",
            "  True: 'VALE' | Pred: 'VALE'\n",
            "  True: 'DREAM' | Pred: 'DREAM'\n",
            "  True: 'PACK' | Pred: 'PACK'\n",
            "  True: '02' | Pred: '02'\n",
            "\n",
            "📈 Epoch 70/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.80it/s, loss=0.006, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 70 Summary:\n",
            "  Training Loss: 0.0199\n",
            "  Training Word Acc: 0.9688\n",
            "  Validation Word Acc: 0.6980\n",
            "  Validation Char Acc: 0.8013\n",
            "  Learning Rate: 0.000819\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'WILT' | Pred: 'WILT'\n",
            "  True: 'HANDY' | Pred: 'HANDY'\n",
            "  True: 'DIAZ' | Pred: 'DIA2'\n",
            "  True: 'AS' | Pred: 'AS'\n",
            "  True: 'VISTA' | Pred: 'VISTA'\n",
            "\n",
            "📈 Epoch 71/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.89it/s, loss=0.016, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 71 Summary:\n",
            "  Training Loss: 0.0172\n",
            "  Training Word Acc: 0.9703\n",
            "  Validation Word Acc: 0.7120\n",
            "  Validation Char Acc: 0.8040\n",
            "  Learning Rate: 0.000814\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'DOT' | Pred: 'DOT'\n",
            "  True: 'JURASSIC' | Pred: 'JUIRASSIC'\n",
            "  True: 'YOUR' | Pred: 'YOUE'\n",
            "  True: 'MASTERFILE' | Pred: 'THIASTERFILE'\n",
            "  True: 'USER' | Pred: 'USER'\n",
            "\n",
            "📈 Epoch 72/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.48it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 72 Summary:\n",
            "  Training Loss: 0.0126\n",
            "  Training Word Acc: 0.9766\n",
            "  Validation Word Acc: 0.7200\n",
            "  Validation Char Acc: 0.8237\n",
            "  Learning Rate: 0.000809\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ECO' | Pred: 'ECO'\n",
            "  True: 'DOT' | Pred: 'DOT'\n",
            "  True: 'PHONE' | Pred: 'PHONE'\n",
            "  True: 'AHEAD' | Pred: 'AHEAD'\n",
            "  True: 'DANGERS' | Pred: 'DANGERS'\n",
            "\n",
            "📈 Epoch 73/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.16it/s, loss=0.069, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 73 Summary:\n",
            "  Training Loss: 0.0122\n",
            "  Training Word Acc: 0.9820\n",
            "  Validation Word Acc: 0.7260\n",
            "  Validation Char Acc: 0.8225\n",
            "  Learning Rate: 0.000804\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TAXI' | Pred: 'TAXL'\n",
            "  True: 'INDIAN' | Pred: 'INDIAN'\n",
            "  True: 'HEIGHT' | Pred: 'HEIGHT'\n",
            "  True: 'PARKING' | Pred: 'PARKING'\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "\n",
            "📈 Epoch 74/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.90it/s, loss=0.004, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 74 Summary:\n",
            "  Training Loss: 0.0063\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7500\n",
            "  Validation Char Acc: 0.8284\n",
            "  Learning Rate: 0.000799\n",
            "  ✅ New best model saved! Word Acc: 0.7500\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'DAY' | Pred: 'DAY'\n",
            "  True: 'DI' | Pred: 'DI'\n",
            "  True: 'TARKOWSKI' | Pred: 'TARKOWSK'\n",
            "  True: 'BE' | Pred: 'BE'\n",
            "  True: 'PRODAJA' | Pred: 'PRODAJA'\n",
            "\n",
            "📈 Epoch 75/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.77it/s, loss=0.007, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 75 Summary:\n",
            "  Training Loss: 0.0108\n",
            "  Training Word Acc: 0.9844\n",
            "  Validation Word Acc: 0.7180\n",
            "  Validation Char Acc: 0.8130\n",
            "  Learning Rate: 0.000794\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PARKING' | Pred: 'PARKING'\n",
            "  True: 'TRINITYLEEDS' | Pred: 'THMLYLFEIS'\n",
            "  True: 'NOW' | Pred: 'NOW'\n",
            "  True: 'ATM' | Pred: 'ATM'\n",
            "  True: 'FUTURE' | Pred: 'FUTURE'\n",
            "\n",
            "📈 Epoch 76/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.48it/s, loss=0.010, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 76 Summary:\n",
            "  Training Loss: 0.0072\n",
            "  Training Word Acc: 0.9820\n",
            "  Validation Word Acc: 0.7420\n",
            "  Validation Char Acc: 0.8135\n",
            "  Learning Rate: 0.000789\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SIGN' | Pred: 'SIGN'\n",
            "  True: 'BE' | Pred: '3E'\n",
            "  True: 'MATRIX' | Pred: 'MATRIX'\n",
            "  True: 'BOGART' | Pred: 'BOGART'\n",
            "  True: 'BANK' | Pred: 'BANK'\n",
            "\n",
            "📈 Epoch 77/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.53it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 77 Summary:\n",
            "  Training Loss: 0.0149\n",
            "  Training Word Acc: 0.9609\n",
            "  Validation Word Acc: 0.7120\n",
            "  Validation Char Acc: 0.8113\n",
            "  Learning Rate: 0.000784\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'DIRECTION' | Pred: 'DIRECTION'\n",
            "  True: 'STORES' | Pred: 'STORES'\n",
            "  True: 'SHIZUOKA' | Pred: 'SHIZUOKA'\n",
            "  True: 'JULY' | Pred: 'JULY'\n",
            "  True: '280' | Pred: '280'\n",
            "\n",
            "📈 Epoch 78/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.12it/s, loss=0.078, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 78 Summary:\n",
            "  Training Loss: 0.0347\n",
            "  Training Word Acc: 0.9602\n",
            "  Validation Word Acc: 0.7000\n",
            "  Validation Char Acc: 0.8114\n",
            "  Learning Rate: 0.000778\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'THINK' | Pred: 'THIN'\n",
            "  True: 'SPACE' | Pred: 'SPACE'\n",
            "  True: 'DAY' | Pred: 'DAY'\n",
            "  True: 'STORES' | Pred: 'STORES'\n",
            "  True: 'FIRE' | Pred: 'FIRE'\n",
            "\n",
            "📈 Epoch 79/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.08it/s, loss=0.024, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 79 Summary:\n",
            "  Training Loss: 0.0247\n",
            "  Training Word Acc: 0.9625\n",
            "  Validation Word Acc: 0.7140\n",
            "  Validation Char Acc: 0.8206\n",
            "  Learning Rate: 0.000773\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '19' | Pred: '10'\n",
            "  True: 'OLD' | Pred: 'OLD'\n",
            "  True: 'ANSON' | Pred: 'ANSON'\n",
            "  True: '212' | Pred: '212'\n",
            "  True: 'COLBY' | Pred: 'COLBY'\n",
            "\n",
            "📈 Epoch 80/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.52it/s, loss=0.062, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 80 Summary:\n",
            "  Training Loss: 0.0174\n",
            "  Training Word Acc: 0.9445\n",
            "  Validation Word Acc: 0.7120\n",
            "  Validation Char Acc: 0.8147\n",
            "  Learning Rate: 0.000768\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'JULY' | Pred: 'JUNY'\n",
            "  True: 'COM' | Pred: 'COM'\n",
            "  True: 'SURVEY' | Pred: 'SURVEY'\n",
            "  True: 'JACKASS' | Pred: 'IACKASS'\n",
            "  True: 'YOURE' | Pred: 'YOURE'\n",
            "\n",
            "📈 Epoch 81/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.71it/s, loss=0.002, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 81 Summary:\n",
            "  Training Loss: 0.0124\n",
            "  Training Word Acc: 0.9805\n",
            "  Validation Word Acc: 0.7440\n",
            "  Validation Char Acc: 0.8333\n",
            "  Learning Rate: 0.000763\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'COTTAGE' | Pred: 'COTTAGE'\n",
            "  True: 'COLBY' | Pred: 'COLBY'\n",
            "  True: 'LOADING' | Pred: 'DADING'\n",
            "  True: 'ONLINE' | Pred: 'ONLINE'\n",
            "  True: '22' | Pred: '28'\n",
            "\n",
            "📈 Epoch 82/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:09<00:00, 15.20it/s, loss=0.003, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 82 Summary:\n",
            "  Training Loss: 0.0140\n",
            "  Training Word Acc: 0.9844\n",
            "  Validation Word Acc: 0.7100\n",
            "  Validation Char Acc: 0.8262\n",
            "  Learning Rate: 0.000757\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'VISTA' | Pred: 'VISTA'\n",
            "  True: '01922' | Pred: '01922'\n",
            "  True: 'ALERT' | Pred: 'ALERT'\n",
            "  True: 'STATE' | Pred: 'STATE'\n",
            "  True: 'SALT' | Pred: 'SALT'\n",
            "\n",
            "📈 Epoch 83/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.03it/s, loss=0.003, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 83 Summary:\n",
            "  Training Loss: 0.0113\n",
            "  Training Word Acc: 0.9883\n",
            "  Validation Word Acc: 0.7240\n",
            "  Validation Char Acc: 0.8245\n",
            "  Learning Rate: 0.000752\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SCHEMES' | Pred: 'SCHEMES'\n",
            "  True: 'SHOP' | Pred: 'SHOP'\n",
            "  True: 'AN' | Pred: 'AN'\n",
            "  True: 'INDIAN' | Pred: 'INDIAN'\n",
            "  True: 'UNE' | Pred: 'UNE'\n",
            "\n",
            "📈 Epoch 84/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.30it/s, loss=0.012, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 84 Summary:\n",
            "  Training Loss: 0.0094\n",
            "  Training Word Acc: 0.9781\n",
            "  Validation Word Acc: 0.6980\n",
            "  Validation Char Acc: 0.8202\n",
            "  Learning Rate: 0.000746\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'THIS' | Pred: 'THIS'\n",
            "  True: 'TELL' | Pred: 'TEIL'\n",
            "  True: 'NOSTOPPING' | Pred: 'NOSTOPPINO'\n",
            "  True: 'CARING' | Pred: 'CARING'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "\n",
            "📈 Epoch 85/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.99it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 85 Summary:\n",
            "  Training Loss: 0.0097\n",
            "  Training Word Acc: 0.9922\n",
            "  Validation Word Acc: 0.7400\n",
            "  Validation Char Acc: 0.8285\n",
            "  Learning Rate: 0.000741\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SCHEMES' | Pred: 'SCHEMES'\n",
            "  True: 'CITY' | Pred: 'CITY'\n",
            "  True: 'CALL' | Pred: 'CALL'\n",
            "  True: 'RESET' | Pred: 'RESET'\n",
            "  True: 'SAW' | Pred: 'SAW'\n",
            "\n",
            "📈 Epoch 86/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.22it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 86 Summary:\n",
            "  Training Loss: 0.0072\n",
            "  Training Word Acc: 0.9844\n",
            "  Validation Word Acc: 0.7280\n",
            "  Validation Char Acc: 0.8162\n",
            "  Learning Rate: 0.000735\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'INDIAN' | Pred: 'INDIAN'\n",
            "  True: 'COM' | Pred: 'COM'\n",
            "  True: 'NEWS' | Pred: 'NEWS'\n",
            "  True: 'FOSTER' | Pred: 'FOSTER'\n",
            "  True: 'PRODAJA' | Pred: 'PRODAJA'\n",
            "\n",
            "📈 Epoch 87/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.06it/s, loss=0.022, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 87 Summary:\n",
            "  Training Loss: 0.0243\n",
            "  Training Word Acc: 0.9664\n",
            "  Validation Word Acc: 0.7100\n",
            "  Validation Char Acc: 0.8083\n",
            "  Learning Rate: 0.000730\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'EASTWOOD' | Pred: 'EASTHOOD'\n",
            "  True: 'PENANG' | Pred: 'PENANG'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'IS' | Pred: 'IS'\n",
            "  True: 'CUSTOMERS' | Pred: 'CISTOMIERS'\n",
            "\n",
            "📈 Epoch 88/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.15it/s, loss=0.007, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 88 Summary:\n",
            "  Training Loss: 0.0207\n",
            "  Training Word Acc: 0.9727\n",
            "  Validation Word Acc: 0.7320\n",
            "  Validation Char Acc: 0.8174\n",
            "  Learning Rate: 0.000724\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'GERARO' | Pred: 'GEHPVNM'\n",
            "  True: 'EXIT' | Pred: 'EXIT'\n",
            "  True: 'LOADING' | Pred: 'LAING'\n",
            "  True: '1989' | Pred: '1989'\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "\n",
            "📈 Epoch 89/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.88it/s, loss=0.010, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 89 Summary:\n",
            "  Training Loss: 0.0115\n",
            "  Training Word Acc: 0.9883\n",
            "  Validation Word Acc: 0.7240\n",
            "  Validation Char Acc: 0.8322\n",
            "  Learning Rate: 0.000719\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '2' | Pred: '2'\n",
            "  True: 'RD' | Pred: 'RD'\n",
            "  True: 'IN' | Pred: 'IN'\n",
            "  True: 'JONES' | Pred: 'JONES'\n",
            "  True: 'CANDIDATE' | Pred: 'CANDIOATE'\n",
            "\n",
            "📈 Epoch 90/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.08it/s, loss=0.002, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 90 Summary:\n",
            "  Training Loss: 0.0182\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7220\n",
            "  Validation Char Acc: 0.8283\n",
            "  Learning Rate: 0.000713\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'AN' | Pred: 'AN'\n",
            "  True: 'THAT' | Pred: 'THAT'\n",
            "  True: 'PULP' | Pred: 'PULP'\n",
            "  True: 'TRINITYLEEDS' | Pred: 'TUMTYLECRIS'\n",
            "  True: 'JOSHUA' | Pred: 'JOSHUA'\n",
            "\n",
            "📈 Epoch 91/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.10it/s, loss=0.023, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 91 Summary:\n",
            "  Training Loss: 0.0089\n",
            "  Training Word Acc: 0.9898\n",
            "  Validation Word Acc: 0.7160\n",
            "  Validation Char Acc: 0.8169\n",
            "  Learning Rate: 0.000707\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'YOU' | Pred: 'YOU'\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "  True: 'INDIASBIN' | Pred: 'INDTAISBIN'\n",
            "  True: 'MOTION' | Pred: 'MOTION'\n",
            "  True: '1800BUYKWIK' | Pred: 'HOBBUYTWIK'\n",
            "\n",
            "📈 Epoch 92/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.01it/s, loss=0.032, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 92 Summary:\n",
            "  Training Loss: 0.0107\n",
            "  Training Word Acc: 0.9820\n",
            "  Validation Word Acc: 0.7180\n",
            "  Validation Char Acc: 0.8203\n",
            "  Learning Rate: 0.000701\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'WINSLET' | Pred: 'WINSLET'\n",
            "  True: 'JACKASS' | Pred: 'IACKASS'\n",
            "  True: 'BOARD' | Pred: 'BOARD'\n",
            "  True: 'HOMICIDE' | Pred: 'HOMICIDE'\n",
            "  True: 'ATMOSPHERE' | Pred: 'AVWGEPNER'\n",
            "\n",
            "📈 Epoch 93/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.82it/s, loss=0.007, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 93 Summary:\n",
            "  Training Loss: 0.0087\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7240\n",
            "  Validation Char Acc: 0.8143\n",
            "  Learning Rate: 0.000696\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'COM' | Pred: 'COM'\n",
            "  True: '4865' | Pred: '4365'\n",
            "  True: 'TELL' | Pred: 'TEIL'\n",
            "  True: 'DRIVE' | Pred: 'DRIAE'\n",
            "  True: 'SWEET' | Pred: 'SWEEY'\n",
            "\n",
            "📈 Epoch 94/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.95it/s, loss=0.057, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 94 Summary:\n",
            "  Training Loss: 0.0101\n",
            "  Training Word Acc: 0.9469\n",
            "  Validation Word Acc: 0.7380\n",
            "  Validation Char Acc: 0.8199\n",
            "  Learning Rate: 0.000690\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'WISHES' | Pred: 'WISHES'\n",
            "  True: 'FIRE' | Pred: 'FIRE'\n",
            "  True: 'HEFNER' | Pred: 'HEFNER'\n",
            "  True: '7' | Pred: '7'\n",
            "  True: 'DAY' | Pred: 'LZCH'\n",
            "\n",
            "📈 Epoch 95/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.09it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 95 Summary:\n",
            "  Training Loss: 0.0075\n",
            "  Training Word Acc: 0.9844\n",
            "  Validation Word Acc: 0.7200\n",
            "  Validation Char Acc: 0.8222\n",
            "  Learning Rate: 0.000684\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'WE' | Pred: 'WE'\n",
            "  True: 'TAKE' | Pred: 'TAKE'\n",
            "  True: 'DAY' | Pred: '1ZH'\n",
            "  True: '50' | Pred: '50'\n",
            "  True: 'HOUSE' | Pred: 'HOLSE'\n",
            "\n",
            "📈 Epoch 96/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.03it/s, loss=0.010, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 96 Summary:\n",
            "  Training Loss: 0.0074\n",
            "  Training Word Acc: 0.9898\n",
            "  Validation Word Acc: 0.7520\n",
            "  Validation Char Acc: 0.8374\n",
            "  Learning Rate: 0.000678\n",
            "  ✅ New best model saved! Word Acc: 0.7520\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TEXT' | Pred: 'TEXT'\n",
            "  True: 'TWITTERCOMAPLUSK' | Pred: 'MTECOMLEPUIST'\n",
            "  True: 'SURREY' | Pred: 'SUREY'\n",
            "  True: 'GREM' | Pred: 'GREM'\n",
            "  True: 'ISTANBUL' | Pred: 'ISTANBUL'\n",
            "\n",
            "📈 Epoch 97/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.72it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 97 Summary:\n",
            "  Training Loss: 0.0056\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8389\n",
            "  Learning Rate: 0.000672\n",
            "  ✅ New best model saved! Word Acc: 0.7540\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '50' | Pred: '50'\n",
            "  True: 'BUY' | Pred: 'BIY'\n",
            "  True: 'ABOUT' | Pred: 'ABOUT'\n",
            "  True: '60' | Pred: '60'\n",
            "  True: 'CANDIDATE' | Pred: 'CANDIDATE'\n",
            "\n",
            "📈 Epoch 98/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.09it/s, loss=0.002, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 98 Summary:\n",
            "  Training Loss: 0.0038\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7340\n",
            "  Validation Char Acc: 0.8312\n",
            "  Learning Rate: 0.000666\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PACK' | Pred: 'PACK'\n",
            "  True: 'CRITICS' | Pred: 'CRITICS'\n",
            "  True: 'AS' | Pred: 'AS'\n",
            "  True: '02' | Pred: '02'\n",
            "  True: 'HANDY' | Pred: 'HAND'\n",
            "\n",
            "📈 Epoch 99/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.79it/s, loss=0.002, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 99 Summary:\n",
            "  Training Loss: 0.0054\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7240\n",
            "  Validation Char Acc: 0.8168\n",
            "  Learning Rate: 0.000660\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'FRUIT' | Pred: 'FUTIT'\n",
            "  True: 'INDIA' | Pred: 'IDIA'\n",
            "  True: '1800GOGEICO' | Pred: '30DGDGECO'\n",
            "  True: 'PRICES' | Pred: 'PRICES'\n",
            "  True: 'DI' | Pred: 'DI'\n",
            "\n",
            "📈 Epoch 100/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.98it/s, loss=0.026, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 100 Summary:\n",
            "  Training Loss: 0.0144\n",
            "  Training Word Acc: 0.9758\n",
            "  Validation Word Acc: 0.7100\n",
            "  Validation Char Acc: 0.8137\n",
            "  Learning Rate: 0.000655\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ISTANBUL' | Pred: 'ISTANGUL'\n",
            "  True: 'WITH' | Pred: 'WITH'\n",
            "  True: 'FOTOLIA' | Pred: 'TOTOLA'\n",
            "  True: 'SANTOMIC' | Pred: 'SANTOMIC'\n",
            "  True: 'MOOD' | Pred: 'MOOD'\n",
            "\n",
            "📈 Epoch 101/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.42it/s, loss=0.005, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 101 Summary:\n",
            "  Training Loss: 0.0243\n",
            "  Training Word Acc: 0.9805\n",
            "  Validation Word Acc: 0.7340\n",
            "  Validation Char Acc: 0.8209\n",
            "  Learning Rate: 0.000649\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'JUKEBOX' | Pred: 'JUKEBOX'\n",
            "  True: 'PITT' | Pred: 'PITT'\n",
            "  True: 'TIMES' | Pred: 'TIMES'\n",
            "  True: 'MATRIX' | Pred: 'MATRIX'\n",
            "  True: 'WISHES' | Pred: 'WISHES'\n",
            "\n",
            "📈 Epoch 102/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.35it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 102 Summary:\n",
            "  Training Loss: 0.0149\n",
            "  Training Word Acc: 0.9609\n",
            "  Validation Word Acc: 0.7460\n",
            "  Validation Char Acc: 0.8225\n",
            "  Learning Rate: 0.000643\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SAW' | Pred: 'SALL'\n",
            "  True: 'RIKHYS' | Pred: 'MKMN'\n",
            "  True: 'DIRECTION' | Pred: 'DIRECTION'\n",
            "  True: 'NURSERY' | Pred: 'SORSRER'\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "\n",
            "📈 Epoch 103/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.97it/s, loss=0.002, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 103 Summary:\n",
            "  Training Loss: 0.0076\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7260\n",
            "  Validation Char Acc: 0.8212\n",
            "  Learning Rate: 0.000636\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'COTTAGE' | Pred: 'COTIAGE'\n",
            "  True: '7' | Pred: '7'\n",
            "  True: 'HENREID' | Pred: 'HENREID'\n",
            "  True: 'VIEWERS' | Pred: 'VIEWERS'\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "\n",
            "📈 Epoch 104/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.87it/s, loss=0.010, word_acc=0.900]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 104 Summary:\n",
            "  Training Loss: 0.0048\n",
            "  Training Word Acc: 0.9797\n",
            "  Validation Word Acc: 0.7240\n",
            "  Validation Char Acc: 0.8202\n",
            "  Learning Rate: 0.000630\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'GLOBAL' | Pred: 'GLOBAL'\n",
            "  True: 'JURASSIC' | Pred: 'JURAGSIC'\n",
            "  True: 'NOVEMBER' | Pred: 'NOVEMBER'\n",
            "  True: 'SQUIRRELS' | Pred: 'FOLUNRRPAE'\n",
            "  True: 'TOM' | Pred: 'TO'\n",
            "\n",
            "📈 Epoch 105/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.95it/s, loss=0.002, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 105 Summary:\n",
            "  Training Loss: 0.0110\n",
            "  Training Word Acc: 0.9883\n",
            "  Validation Word Acc: 0.7100\n",
            "  Validation Char Acc: 0.8279\n",
            "  Learning Rate: 0.000624\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TITANS' | Pred: 'TITANS'\n",
            "  True: 'DAY' | Pred: 'DAY'\n",
            "  True: 'SHOESTRING' | Pred: 'HLOWOTREE'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'OLD' | Pred: 'OTLO'\n",
            "\n",
            "📈 Epoch 106/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.64it/s, loss=0.007, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 106 Summary:\n",
            "  Training Loss: 0.0089\n",
            "  Training Word Acc: 0.9781\n",
            "  Validation Word Acc: 0.7320\n",
            "  Validation Char Acc: 0.8173\n",
            "  Learning Rate: 0.000618\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PHOENIX' | Pred: 'PHOENX'\n",
            "  True: 'COLOURS' | Pred: 'COLARS'\n",
            "  True: 'ANSON' | Pred: 'ANSON'\n",
            "  True: 'HEIGHT' | Pred: 'HEIGHT'\n",
            "  True: 'BANK' | Pred: 'BANE'\n",
            "\n",
            "📈 Epoch 107/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:09<00:00, 15.00it/s, loss=0.006, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 107 Summary:\n",
            "  Training Loss: 0.0077\n",
            "  Training Word Acc: 0.9922\n",
            "  Validation Word Acc: 0.7500\n",
            "  Validation Char Acc: 0.8311\n",
            "  Learning Rate: 0.000612\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'DANGERS' | Pred: 'DANGERS'\n",
            "  True: '63' | Pred: '63'\n",
            "  True: 'NEW' | Pred: 'NEW'\n",
            "  True: 'TAKE' | Pred: 'TAKE'\n",
            "  True: 'WORTHINGTON' | Pred: 'IEEILIIETLL'\n",
            "\n",
            "📈 Epoch 108/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:09<00:00, 15.67it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 108 Summary:\n",
            "  Training Loss: 0.0043\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8329\n",
            "  Learning Rate: 0.000606\n",
            "  ✅ New best model saved! Word Acc: 0.7580\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'RESIST' | Pred: 'HESIST'\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "  True: 'WITH' | Pred: 'WITH'\n",
            "  True: 'A' | Pred: 'A'\n",
            "  True: 'ROUTH' | Pred: 'ROUTH'\n",
            "\n",
            "📈 Epoch 109/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.04it/s, loss=0.002, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 109 Summary:\n",
            "  Training Loss: 0.0064\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7360\n",
            "  Validation Char Acc: 0.8262\n",
            "  Learning Rate: 0.000600\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '212' | Pred: '212'\n",
            "  True: 'COUNTRY' | Pred: 'COUNTRY'\n",
            "  True: '02' | Pred: '02'\n",
            "  True: 'ANGELS' | Pred: 'ANGELS'\n",
            "  True: 'NOSTOPPING' | Pred: 'NOSTOPPING'\n",
            "\n",
            "📈 Epoch 110/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.79it/s, loss=0.006, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 110 Summary:\n",
            "  Training Loss: 0.0106\n",
            "  Training Word Acc: 0.9883\n",
            "  Validation Word Acc: 0.7240\n",
            "  Validation Char Acc: 0.8234\n",
            "  Learning Rate: 0.000594\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'EXIT' | Pred: 'EXIT'\n",
            "  True: 'THE' | Pred: 'THO'\n",
            "  True: 'NAME' | Pred: 'NAME'\n",
            "  True: 'AND' | Pred: 'AND'\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "\n",
            "📈 Epoch 111/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.98it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 111 Summary:\n",
            "  Training Loss: 0.0071\n",
            "  Training Word Acc: 0.9883\n",
            "  Validation Word Acc: 0.7320\n",
            "  Validation Char Acc: 0.8404\n",
            "  Learning Rate: 0.000588\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'COTTAGE' | Pred: 'COTTAGE'\n",
            "  True: 'HITAM' | Pred: 'HITAM'\n",
            "  True: 'STATION' | Pred: 'STATION'\n",
            "  True: '63' | Pred: '63'\n",
            "  True: 'GO' | Pred: 'GO'\n",
            "\n",
            "📈 Epoch 112/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.98it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 112 Summary:\n",
            "  Training Loss: 0.0063\n",
            "  Training Word Acc: 0.9883\n",
            "  Validation Word Acc: 0.7320\n",
            "  Validation Char Acc: 0.8414\n",
            "  Learning Rate: 0.000581\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'A' | Pred: 'A'\n",
            "  True: 'RESET' | Pred: 'RESET'\n",
            "  True: 'TWILIGHT' | Pred: 'TWILIGHT'\n",
            "  True: 'HENREID' | Pred: 'HENREID'\n",
            "  True: 'HOURS' | Pred: 'HOURS'\n",
            "\n",
            "📈 Epoch 113/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.88it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 113 Summary:\n",
            "  Training Loss: 0.0057\n",
            "  Training Word Acc: 0.9883\n",
            "  Validation Word Acc: 0.7460\n",
            "  Validation Char Acc: 0.8425\n",
            "  Learning Rate: 0.000575\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'OFFICE' | Pred: 'OFFICE'\n",
            "  True: 'RD' | Pred: 'RD'\n",
            "  True: 'TAKE' | Pred: 'TAKE'\n",
            "  True: 'INVERCARGILL' | Pred: 'INVEREARGIL'\n",
            "  True: 'HELT' | Pred: 'HELT'\n",
            "\n",
            "📈 Epoch 114/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.82it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 114 Summary:\n",
            "  Training Loss: 0.0035\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7380\n",
            "  Validation Char Acc: 0.8356\n",
            "  Learning Rate: 0.000569\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TELL' | Pred: 'TEIL'\n",
            "  True: 'ONLY' | Pred: 'ONLY'\n",
            "  True: 'LOW' | Pred: 'LOW'\n",
            "  True: 'LOSE' | Pred: 'ZOSE'\n",
            "  True: 'SALT' | Pred: 'SALT'\n",
            "\n",
            "📈 Epoch 115/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.60it/s, loss=0.014, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 115 Summary:\n",
            "  Training Loss: 0.0076\n",
            "  Training Word Acc: 0.9898\n",
            "  Validation Word Acc: 0.7360\n",
            "  Validation Char Acc: 0.8358\n",
            "  Learning Rate: 0.000563\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'IN' | Pred: 'IN'\n",
            "  True: 'EXIT' | Pred: 'EXIT'\n",
            "  True: 'INDIA' | Pred: 'MNAIA'\n",
            "  True: 'WELCOME' | Pred: 'WELCOME'\n",
            "  True: 'BANKNORTH' | Pred: 'BANKNORIH'\n",
            "\n",
            "📈 Epoch 116/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.19it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 116 Summary:\n",
            "  Training Loss: 0.0075\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7340\n",
            "  Validation Char Acc: 0.8324\n",
            "  Learning Rate: 0.000556\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BUY' | Pred: 'BIY'\n",
            "  True: 'GLOBAL' | Pred: 'GLOBAL'\n",
            "  True: 'NOT' | Pred: 'NOT'\n",
            "  True: 'EVERY' | Pred: 'EVEY'\n",
            "  True: '24' | Pred: '24'\n",
            "\n",
            "📈 Epoch 117/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.16it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 117 Summary:\n",
            "  Training Loss: 0.0086\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7400\n",
            "  Validation Char Acc: 0.8315\n",
            "  Learning Rate: 0.000550\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BLUBBER' | Pred: 'BLUBBER'\n",
            "  True: 'ADOPTION' | Pred: 'ADOPTION'\n",
            "  True: 'ANGELS' | Pred: 'ANGELS'\n",
            "  True: 'ONLY' | Pred: 'ONLY'\n",
            "  True: 'NOW' | Pred: 'NOW'\n",
            "\n",
            "📈 Epoch 118/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.60it/s, loss=0.021, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 118 Summary:\n",
            "  Training Loss: 0.0069\n",
            "  Training Word Acc: 0.9898\n",
            "  Validation Word Acc: 0.7440\n",
            "  Validation Char Acc: 0.8366\n",
            "  Learning Rate: 0.000544\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'EXIT' | Pred: 'EXIT'\n",
            "  True: 'STATE' | Pred: 'STATE'\n",
            "  True: 'QUEENSWAY' | Pred: 'CUEENSWOY'\n",
            "  True: 'COM' | Pred: 'COM'\n",
            "  True: 'HANDY' | Pred: 'HANDY'\n",
            "\n",
            "📈 Epoch 119/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.60it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 119 Summary:\n",
            "  Training Loss: 0.0097\n",
            "  Training Word Acc: 0.9883\n",
            "  Validation Word Acc: 0.7260\n",
            "  Validation Char Acc: 0.8223\n",
            "  Learning Rate: 0.000538\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'THEYRE' | Pred: 'THEYRE'\n",
            "  True: 'JUKEBOX' | Pred: 'JUKEBOX'\n",
            "  True: '120' | Pred: '1730'\n",
            "  True: '212' | Pred: '212'\n",
            "  True: 'HOMICIDE' | Pred: 'HOMICIDE'\n",
            "\n",
            "📈 Epoch 120/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.99it/s, loss=0.004, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 120 Summary:\n",
            "  Training Loss: 0.0073\n",
            "  Training Word Acc: 0.9844\n",
            "  Validation Word Acc: 0.7260\n",
            "  Validation Char Acc: 0.8308\n",
            "  Learning Rate: 0.000531\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SPACE' | Pred: 'SPACE'\n",
            "  True: 'SAJITH' | Pred: 'SAJITH'\n",
            "  True: 'LOVE' | Pred: 'DO'\n",
            "  True: 'THINK' | Pred: 'THINK'\n",
            "  True: 'STORY' | Pred: 'STORY'\n",
            "\n",
            "📈 Epoch 121/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.09it/s, loss=0.029, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 121 Summary:\n",
            "  Training Loss: 0.0041\n",
            "  Training Word Acc: 0.9859\n",
            "  Validation Word Acc: 0.7300\n",
            "  Validation Char Acc: 0.8317\n",
            "  Learning Rate: 0.000525\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'MURDER' | Pred: 'MLRDER'\n",
            "  True: 'YOU' | Pred: 'YOU'\n",
            "  True: 'JALAN' | Pred: 'JALAN'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'DENZEL' | Pred: 'DENZEL'\n",
            "\n",
            "📈 Epoch 122/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.61it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 122 Summary:\n",
            "  Training Loss: 0.0021\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7380\n",
            "  Validation Char Acc: 0.8267\n",
            "  Learning Rate: 0.000519\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BLOOM' | Pred: 'OBIODON'\n",
            "  True: 'CUSTOMERS' | Pred: 'CISTOMMERS'\n",
            "  True: 'ROUTH' | Pred: 'POUTH'\n",
            "  True: 'CURRENCY' | Pred: 'CRREREY'\n",
            "  True: 'ANSON' | Pred: 'ANSON'\n",
            "\n",
            "📈 Epoch 123/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.74it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 123 Summary:\n",
            "  Training Loss: 0.0012\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7380\n",
            "  Validation Char Acc: 0.8321\n",
            "  Learning Rate: 0.000513\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'IMAIZUMI' | Pred: 'WGLUMI'\n",
            "  True: 'STICKY' | Pred: 'STUGSY'\n",
            "  True: '208' | Pred: '208'\n",
            "  True: 'ANSON' | Pred: 'ANSON'\n",
            "  True: 'ON' | Pred: 'ON'\n",
            "\n",
            "📈 Epoch 124/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.19it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 124 Summary:\n",
            "  Training Loss: 0.0008\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7400\n",
            "  Validation Char Acc: 0.8334\n",
            "  Learning Rate: 0.000506\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'LA' | Pred: 'T'\n",
            "  True: 'REVERSE' | Pred: 'REVERSE'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'SALT' | Pred: 'SALT'\n",
            "  True: 'WINSLET' | Pred: 'WINSLET'\n",
            "\n",
            "📈 Epoch 125/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.14it/s, loss=0.003, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 125 Summary:\n",
            "  Training Loss: 0.0007\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7400\n",
            "  Validation Char Acc: 0.8391\n",
            "  Learning Rate: 0.000500\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "  True: 'ALERT' | Pred: 'ALERT'\n",
            "  True: 'HOMICIDE' | Pred: 'HOMICIDE'\n",
            "  True: 'BANK' | Pred: 'BANK'\n",
            "  True: 'THE' | Pred: 'THO'\n",
            "\n",
            "📈 Epoch 126/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.41it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 126 Summary:\n",
            "  Training Loss: 0.0006\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7440\n",
            "  Validation Char Acc: 0.8410\n",
            "  Learning Rate: 0.000494\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'A' | Pred: 'A'\n",
            "  True: '24' | Pred: '24'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'SURVEY' | Pred: 'SURVEY'\n",
            "  True: 'BADGES' | Pred: 'BADGES'\n",
            "\n",
            "📈 Epoch 127/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 17.01it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 127 Summary:\n",
            "  Training Loss: 0.0006\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7500\n",
            "  Validation Char Acc: 0.8337\n",
            "  Learning Rate: 0.000487\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '280' | Pred: '280'\n",
            "  True: 'COLOURS' | Pred: 'COLONRS'\n",
            "  True: 'HOME' | Pred: 'SOME'\n",
            "  True: 'TERRACE' | Pred: 'TERRACE'\n",
            "  True: 'TAXI' | Pred: 'TAXL'\n",
            "\n",
            "📈 Epoch 128/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.27it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 128 Summary:\n",
            "  Training Loss: 0.0007\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8431\n",
            "  Learning Rate: 0.000481\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "  True: 'VIEW' | Pred: 'VIEW'\n",
            "  True: 'DIRECTION' | Pred: 'DIRECTION'\n",
            "  True: 'VEGETARIAN' | Pred: 'UECSTARIAN'\n",
            "  True: 'GASES' | Pred: 'GASES'\n",
            "\n",
            "📈 Epoch 129/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.13it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 129 Summary:\n",
            "  Training Loss: 0.0011\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7480\n",
            "  Validation Char Acc: 0.8307\n",
            "  Learning Rate: 0.000475\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BPL' | Pred: 'BPL'\n",
            "  True: 'JUBILEE' | Pred: 'JUBILEE'\n",
            "  True: 'WISTERIA' | Pred: 'HCTRRA'\n",
            "  True: 'METER' | Pred: 'METER'\n",
            "  True: '2' | Pred: 'A'\n",
            "\n",
            "📈 Epoch 130/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.37it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 130 Summary:\n",
            "  Training Loss: 0.0008\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7320\n",
            "  Validation Char Acc: 0.8391\n",
            "  Learning Rate: 0.000469\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BLUBBER' | Pred: 'BLUBBER'\n",
            "  True: 'BLOOM' | Pred: 'OBIOON'\n",
            "  True: 'VIJAYAWADA' | Pred: 'VAAWON'\n",
            "  True: 'THINK' | Pred: 'THINK'\n",
            "  True: 'FAILTE' | Pred: 'TAILTE'\n",
            "\n",
            "📈 Epoch 131/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.80it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 131 Summary:\n",
            "  Training Loss: 0.0077\n",
            "  Training Word Acc: 0.9922\n",
            "  Validation Word Acc: 0.7140\n",
            "  Validation Char Acc: 0.8125\n",
            "  Learning Rate: 0.000462\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'WASHINGTON' | Pred: 'WASHINGION'\n",
            "  True: 'ASIA' | Pred: 'ASIA'\n",
            "  True: 'MIRREN' | Pred: 'MIRREN'\n",
            "  True: '3D' | Pred: 'BR'\n",
            "  True: 'BANKNORTH' | Pred: 'BANKNORIH'\n",
            "\n",
            "📈 Epoch 132/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:09<00:00, 15.19it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 132 Summary:\n",
            "  Training Loss: 0.0099\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7060\n",
            "  Validation Char Acc: 0.8078\n",
            "  Learning Rate: 0.000456\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'LEAGUE' | Pred: 'LEAGUE'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'COMPARISON' | Pred: 'COMPARISON'\n",
            "  True: 'DANGERS' | Pred: 'DANGERS'\n",
            "  True: '317' | Pred: '317'\n",
            "\n",
            "📈 Epoch 133/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.01it/s, loss=0.003, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 133 Summary:\n",
            "  Training Loss: 0.0072\n",
            "  Training Word Acc: 0.9844\n",
            "  Validation Word Acc: 0.7420\n",
            "  Validation Char Acc: 0.8339\n",
            "  Learning Rate: 0.000450\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '3D' | Pred: '8R'\n",
            "  True: 'FEW' | Pred: 'FEW'\n",
            "  True: 'STATE' | Pred: 'STATE'\n",
            "  True: 'CREATE' | Pred: 'CREATE'\n",
            "  True: 'PROVINCIAL' | Pred: 'PROVINEIAI'\n",
            "\n",
            "📈 Epoch 134/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.54it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 134 Summary:\n",
            "  Training Loss: 0.0045\n",
            "  Training Word Acc: 0.9883\n",
            "  Validation Word Acc: 0.7300\n",
            "  Validation Char Acc: 0.8272\n",
            "  Learning Rate: 0.000444\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '19' | Pred: '1'\n",
            "  True: 'MIRREN' | Pred: 'MIRREN'\n",
            "  True: 'SOLVE' | Pred: 'SOLVE'\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "  True: 'HOME' | Pred: 'HOME'\n",
            "\n",
            "📈 Epoch 135/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.74it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 135 Summary:\n",
            "  Training Loss: 0.0050\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7180\n",
            "  Validation Char Acc: 0.8220\n",
            "  Learning Rate: 0.000437\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'FARM' | Pred: 'FARM'\n",
            "  True: 'INDIA' | Pred: 'INALA'\n",
            "  True: '208' | Pred: '208'\n",
            "  True: 'ILL' | Pred: 'ILL'\n",
            "\n",
            "📈 Epoch 136/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.00it/s, loss=0.002, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 136 Summary:\n",
            "  Training Loss: 0.0089\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7280\n",
            "  Validation Char Acc: 0.8222\n",
            "  Learning Rate: 0.000431\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'COM' | Pred: 'COM'\n",
            "  True: 'STORES' | Pred: 'STORES'\n",
            "  True: 'SREELAKSHMI' | Pred: 'SRINTARKSSINI'\n",
            "  True: 'SETH' | Pred: 'CALW'\n",
            "  True: 'NEW' | Pred: 'NEW'\n",
            "\n",
            "📈 Epoch 137/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.05it/s, loss=0.002, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 137 Summary:\n",
            "  Training Loss: 0.0059\n",
            "  Training Word Acc: 0.9922\n",
            "  Validation Word Acc: 0.7360\n",
            "  Validation Char Acc: 0.8306\n",
            "  Learning Rate: 0.000425\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'EXIT' | Pred: 'EXIT'\n",
            "  True: 'AUR' | Pred: 'AUR'\n",
            "  True: 'COMPARISON' | Pred: 'COMPARISON'\n",
            "  True: 'WAS' | Pred: 'WAS'\n",
            "  True: 'BE' | Pred: 'BE'\n",
            "\n",
            "📈 Epoch 138/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.00it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 138 Summary:\n",
            "  Training Loss: 0.0028\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7340\n",
            "  Validation Char Acc: 0.8371\n",
            "  Learning Rate: 0.000419\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CATE' | Pred: 'CATE'\n",
            "  True: 'MELIN' | Pred: 'MELIN'\n",
            "  True: '24' | Pred: '24'\n",
            "  True: 'ONLY' | Pred: 'ONLY'\n",
            "  True: 'VIJAYAWADA' | Pred: 'VAYAMKOR'\n",
            "\n",
            "📈 Epoch 139/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.59it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 139 Summary:\n",
            "  Training Loss: 0.0024\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7300\n",
            "  Validation Char Acc: 0.8378\n",
            "  Learning Rate: 0.000412\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'EARTHSELLERS' | Pred: 'EARTHSEIES'\n",
            "  True: '50' | Pred: '250'\n",
            "  True: 'GERARO' | Pred: 'GEBBID'\n",
            "  True: 'DIRECTLY' | Pred: 'DIRECTLY'\n",
            "  True: 'HALE' | Pred: 'FALE'\n",
            "\n",
            "📈 Epoch 140/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.86it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 140 Summary:\n",
            "  Training Loss: 0.0043\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7460\n",
            "  Validation Char Acc: 0.8304\n",
            "  Learning Rate: 0.000406\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'GO' | Pred: 'ED'\n",
            "  True: 'BLOOM' | Pred: 'OBIOOM'\n",
            "  True: 'CREEK' | Pred: 'CREEX'\n",
            "  True: 'CURRENTLY' | Pred: 'CURRENTLY'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "\n",
            "📈 Epoch 141/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.84it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 141 Summary:\n",
            "  Training Loss: 0.0019\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7380\n",
            "  Validation Char Acc: 0.8295\n",
            "  Learning Rate: 0.000400\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'NEW' | Pred: 'NEW'\n",
            "  True: 'STATE' | Pred: 'STATE'\n",
            "  True: 'IMAIZUMI' | Pred: 'WGLPUMI'\n",
            "  True: 'THINK' | Pred: 'THINK'\n",
            "  True: 'COOPER' | Pred: 'COOPER'\n",
            "\n",
            "📈 Epoch 142/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.82it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 142 Summary:\n",
            "  Training Loss: 0.0009\n",
            "  Training Word Acc: 0.9922\n",
            "  Validation Word Acc: 0.7320\n",
            "  Validation Char Acc: 0.8360\n",
            "  Learning Rate: 0.000394\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "  True: 'METER' | Pred: 'METER'\n",
            "  True: '1800GOGEICO' | Pred: '30DGDGECO'\n",
            "  True: 'SQUIRRELS' | Pred: 'FOAUNRRELS'\n",
            "  True: 'CHANDIGARH' | Pred: 'CHANDIGARI'\n",
            "\n",
            "📈 Epoch 143/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.54it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 143 Summary:\n",
            "  Training Loss: 0.0008\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7380\n",
            "  Validation Char Acc: 0.8380\n",
            "  Learning Rate: 0.000388\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'JUKEBOX' | Pred: 'JUKEBOX'\n",
            "  True: 'CIUDAD' | Pred: 'CIUDAD'\n",
            "  True: 'A' | Pred: 'A'\n",
            "  True: 'COLOURS' | Pred: 'CLONS'\n",
            "  True: 'FOSTER' | Pred: 'FOSTER'\n",
            "\n",
            "📈 Epoch 144/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.97it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 144 Summary:\n",
            "  Training Loss: 0.0007\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7420\n",
            "  Validation Char Acc: 0.8358\n",
            "  Learning Rate: 0.000382\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ARK' | Pred: 'BKK'\n",
            "  True: 'CITY' | Pred: 'CITY'\n",
            "  True: 'AUGUST' | Pred: 'AUGUST'\n",
            "  True: 'TOTAL' | Pred: 'TOTAL'\n",
            "  True: 'WAS' | Pred: 'WAS'\n",
            "\n",
            "📈 Epoch 145/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.87it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 145 Summary:\n",
            "  Training Loss: 0.0005\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7480\n",
            "  Validation Char Acc: 0.8341\n",
            "  Learning Rate: 0.000376\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ASUN' | Pred: 'ASUN'\n",
            "  True: 'NIN' | Pred: 'ITIIN'\n",
            "  True: 'CAN' | Pred: 'CAN'\n",
            "  True: 'YOURE' | Pred: 'YOURE'\n",
            "  True: 'CRESTDOWN' | Pred: 'CRESTDOWN'\n",
            "\n",
            "📈 Epoch 146/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:09<00:00, 15.66it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 146 Summary:\n",
            "  Training Loss: 0.0005\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7420\n",
            "  Validation Char Acc: 0.8360\n",
            "  Learning Rate: 0.000370\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'GREAT' | Pred: 'GREAT'\n",
            "  True: 'ANGELS' | Pred: 'ANGELS'\n",
            "  True: 'LOVE' | Pred: 'CE'\n",
            "  True: 'EXIT' | Pred: 'EXIT'\n",
            "  True: 'THEYRE' | Pred: 'THEYRE'\n",
            "\n",
            "📈 Epoch 147/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.41it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 147 Summary:\n",
            "  Training Loss: 0.0004\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7520\n",
            "  Validation Char Acc: 0.8392\n",
            "  Learning Rate: 0.000364\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SOLVE' | Pred: 'SOLVE'\n",
            "  True: 'WAS' | Pred: 'WAS'\n",
            "  True: 'GO' | Pred: 'CO'\n",
            "  True: 'SREELAKSHMI' | Pred: 'SNINLAKSSINI'\n",
            "  True: 'CARD' | Pred: 'CARD'\n",
            "\n",
            "📈 Epoch 148/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.27it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 148 Summary:\n",
            "  Training Loss: 0.0004\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7440\n",
            "  Validation Char Acc: 0.8378\n",
            "  Learning Rate: 0.000357\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'JACKASS' | Pred: 'IACKASS'\n",
            "  True: 'NEWS' | Pred: 'NEWS'\n",
            "  True: '930' | Pred: '930'\n",
            "  True: 'COM' | Pred: 'COM'\n",
            "  True: 'LETS' | Pred: 'LETS'\n",
            "\n",
            "📈 Epoch 149/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.84it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 149 Summary:\n",
            "  Training Loss: 0.0004\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8433\n",
            "  Learning Rate: 0.000351\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CRITICS' | Pred: 'CRITICS'\n",
            "  True: 'USER' | Pred: 'USER'\n",
            "  True: 'MEANS' | Pred: 'MEANS'\n",
            "  True: 'JACKASS' | Pred: 'IACKASS'\n",
            "  True: 'OOPS' | Pred: 'OOPS'\n",
            "\n",
            "📈 Epoch 150/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.95it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 150 Summary:\n",
            "  Training Loss: 0.0007\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7360\n",
            "  Validation Char Acc: 0.8323\n",
            "  Learning Rate: 0.000345\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'HANDY' | Pred: 'HANDY'\n",
            "  True: 'ONLY' | Pred: 'ONLY'\n",
            "  True: 'SALT' | Pred: 'SALT'\n",
            "  True: 'A' | Pred: 'A'\n",
            "  True: 'ANSON' | Pred: 'ANSON'\n",
            "\n",
            "📈 Epoch 151/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.11it/s, loss=0.005, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 151 Summary:\n",
            "  Training Loss: 0.0014\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7300\n",
            "  Validation Char Acc: 0.8270\n",
            "  Learning Rate: 0.000340\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'DENZEL' | Pred: 'DENAEL'\n",
            "  True: 'REEVES' | Pred: 'REEVES'\n",
            "  True: 'IMAGE' | Pred: 'IMAGE'\n",
            "  True: 'DONE' | Pred: 'DONE'\n",
            "  True: 'MEANS' | Pred: 'MEANS'\n",
            "\n",
            "📈 Epoch 152/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.60it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 152 Summary:\n",
            "  Training Loss: 0.0008\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7280\n",
            "  Validation Char Acc: 0.8310\n",
            "  Learning Rate: 0.000334\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BOB' | Pred: 'BOB'\n",
            "  True: 'HUNTINGTON' | Pred: 'HUNTINFON'\n",
            "  True: 'ASIA' | Pred: 'ASIA'\n",
            "  True: 'TOM' | Pred: 'TOM'\n",
            "  True: 'WISHES' | Pred: 'WISHES'\n",
            "\n",
            "📈 Epoch 153/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.05it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 153 Summary:\n",
            "  Training Loss: 0.0011\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7300\n",
            "  Validation Char Acc: 0.8340\n",
            "  Learning Rate: 0.000328\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'AHEAD' | Pred: 'AHEAD'\n",
            "  True: 'PHONE' | Pred: 'PHONE'\n",
            "  True: 'BEEN' | Pred: 'BEEN'\n",
            "  True: 'NORTH' | Pred: 'NORTH'\n",
            "\n",
            "📈 Epoch 154/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.08it/s, loss=0.047, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 154 Summary:\n",
            "  Training Loss: 0.0029\n",
            "  Training Word Acc: 0.9898\n",
            "  Validation Word Acc: 0.7360\n",
            "  Validation Char Acc: 0.8262\n",
            "  Learning Rate: 0.000322\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TRINITYLEEDS' | Pred: 'THMTYLECRDS'\n",
            "  True: 'COLA' | Pred: 'COLA'\n",
            "  True: 'ZIEHEN' | Pred: 'ZIEHEN'\n",
            "  True: 'KINGS' | Pred: 'KINGS'\n",
            "  True: 'UNIVERSITY' | Pred: 'UNTIVERSTIY'\n",
            "\n",
            "📈 Epoch 155/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.07it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 155 Summary:\n",
            "  Training Loss: 0.0035\n",
            "  Training Word Acc: 0.9883\n",
            "  Validation Word Acc: 0.7440\n",
            "  Validation Char Acc: 0.8305\n",
            "  Learning Rate: 0.000316\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'STATION' | Pred: 'STATION'\n",
            "  True: 'JONES' | Pred: 'JONES'\n",
            "  True: 'BANK' | Pred: 'BANK'\n",
            "  True: 'EXIT' | Pred: 'EXIT'\n",
            "  True: 'DENZEL' | Pred: 'DENAEL'\n",
            "\n",
            "📈 Epoch 156/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.02it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 156 Summary:\n",
            "  Training Loss: 0.0031\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7380\n",
            "  Validation Char Acc: 0.8298\n",
            "  Learning Rate: 0.000310\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'FRIENDS' | Pred: 'FRIENDS'\n",
            "  True: 'ON' | Pred: 'ON'\n",
            "  True: 'SHIZUOKA' | Pred: 'SHZUOKA'\n",
            "  True: 'WYNTON' | Pred: 'WGATON'\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "\n",
            "📈 Epoch 157/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.12it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 157 Summary:\n",
            "  Training Loss: 0.0017\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7400\n",
            "  Validation Char Acc: 0.8284\n",
            "  Learning Rate: 0.000304\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '280' | Pred: '280'\n",
            "  True: 'JURASSIC' | Pred: 'JURASSIC'\n",
            "  True: 'CRESTED' | Pred: 'ERESTED'\n",
            "  True: 'BANK' | Pred: 'BARNKE'\n",
            "  True: '560' | Pred: '560'\n",
            "\n",
            "📈 Epoch 158/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.11it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 158 Summary:\n",
            "  Training Loss: 0.0017\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7420\n",
            "  Validation Char Acc: 0.8359\n",
            "  Learning Rate: 0.000299\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'POINT' | Pred: 'KOLN'\n",
            "  True: 'CRESTED' | Pred: 'ERESTED'\n",
            "  True: 'POSSOBILITIES' | Pred: 'POSSIBITIES'\n",
            "  True: 'PHOENIX' | Pred: 'PHOENDX'\n",
            "  True: 'BUT' | Pred: 'BUT'\n",
            "\n",
            "📈 Epoch 159/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.06it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 159 Summary:\n",
            "  Training Loss: 0.0020\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7260\n",
            "  Validation Char Acc: 0.8253\n",
            "  Learning Rate: 0.000293\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '3D' | Pred: 'BR'\n",
            "  True: 'DIAZ' | Pred: 'DIA'\n",
            "  True: 'GENOAS' | Pred: 'GENOAS'\n",
            "  True: 'ORDER' | Pred: 'DRDER'\n",
            "  True: 'FUTURE' | Pred: 'FUTURE'\n",
            "\n",
            "📈 Epoch 160/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.81it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 160 Summary:\n",
            "  Training Loss: 0.0013\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7460\n",
            "  Validation Char Acc: 0.8245\n",
            "  Learning Rate: 0.000287\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'HIDLY' | Pred: 'HIDLY'\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "  True: 'COM' | Pred: 'COM'\n",
            "  True: 'SHOP' | Pred: 'SHOP'\n",
            "  True: 'BUY' | Pred: 'BIY'\n",
            "\n",
            "📈 Epoch 161/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.23it/s, loss=0.004, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 161 Summary:\n",
            "  Training Loss: 0.0019\n",
            "  Training Word Acc: 0.9922\n",
            "  Validation Word Acc: 0.7520\n",
            "  Validation Char Acc: 0.8417\n",
            "  Learning Rate: 0.000281\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TWENTY' | Pred: 'INENTT'\n",
            "  True: 'CATE' | Pred: 'CATE'\n",
            "  True: 'UNE' | Pred: 'UNE'\n",
            "  True: 'ALIBABA' | Pred: 'ALIBABA'\n",
            "  True: 'DUKES' | Pred: 'DUKES'\n",
            "\n",
            "📈 Epoch 162/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.17it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 162 Summary:\n",
            "  Training Loss: 0.0014\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8477\n",
            "  Learning Rate: 0.000276\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'QUEENSWAY' | Pred: 'CUEENSWOY'\n",
            "  True: 'ATM' | Pred: 'ATM'\n",
            "  True: 'CORRESLAW' | Pred: 'CORRESLAY'\n",
            "  True: '01922' | Pred: '01922'\n",
            "  True: 'GLOBAL' | Pred: 'GLOBAL'\n",
            "\n",
            "📈 Epoch 163/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.24it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 163 Summary:\n",
            "  Training Loss: 0.0028\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7480\n",
            "  Validation Char Acc: 0.8418\n",
            "  Learning Rate: 0.000270\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'GREM' | Pred: 'GREM'\n",
            "  True: 'SAVE' | Pred: 'SAVE'\n",
            "  True: 'FARM' | Pred: 'FARM'\n",
            "  True: 'MATRIX' | Pred: 'MATRIX'\n",
            "  True: 'NEW' | Pred: 'NEW'\n",
            "\n",
            "📈 Epoch 164/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.84it/s, loss=0.028, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 164 Summary:\n",
            "  Training Loss: 0.0011\n",
            "  Training Word Acc: 0.9938\n",
            "  Validation Word Acc: 0.7480\n",
            "  Validation Char Acc: 0.8463\n",
            "  Learning Rate: 0.000265\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'JONES' | Pred: 'JONES'\n",
            "  True: 'BIG' | Pred: 'BIG'\n",
            "  True: 'COOPER' | Pred: 'COOPER'\n",
            "  True: '23' | Pred: '23'\n",
            "  True: 'NO' | Pred: 'NO'\n",
            "\n",
            "📈 Epoch 165/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.21it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 165 Summary:\n",
            "  Training Loss: 0.0007\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7380\n",
            "  Validation Char Acc: 0.8396\n",
            "  Learning Rate: 0.000259\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TAXI' | Pred: 'TAXL'\n",
            "  True: 'QAARVAN' | Pred: 'DAARVAN'\n",
            "  True: 'IS' | Pred: 'ISS'\n",
            "  True: '95' | Pred: '95'\n",
            "  True: 'BPL' | Pred: 'BPL'\n",
            "\n",
            "📈 Epoch 166/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.11it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 166 Summary:\n",
            "  Training Loss: 0.0007\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7420\n",
            "  Validation Char Acc: 0.8473\n",
            "  Learning Rate: 0.000254\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'OOPS' | Pred: 'OOPS'\n",
            "  True: 'ON' | Pred: 'ON'\n",
            "  True: 'STATE' | Pred: 'STATE'\n",
            "  True: '560' | Pred: '560'\n",
            "  True: 'GREM' | Pred: 'GREM'\n",
            "\n",
            "📈 Epoch 167/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.19it/s, loss=0.005, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 167 Summary:\n",
            "  Training Loss: 0.0014\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8373\n",
            "  Learning Rate: 0.000248\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'DEMONS' | Pred: 'DEMONS'\n",
            "  True: 'N72' | Pred: 'N'\n",
            "  True: 'SREELAKSHMI' | Pred: 'SRINLAKSSINMI'\n",
            "  True: 'TWILIGHT' | Pred: 'TWILIGHT'\n",
            "  True: 'YOU' | Pred: 'YOU'\n",
            "\n",
            "📈 Epoch 168/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.78it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 168 Summary:\n",
            "  Training Loss: 0.0009\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7440\n",
            "  Validation Char Acc: 0.8249\n",
            "  Learning Rate: 0.000243\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '2' | Pred: '2'\n",
            "  True: 'SCOOTER' | Pred: 'SCOOLER'\n",
            "  True: '1989' | Pred: '1939'\n",
            "  True: '2' | Pred: '2'\n",
            "  True: 'CITROEN' | Pred: 'CITROEN'\n",
            "\n",
            "📈 Epoch 169/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.48it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 169 Summary:\n",
            "  Training Loss: 0.0004\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8415\n",
            "  Learning Rate: 0.000237\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PEACE' | Pred: 'REACE'\n",
            "  True: 'PANCHGANI' | Pred: 'PANCHGANI'\n",
            "  True: 'CURRENTLY' | Pred: 'CURRENTLY'\n",
            "  True: 'TIMES' | Pred: 'TIMES'\n",
            "  True: 'LOVE' | Pred: 'CE'\n",
            "\n",
            "📈 Epoch 170/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.14it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 170 Summary:\n",
            "  Training Loss: 0.0003\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8389\n",
            "  Learning Rate: 0.000232\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'AS' | Pred: 'AS'\n",
            "  True: 'CHRYSLER' | Pred: 'CHAVSLER'\n",
            "  True: 'NIN' | Pred: 'ITIN'\n",
            "  True: 'WAS' | Pred: 'WAS'\n",
            "  True: 'IN' | Pred: 'IN'\n",
            "\n",
            "📈 Epoch 171/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.12it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 171 Summary:\n",
            "  Training Loss: 0.0010\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7480\n",
            "  Validation Char Acc: 0.8402\n",
            "  Learning Rate: 0.000227\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PAUL' | Pred: 'PAUL'\n",
            "  True: 'TOLL' | Pred: 'TOIL'\n",
            "  True: 'AND' | Pred: 'ANO'\n",
            "  True: 'MATRIX' | Pred: 'MATRIX'\n",
            "  True: 'GREAT' | Pred: 'GREAT'\n",
            "\n",
            "📈 Epoch 172/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.72it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 172 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7500\n",
            "  Validation Char Acc: 0.8387\n",
            "  Learning Rate: 0.000222\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '5' | Pred: '5'\n",
            "  True: 'SCHEMES' | Pred: 'SCHEMES'\n",
            "  True: 'JACKASS' | Pred: 'IACKASS'\n",
            "  True: 'FUTURE' | Pred: 'FUTURE'\n",
            "  True: 'DAY' | Pred: 'DAY'\n",
            "\n",
            "📈 Epoch 173/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.59it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 173 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7520\n",
            "  Validation Char Acc: 0.8313\n",
            "  Learning Rate: 0.000216\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '45' | Pred: '45'\n",
            "  True: 'INDIAN' | Pred: 'INDIAN'\n",
            "  True: 'HOURS' | Pred: 'HOURS'\n",
            "  True: 'COM' | Pred: 'COM'\n",
            "  True: 'NOTHING' | Pred: 'NOTHING'\n",
            "\n",
            "📈 Epoch 174/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.82it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 174 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7480\n",
            "  Validation Char Acc: 0.8371\n",
            "  Learning Rate: 0.000211\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'HERE' | Pred: 'HERE'\n",
            "  True: 'BE' | Pred: 'BE'\n",
            "  True: 'PITT' | Pred: 'PITT'\n",
            "  True: 'BORDER' | Pred: 'BORDER'\n",
            "  True: 'PACK' | Pred: 'PACK'\n",
            "\n",
            "📈 Epoch 175/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.86it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 175 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8398\n",
            "  Learning Rate: 0.000206\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'STORY' | Pred: 'STORY'\n",
            "  True: 'MCKINNEY' | Pred: 'MEKINNEY'\n",
            "  True: 'PENANG' | Pred: 'PENANG'\n",
            "  True: 'INSTORE' | Pred: 'INSTORE'\n",
            "  True: 'DAY' | Pred: 'DAY'\n",
            "\n",
            "📈 Epoch 176/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.24it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 176 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8370\n",
            "  Learning Rate: 0.000201\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BE' | Pred: 'BE'\n",
            "  True: '930' | Pred: '930'\n",
            "  True: 'ORDER' | Pred: 'DRDER'\n",
            "  True: 'JONES' | Pred: 'JONES'\n",
            "  True: 'WWWSHUTTERSTOCKCOM' | Pred: 'WWWSHUTTERSTOKCOM'\n",
            "\n",
            "📈 Epoch 177/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.83it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 177 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8389\n",
            "  Learning Rate: 0.000196\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'NOVO' | Pred: 'NOVO'\n",
            "  True: 'MATRIX' | Pred: 'MATRIX'\n",
            "  True: 'COOPER' | Pred: 'COOPER'\n",
            "  True: 'DIRECTION' | Pred: 'DIRECTION'\n",
            "  True: 'ADOPTION' | Pred: 'ADOPTION'\n",
            "\n",
            "📈 Epoch 178/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.93it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 178 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8394\n",
            "  Learning Rate: 0.000191\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'REGENCY' | Pred: 'DLGENCY'\n",
            "  True: 'BOB' | Pred: '90B'\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "  True: '7' | Pred: '7'\n",
            "  True: 'IN' | Pred: 'IN'\n",
            "\n",
            "📈 Epoch 179/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.05it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 179 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8430\n",
            "  Learning Rate: 0.000186\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SAJITH' | Pred: 'SAIITH'\n",
            "  True: 'AND' | Pred: 'AND'\n",
            "  True: 'ASHTON' | Pred: 'ASHTON'\n",
            "  True: '3D' | Pred: '3D'\n",
            "  True: 'SQUIRRELS' | Pred: 'FOAUNRRES'\n",
            "\n",
            "📈 Epoch 180/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.10it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 180 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7620\n",
            "  Validation Char Acc: 0.8444\n",
            "  Learning Rate: 0.000181\n",
            "  ✅ New best model saved! Word Acc: 0.7620\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'US' | Pred: 'US'\n",
            "  True: 'SURVEY' | Pred: 'SURVEY'\n",
            "  True: 'STATE' | Pred: 'STATE'\n",
            "  True: 'EVERY' | Pred: 'EVEY'\n",
            "  True: 'GRASSROOTSMARKETING' | Pred: 'WWULSTROMATHOHWTHW'\n",
            "\n",
            "📈 Epoch 181/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.87it/s, loss=0.004, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 181 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8408\n",
            "  Learning Rate: 0.000176\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "  True: '280' | Pred: '280'\n",
            "  True: '25' | Pred: '25'\n",
            "  True: 'INK' | Pred: 'INK'\n",
            "  True: 'CURRENCY' | Pred: 'CURTRERCY'\n",
            "\n",
            "📈 Epoch 182/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.85it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 182 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8419\n",
            "  Learning Rate: 0.000172\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CARD' | Pred: 'CARD'\n",
            "  True: 'SCOOTER' | Pred: 'SCOOLER'\n",
            "  True: 'BROWN' | Pred: 'BROWN'\n",
            "  True: 'REBELLION' | Pred: 'REBELLION'\n",
            "  True: 'MONTGOMERY' | Pred: 'MONTGOMMERY'\n",
            "\n",
            "📈 Epoch 183/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.95it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 183 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7500\n",
            "  Validation Char Acc: 0.8381\n",
            "  Learning Rate: 0.000167\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'JUKEBOX' | Pred: 'JUKEBOX'\n",
            "  True: '212' | Pred: '212'\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "  True: 'TOLL' | Pred: 'TOIL'\n",
            "  True: 'REEVES' | Pred: 'REEVES'\n",
            "\n",
            "📈 Epoch 184/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.79it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 184 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8384\n",
            "  Learning Rate: 0.000162\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'KINGS' | Pred: 'KINGS'\n",
            "  True: '125' | Pred: '126'\n",
            "  True: '20' | Pred: '20'\n",
            "  True: 'INK' | Pred: 'INK'\n",
            "  True: '3D' | Pred: '3'\n",
            "\n",
            "📈 Epoch 185/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.47it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 185 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7520\n",
            "  Validation Char Acc: 0.8371\n",
            "  Learning Rate: 0.000158\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SPACE' | Pred: 'SPACE'\n",
            "  True: '120' | Pred: '120'\n",
            "  True: 'TOLL' | Pred: 'TOIL'\n",
            "  True: '15' | Pred: '15'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "\n",
            "📈 Epoch 186/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.15it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 186 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8424\n",
            "  Learning Rate: 0.000153\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'COLOURS' | Pred: 'COLONRS'\n",
            "  True: 'VIEWERS' | Pred: 'VIEWERS'\n",
            "  True: '1800BUYKWIK' | Pred: 'BEODBUYHWEK'\n",
            "  True: 'OFFICE' | Pred: 'OFFICE'\n",
            "  True: 'CREEK' | Pred: 'CREEX'\n",
            "\n",
            "📈 Epoch 187/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.96it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 187 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8424\n",
            "  Learning Rate: 0.000149\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'MOTION' | Pred: 'MOTION'\n",
            "  True: 'EVERY' | Pred: 'EVEY'\n",
            "  True: 'SWEET' | Pred: 'SNEEY'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'ROUTH' | Pred: 'POUTH'\n",
            "\n",
            "📈 Epoch 188/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.02it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 188 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7480\n",
            "  Validation Char Acc: 0.8410\n",
            "  Learning Rate: 0.000144\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TITANS' | Pred: 'TITANS'\n",
            "  True: 'CITROEN' | Pred: 'CITROEN'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'A' | Pred: 'A'\n",
            "  True: 'NOW' | Pred: 'NOW'\n",
            "\n",
            "📈 Epoch 189/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.34it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 189 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8413\n",
            "  Learning Rate: 0.000140\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'THINK' | Pred: 'THINB'\n",
            "  True: '4865' | Pred: '4365'\n",
            "  True: '1800GOGEICO' | Pred: '400GDGECO'\n",
            "  True: 'LOSE' | Pred: 'LOSE'\n",
            "  True: '99' | Pred: '99'\n",
            "\n",
            "📈 Epoch 190/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.54it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 190 Summary:\n",
            "  Training Loss: 0.0003\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8412\n",
            "  Learning Rate: 0.000136\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BPL' | Pred: 'BPL'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'MIRREN' | Pred: 'MIRREN'\n",
            "  True: 'NOW' | Pred: 'NAY'\n",
            "  True: 'MORE' | Pred: 'MORE'\n",
            "\n",
            "📈 Epoch 191/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.93it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 191 Summary:\n",
            "  Training Loss: 0.0003\n",
            "  Training Word Acc: 0.9961\n",
            "  Validation Word Acc: 0.7520\n",
            "  Validation Char Acc: 0.8360\n",
            "  Learning Rate: 0.000131\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'NOW' | Pred: 'NOW'\n",
            "  True: 'SOLVE' | Pred: 'SOLVE'\n",
            "  True: '317' | Pred: '317'\n",
            "  True: 'ASTAIRE' | Pred: 'ASTAIRE'\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "\n",
            "📈 Epoch 192/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.04it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 192 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8384\n",
            "  Learning Rate: 0.000127\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'SAW' | Pred: 'SALL'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'A' | Pred: 'A'\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "  True: '2' | Pred: '2'\n",
            "\n",
            "📈 Epoch 193/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.17it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 193 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7620\n",
            "  Validation Char Acc: 0.8446\n",
            "  Learning Rate: 0.000123\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'YOU' | Pred: 'YOU'\n",
            "  True: 'DUKES' | Pred: 'DUKES'\n",
            "  True: 'TERMINAL' | Pred: 'TERMINEL'\n",
            "  True: 'PENANG' | Pred: 'PENANG'\n",
            "  True: 'FARM' | Pred: 'FARM'\n",
            "\n",
            "📈 Epoch 194/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.71it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 194 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8394\n",
            "  Learning Rate: 0.000119\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'FRIENDS' | Pred: 'FRIENDS'\n",
            "  True: 'THROW' | Pred: 'THROW'\n",
            "  True: '212' | Pred: '212'\n",
            "  True: 'WASHINGTON' | Pred: 'WASHINGTON'\n",
            "  True: 'JULY' | Pred: 'JULY'\n",
            "\n",
            "📈 Epoch 195/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.10it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 195 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8389\n",
            "  Learning Rate: 0.000115\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PHONE' | Pred: 'PHONE'\n",
            "  True: 'BLUE' | Pred: 'BLUE'\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "  True: 'EXIT' | Pred: 'EXIT'\n",
            "  True: 'BANK' | Pred: 'BANKK'\n",
            "\n",
            "📈 Epoch 196/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.99it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 196 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7500\n",
            "  Validation Char Acc: 0.8327\n",
            "  Learning Rate: 0.000111\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'NO' | Pred: 'NO'\n",
            "  True: 'BE' | Pred: 'BE'\n",
            "  True: 'NEWS' | Pred: 'NEWS'\n",
            "  True: 'PHONE' | Pred: 'PHONE'\n",
            "  True: 'LOVE' | Pred: 'CO'\n",
            "\n",
            "📈 Epoch 197/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.01it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 197 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7460\n",
            "  Validation Char Acc: 0.8346\n",
            "  Learning Rate: 0.000107\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TIME' | Pred: 'TVE'\n",
            "  True: 'ASIA' | Pred: 'ASIA'\n",
            "  True: 'REBELLION' | Pred: 'REBELLILON'\n",
            "  True: 'AND' | Pred: 'AND'\n",
            "  True: 'ROLAND' | Pred: 'ROLAND'\n",
            "\n",
            "📈 Epoch 198/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.82it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 198 Summary:\n",
            "  Training Loss: 0.0005\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7520\n",
            "  Validation Char Acc: 0.8423\n",
            "  Learning Rate: 0.000103\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'JURASSIC' | Pred: 'JURASSIC'\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "  True: 'IS' | Pred: 'IS'\n",
            "  True: 'PHONE' | Pred: 'PHONE'\n",
            "  True: 'SHOESTRING' | Pred: 'PLOESTRE'\n",
            "\n",
            "📈 Epoch 199/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.96it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 199 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7480\n",
            "  Validation Char Acc: 0.8348\n",
            "  Learning Rate: 0.000099\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'AN' | Pred: 'AN'\n",
            "  True: 'LOANS' | Pred: 'LOANS'\n",
            "  True: 'JUBILEE' | Pred: 'JUBILEE'\n",
            "  True: 'NOVEMBER' | Pred: 'NOVEMBER'\n",
            "  True: 'LOSE' | Pred: 'LOSE'\n",
            "\n",
            "📈 Epoch 200/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.13it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 200 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7680\n",
            "  Validation Char Acc: 0.8428\n",
            "  Learning Rate: 0.000095\n",
            "  ✅ New best model saved! Word Acc: 0.7680\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'GENOAS' | Pred: 'GENOAS'\n",
            "  True: 'VIEW' | Pred: 'VIEW'\n",
            "  True: 'JULY' | Pred: 'JULY'\n",
            "  True: 'CHANDIGARH' | Pred: 'CHANDIGARH'\n",
            "  True: 'FIRST' | Pred: 'FIRST'\n",
            "\n",
            "📈 Epoch 201/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.09it/s, loss=0.001, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 201 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7620\n",
            "  Validation Char Acc: 0.8407\n",
            "  Learning Rate: 0.000092\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "  True: 'VEGETARIAN' | Pred: 'VECSTARIAN'\n",
            "  True: '7' | Pred: '7'\n",
            "  True: 'PAUL' | Pred: 'PAUL'\n",
            "  True: 'HITAM' | Pred: 'HITAM'\n",
            "\n",
            "📈 Epoch 202/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.73it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 202 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7640\n",
            "  Validation Char Acc: 0.8442\n",
            "  Learning Rate: 0.000088\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PORTABLE' | Pred: 'PORTABLE'\n",
            "  True: 'FARM' | Pred: 'FARM'\n",
            "  True: 'TOTAL' | Pred: 'TOTAL'\n",
            "  True: 'SBI' | Pred: 'SBR'\n",
            "  True: 'OF' | Pred: 'OF'\n",
            "\n",
            "📈 Epoch 203/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.03it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 203 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8387\n",
            "  Learning Rate: 0.000085\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'REGENCY' | Pred: 'NLGENCY'\n",
            "  True: '208' | Pred: '208'\n",
            "  True: 'KELLIMAR' | Pred: 'KEAMMA'\n",
            "  True: 'SETH' | Pred: 'CEW'\n",
            "\n",
            "📈 Epoch 204/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.99it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 204 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8379\n",
            "  Learning Rate: 0.000081\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '7' | Pred: '7'\n",
            "  True: 'HEFNER' | Pred: 'HEFNER'\n",
            "  True: 'WORTHINGTON' | Pred: 'IIEILIIETLL'\n",
            "  True: 'TWITTERCOMAPLUSK' | Pred: 'MLECOMEPIESY'\n",
            "  True: 'MATRIX' | Pred: 'MATRIX'\n",
            "\n",
            "📈 Epoch 205/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:09<00:00, 14.99it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 205 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7640\n",
            "  Validation Char Acc: 0.8453\n",
            "  Learning Rate: 0.000078\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'LOADING' | Pred: 'CECING'\n",
            "  True: 'THROW' | Pred: 'THROW'\n",
            "  True: 'SPECIAL' | Pred: 'GPTCIOL'\n",
            "  True: 'HUNTINGTON' | Pred: 'HUNTINETON'\n",
            "  True: 'OOPS' | Pred: 'OOPS'\n",
            "\n",
            "📈 Epoch 206/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.80it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 206 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8409\n",
            "  Learning Rate: 0.000075\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'AVAILABLE' | Pred: 'AVALABLE'\n",
            "  True: 'ATM' | Pred: 'ATM'\n",
            "  True: 'BROWN' | Pred: 'BROWN'\n",
            "  True: 'ONLINE' | Pred: 'ONLINE'\n",
            "  True: 'COLOURS' | Pred: 'COLONRS'\n",
            "\n",
            "📈 Epoch 207/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.91it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 207 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8374\n",
            "  Learning Rate: 0.000071\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "  True: 'US' | Pred: 'US'\n",
            "  True: 'SANTOMIC' | Pred: 'SANTOMIC'\n",
            "  True: '280' | Pred: '280'\n",
            "  True: 'VEGETARIAN' | Pred: 'VECSTARIAN'\n",
            "\n",
            "📈 Epoch 208/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.90it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 208 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8388\n",
            "  Learning Rate: 0.000068\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '930' | Pred: '930'\n",
            "  True: '2ND' | Pred: '2ND'\n",
            "  True: 'MARZO' | Pred: 'MARZO'\n",
            "  True: 'ALIBABA' | Pred: 'ATIBABA'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "\n",
            "📈 Epoch 209/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.85it/s, loss=0.009, word_acc=0.950]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 209 Summary:\n",
            "  Training Loss: 0.0002\n",
            "  Training Word Acc: 0.9938\n",
            "  Validation Word Acc: 0.7620\n",
            "  Validation Char Acc: 0.8424\n",
            "  Learning Rate: 0.000065\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'JACKASS' | Pred: 'IACKASS'\n",
            "  True: 'VEGETARIAN' | Pred: 'VECSTARIAN'\n",
            "  True: 'MASS' | Pred: 'MASS'\n",
            "  True: '19' | Pred: '1'\n",
            "  True: 'TWENTY' | Pred: 'INENTT'\n",
            "\n",
            "📈 Epoch 210/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.54it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 210 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7520\n",
            "  Validation Char Acc: 0.8356\n",
            "  Learning Rate: 0.000062\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'OFFICE' | Pred: 'OFFICE'\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "  True: 'REBELLION' | Pred: 'REBELLION'\n",
            "  True: 'TRINITYLEEDS' | Pred: 'TMUMTYLERDS'\n",
            "  True: 'ASHTON' | Pred: 'ASHTON'\n",
            "\n",
            "📈 Epoch 211/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.04it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 211 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8376\n",
            "  Learning Rate: 0.000059\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'TO' | Pred: 'TO'\n",
            "  True: 'FOR' | Pred: 'FOR'\n",
            "  True: 'MONTGOMERY' | Pred: 'MONTCOLIERY'\n",
            "  True: '77' | Pred: '77'\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "\n",
            "📈 Epoch 212/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.89it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 212 Summary:\n",
            "  Training Loss: 0.0003\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8350\n",
            "  Learning Rate: 0.000056\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ANSON' | Pred: 'ANSON'\n",
            "  True: 'HOMICIDE' | Pred: 'HOMICIDE'\n",
            "  True: 'FAILTE' | Pred: 'TAILTE'\n",
            "  True: 'ALIBABA' | Pred: 'ALIBABA'\n",
            "  True: 'AND' | Pred: 'AND'\n",
            "\n",
            "📈 Epoch 213/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.75it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 213 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8371\n",
            "  Learning Rate: 0.000053\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "  True: 'TIMES' | Pred: 'TIMES'\n",
            "  True: 'GREAT' | Pred: 'GREAT'\n",
            "  True: 'SAJITH' | Pred: 'SAIITH'\n",
            "  True: 'BOARD' | Pred: 'BOARD'\n",
            "\n",
            "📈 Epoch 214/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.12it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 214 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8354\n",
            "  Learning Rate: 0.000050\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'DREAM' | Pred: 'DREAM'\n",
            "  True: 'FOSTER' | Pred: 'FOSTER'\n",
            "  True: 'HOME' | Pred: 'HOME'\n",
            "  True: 'AND' | Pred: 'ANO'\n",
            "  True: '3D' | Pred: '3D'\n",
            "\n",
            "📈 Epoch 215/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.43it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 215 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8341\n",
            "  Learning Rate: 0.000048\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CONTACT' | Pred: 'CONTACT'\n",
            "  True: 'THE' | Pred: 'THE'\n",
            "  True: 'LOVE' | Pred: 'CO'\n",
            "  True: 'DI' | Pred: 'DI'\n",
            "  True: 'CAN' | Pred: 'CAN'\n",
            "\n",
            "📈 Epoch 216/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.84it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 216 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8358\n",
            "  Learning Rate: 0.000045\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CFN' | Pred: 'CFN'\n",
            "  True: 'STATE' | Pred: 'STATE'\n",
            "  True: 'IMAIZUMI' | Pred: 'WOPUMI'\n",
            "  True: 'HOME' | Pred: 'HOIE'\n",
            "  True: 'FRUIT' | Pred: 'FUTIT'\n",
            "\n",
            "📈 Epoch 217/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.68it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 217 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8413\n",
            "  Learning Rate: 0.000042\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'STATE' | Pred: 'SATE'\n",
            "  True: 'MIRREN' | Pred: 'MIRREN'\n",
            "  True: 'CARING' | Pred: 'CARING'\n",
            "  True: 'ZIEHEN' | Pred: 'ZIEHEN'\n",
            "  True: 'SCHEMES' | Pred: 'SCHEMES'\n",
            "\n",
            "📈 Epoch 218/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.69it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 218 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8362\n",
            "  Learning Rate: 0.000040\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'YOU' | Pred: 'YOU'\n",
            "  True: 'MARILYN' | Pred: 'MARILYN'\n",
            "  True: 'PORTABLE' | Pred: 'PORTABLE'\n",
            "  True: 'BE' | Pred: 'BE'\n",
            "  True: 'MONTGOMERY' | Pred: 'MONTCONIERY'\n",
            "\n",
            "📈 Epoch 219/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.45it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 219 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8351\n",
            "  Learning Rate: 0.000037\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'GRAHAMS' | Pred: 'GRAHONTS'\n",
            "  True: '15' | Pred: '15'\n",
            "  True: 'NOTHING' | Pred: 'NOTHING'\n",
            "  True: 'IMAGE' | Pred: 'IMAGE'\n",
            "  True: 'INTO' | Pred: 'INTO'\n",
            "\n",
            "📈 Epoch 220/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:09<00:00, 15.65it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 220 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8316\n",
            "  Learning Rate: 0.000035\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '280' | Pred: '280'\n",
            "  True: '125' | Pred: '125'\n",
            "  True: 'WYNTON' | Pred: 'WGATON'\n",
            "  True: 'KELLIMAR' | Pred: 'KEAMA'\n",
            "  True: 'YOUR' | Pred: 'YOUR'\n",
            "\n",
            "📈 Epoch 221/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:09<00:00, 15.63it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 221 Summary:\n",
            "  Training Loss: 0.0000\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7620\n",
            "  Validation Char Acc: 0.8356\n",
            "  Learning Rate: 0.000033\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '4' | Pred: '4'\n",
            "  True: 'WWWSHUTTERSTOCKCOM' | Pred: 'WWWSHUTTERSTOKCOM'\n",
            "  True: 'LOADING' | Pred: 'CECING'\n",
            "  True: 'ON' | Pred: 'ON'\n",
            "  True: 'PHOENIX' | Pred: 'PHOENDX'\n",
            "\n",
            "📈 Epoch 222/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.69it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 222 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8311\n",
            "  Learning Rate: 0.000031\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CONSECUTIVE' | Pred: 'CONSECUTIVE'\n",
            "  True: 'UNIVERSITY' | Pred: 'UNIVERSTIY'\n",
            "  True: 'OUTDOOR' | Pred: 'OUTDOOR'\n",
            "  True: 'DAY' | Pred: 'DAY'\n",
            "  True: 'CITY' | Pred: 'CITY'\n",
            "\n",
            "📈 Epoch 223/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.17it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 223 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7540\n",
            "  Validation Char Acc: 0.8356\n",
            "  Learning Rate: 0.000029\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'NEWS' | Pred: 'NEWS'\n",
            "  True: 'BRISTOL' | Pred: 'BRISTOL'\n",
            "  True: 'SOLVE' | Pred: 'SOLVE'\n",
            "  True: 'DOT' | Pred: 'DOT'\n",
            "  True: 'COLOURS' | Pred: 'CLONRS'\n",
            "\n",
            "📈 Epoch 224/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.22it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 224 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8327\n",
            "  Learning Rate: 0.000026\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '23' | Pred: '23'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'INDIASBIN' | Pred: 'INDTADSBIN'\n",
            "  True: 'LOUIS' | Pred: 'LGUIIS'\n",
            "\n",
            "📈 Epoch 225/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.86it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 225 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8327\n",
            "  Learning Rate: 0.000024\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ROLAND' | Pred: 'ROLAND'\n",
            "  True: '50' | Pred: '50'\n",
            "  True: 'ON' | Pred: 'ON'\n",
            "  True: 'IS' | Pred: 'IS'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "\n",
            "📈 Epoch 226/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.88it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 226 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8356\n",
            "  Learning Rate: 0.000023\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'FIRE' | Pred: 'FIRE'\n",
            "  True: 'BLANKES' | Pred: 'BLANKES'\n",
            "  True: 'JONES' | Pred: 'JONES'\n",
            "  True: 'HELT' | Pred: 'HELT'\n",
            "  True: 'DONE' | Pred: 'DONE'\n",
            "\n",
            "📈 Epoch 227/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.02it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 227 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8318\n",
            "  Learning Rate: 0.000021\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PANCHGANI' | Pred: 'PANCHGANI'\n",
            "  True: '2' | Pred: '2'\n",
            "  True: 'SQUIRRELS' | Pred: 'FOAUNRRELS'\n",
            "  True: 'LOADING' | Pred: 'CECING'\n",
            "  True: 'GSTAR' | Pred: 'GSTAR'\n",
            "\n",
            "📈 Epoch 228/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.54it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 228 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8383\n",
            "  Learning Rate: 0.000019\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'NEWS' | Pred: 'NEWS'\n",
            "  True: 'CRITICS' | Pred: 'CRITICS'\n",
            "  True: 'VEGETARIAN' | Pred: 'VECSTARIAN'\n",
            "  True: 'PAUL' | Pred: 'PAUL'\n",
            "  True: 'ASTAIRE' | Pred: 'ASTAIRE'\n",
            "\n",
            "📈 Epoch 229/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:09<00:00, 15.18it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 229 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8399\n",
            "  Learning Rate: 0.000017\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'JUBILEE' | Pred: 'JUBILEE'\n",
            "  True: 'YOU' | Pred: 'YOU'\n",
            "  True: 'WAS' | Pred: 'WAS'\n",
            "  True: 'AN' | Pred: 'AN'\n",
            "  True: 'OUTDOOR' | Pred: 'OUTDOOR'\n",
            "\n",
            "📈 Epoch 230/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.07it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 230 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8374\n",
            "  Learning Rate: 0.000016\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'DAY' | Pred: 'DAY'\n",
            "  True: 'RESET' | Pred: 'RESET'\n",
            "  True: 'RIGHT' | Pred: 'RIGHT'\n",
            "  True: '1800BUYKWIK' | Pred: 'BODBUYHWIK'\n",
            "  True: 'AHEAD' | Pred: 'AHEAD'\n",
            "\n",
            "📈 Epoch 231/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.08it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 231 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8413\n",
            "  Learning Rate: 0.000014\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'INDIAN' | Pred: 'INDIAD'\n",
            "  True: 'KINGS' | Pred: 'KINGS'\n",
            "  True: 'NOT' | Pred: 'NOT'\n",
            "  True: 'WELCOME' | Pred: 'WELCOME'\n",
            "  True: 'ZAJAZD' | Pred: 'LHEED'\n",
            "\n",
            "📈 Epoch 232/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.89it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 232 Summary:\n",
            "  Training Loss: 0.0000\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8372\n",
            "  Learning Rate: 0.000013\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '1911' | Pred: 'I9LL'\n",
            "  True: 'BE' | Pred: 'BE'\n",
            "  True: 'TERMINAL' | Pred: 'TERMINEL'\n",
            "  True: 'SANTOMIC' | Pred: 'SANTOMIC'\n",
            "  True: 'SIGN' | Pred: 'SIGN'\n",
            "\n",
            "📈 Epoch 233/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.10it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 233 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8389\n",
            "  Learning Rate: 0.000011\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '19' | Pred: '1'\n",
            "  True: 'SHOP' | Pred: 'SHOP'\n",
            "  True: 'WITH' | Pred: 'WITH'\n",
            "  True: 'CREEK' | Pred: 'CREEX'\n",
            "  True: 'AND' | Pred: 'ANOD'\n",
            "\n",
            "📈 Epoch 234/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.02it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 234 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8397\n",
            "  Learning Rate: 0.000010\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'HERE' | Pred: 'HERE'\n",
            "  True: 'SHIZUOKA' | Pred: 'SHZUOKA'\n",
            "  True: '208' | Pred: '208'\n",
            "  True: 'CANDIDATE' | Pred: 'CANDIDATE'\n",
            "  True: 'BIG' | Pred: 'BIG'\n",
            "\n",
            "📈 Epoch 235/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.06it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 235 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8408\n",
            "  Learning Rate: 0.000009\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ECO' | Pred: 'ECO'\n",
            "  True: 'INSTORE' | Pred: 'INSTORE'\n",
            "  True: 'HOURS' | Pred: 'HOURS'\n",
            "  True: 'VISTA' | Pred: 'VISTA'\n",
            "  True: 'TWENTY' | Pred: 'INENTW'\n",
            "\n",
            "📈 Epoch 236/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.87it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 236 Summary:\n",
            "  Training Loss: 0.0000\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8389\n",
            "  Learning Rate: 0.000008\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'PARKING' | Pred: 'PARKING'\n",
            "  True: 'SCHEMES' | Pred: 'SCHEMES'\n",
            "  True: 'WHETLEY' | Pred: 'WHETLEY'\n",
            "  True: '4' | Pred: '4'\n",
            "  True: '02' | Pred: '02'\n",
            "\n",
            "📈 Epoch 237/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.23it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 237 Summary:\n",
            "  Training Loss: 0.0000\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7560\n",
            "  Validation Char Acc: 0.8389\n",
            "  Learning Rate: 0.000007\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'HERE' | Pred: 'HERE'\n",
            "  True: 'TO' | Pred: 'TO'\n",
            "  True: 'SPACE' | Pred: 'SPACE'\n",
            "  True: 'COOPER' | Pred: 'COOPER'\n",
            "  True: 'NURSERY' | Pred: 'HORSEEY'\n",
            "\n",
            "📈 Epoch 238/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.07it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 238 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8350\n",
            "  Learning Rate: 0.000006\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CAN' | Pred: 'CAN'\n",
            "  True: '50' | Pred: '50'\n",
            "  True: '25' | Pred: '25'\n",
            "  True: 'PRODAJA' | Pred: 'PRODAJA'\n",
            "  True: 'YOURE' | Pred: 'YOURE'\n",
            "\n",
            "📈 Epoch 239/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.99it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 239 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8361\n",
            "  Learning Rate: 0.000005\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'BLUBBER' | Pred: 'BLUBBER'\n",
            "  True: 'CITY' | Pred: 'CITY'\n",
            "  True: '22' | Pred: '88'\n",
            "  True: '4' | Pred: '4'\n",
            "  True: 'HITAM' | Pred: 'HITAM'\n",
            "\n",
            "📈 Epoch 240/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.50it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 240 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8411\n",
            "  Learning Rate: 0.000004\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '930' | Pred: '930'\n",
            "  True: 'INSTORE' | Pred: 'INSTORE'\n",
            "  True: 'BANK' | Pred: 'BANK'\n",
            "  True: 'HOUSE' | Pred: 'HOUSE'\n",
            "  True: 'BUT' | Pred: 'BUT'\n",
            "\n",
            "📈 Epoch 241/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.33it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 241 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8376\n",
            "  Learning Rate: 0.000003\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'INDIA' | Pred: 'INDIA'\n",
            "  True: 'ON' | Pred: 'ON'\n",
            "  True: '3D' | Pred: '3D'\n",
            "  True: 'LOW' | Pred: 'LOW'\n",
            "  True: 'CHANGE' | Pred: 'CHANGE'\n",
            "\n",
            "📈 Epoch 242/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.11it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 242 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8378\n",
            "  Learning Rate: 0.000003\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'UNE' | Pred: 'UNE'\n",
            "  True: 'POSSOBILITIES' | Pred: 'POSSIBITES'\n",
            "  True: '63' | Pred: '63'\n",
            "  True: 'LOSE' | Pred: 'LOSE'\n",
            "  True: '60602974' | Pred: '60602974'\n",
            "\n",
            "📈 Epoch 243/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 15.97it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 243 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8391\n",
            "  Learning Rate: 0.000002\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '02' | Pred: '02'\n",
            "  True: 'CATE' | Pred: 'CATE'\n",
            "  True: 'ECO' | Pred: 'ECO'\n",
            "  True: 'CITROEN' | Pred: 'CITROEN'\n",
            "  True: 'COM' | Pred: 'COM'\n",
            "\n",
            "📈 Epoch 244/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.61it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 244 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7620\n",
            "  Validation Char Acc: 0.8397\n",
            "  Learning Rate: 0.000001\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '95' | Pred: '95'\n",
            "  True: 'ROUTH' | Pred: 'POUTH'\n",
            "  True: 'VIEW' | Pred: 'VIEW'\n",
            "  True: '2' | Pred: '2'\n",
            "  True: 'MIRREN' | Pred: 'MIRREN'\n",
            "\n",
            "📈 Epoch 245/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.60it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 245 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8365\n",
            "  Learning Rate: 0.000001\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: '280' | Pred: '280'\n",
            "  True: 'METER' | Pred: 'METER'\n",
            "  True: 'REVERSE' | Pred: 'REVERSE'\n",
            "  True: 'PEACE' | Pred: 'REACE'\n",
            "  True: 'VALE' | Pred: 'VALE'\n",
            "\n",
            "📈 Epoch 246/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.06it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 246 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7620\n",
            "  Validation Char Acc: 0.8378\n",
            "  Learning Rate: 0.000001\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'ECO' | Pred: 'ECO'\n",
            "  True: 'WITH' | Pred: 'WITH'\n",
            "  True: 'NOW' | Pred: 'NAY'\n",
            "  True: '3D' | Pred: '8'\n",
            "  True: 'KELLIMAR' | Pred: 'KEAMMA'\n",
            "\n",
            "📈 Epoch 247/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.18it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 247 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7580\n",
            "  Validation Char Acc: 0.8353\n",
            "  Learning Rate: 0.000000\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'CHIC' | Pred: 'CHIC'\n",
            "  True: 'RESIST' | Pred: 'HESTST'\n",
            "  True: 'BEEN' | Pred: 'BEEN'\n",
            "  True: 'A' | Pred: 'A'\n",
            "  True: '120' | Pred: '120'\n",
            "\n",
            "📈 Epoch 248/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.31it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 248 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8428\n",
            "  Learning Rate: 0.000000\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'NOW' | Pred: 'NAY'\n",
            "  True: 'STATE' | Pred: 'STATE'\n",
            "  True: 'BLUE' | Pred: 'BLUE'\n",
            "  True: 'SBI' | Pred: 'SBR'\n",
            "  True: '2ND' | Pred: '2ND'\n",
            "\n",
            "📈 Epoch 249/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.61it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 249 Summary:\n",
            "  Training Loss: 0.0001\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7600\n",
            "  Validation Char Acc: 0.8391\n",
            "  Learning Rate: 0.000000\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'LEAGUE' | Pred: 'LEAGUE'\n",
            "  True: 'NOT' | Pred: 'NOT'\n",
            "  True: 'DREAM' | Pred: 'DREAM'\n",
            "  True: 'POD' | Pred: 'POD'\n",
            "  True: 'HOME' | Pred: 'HOME'\n",
            "\n",
            "📈 Epoch 250/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 141/141 [00:08<00:00, 16.11it/s, loss=0.000, word_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 250 Summary:\n",
            "  Training Loss: 0.0000\n",
            "  Training Word Acc: 1.0000\n",
            "  Validation Word Acc: 0.7620\n",
            "  Validation Char Acc: 0.8391\n",
            "  Learning Rate: 0.000000\n",
            "\n",
            "🎯 Sample predictions:\n",
            "  True: 'JALAN' | Pred: 'JALAN'\n",
            "  True: 'BACK' | Pred: 'BACK'\n",
            "  True: 'CUSTOMERS' | Pred: 'CISTOMERS'\n",
            "  True: 'PEACE' | Pred: 'REACE'\n",
            "  True: 'ROOM' | Pred: 'POORI'\n",
            "\n",
            "🎉 Training completed!\n",
            "Best validation word accuracy: 0.7680\n",
            "\n",
            "🏆 Final result: 0.7680 word accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# enhanced_deep_ocr.py\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "import scipy.io\n",
        "import random\n",
        "import math\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# ======================\n",
        "# 1. ENHANCED DATASET WITH AUGMENTATION\n",
        "# ======================\n",
        "class EnhancedCustomSplitIIIT5KDataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', img_height=32, img_width=128,\n",
        "                 train_samples=4500, test_samples=500, random_seed=42, augment=True):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.iiit5k_dir = os.path.join(root_dir, \"IIIT5K\")\n",
        "        self.augment = augment and split == 'train'\n",
        "\n",
        "        # Set random seed for reproducible splits\n",
        "        random.seed(random_seed)\n",
        "        np.random.seed(random_seed)\n",
        "\n",
        "        # Define vocabulary\n",
        "        self.chars = string.ascii_letters + string.digits + \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
        "        self.char_to_idx = {char: idx + 1 for idx, char in enumerate(self.chars)}\n",
        "        self.idx_to_char = {idx + 1: char for idx, char in enumerate(self.chars)}\n",
        "        self.idx_to_char[0] = '<BLANK>'\n",
        "        self.num_classes = len(self.chars) + 1  # 95 + 1\n",
        "\n",
        "        print(f\"Creating custom dataset split with {train_samples} train, {test_samples} test samples...\")\n",
        "\n",
        "        # Load all data from both original train and test sets\n",
        "        all_samples = []\n",
        "\n",
        "        # Load original train data\n",
        "        train_mat_file = os.path.join(self.iiit5k_dir, \"traindata.mat\")\n",
        "        train_data_dir = os.path.join(self.iiit5k_dir, \"train\")\n",
        "        if os.path.exists(train_mat_file):\n",
        "            all_samples.extend(self._load_mat_data(train_mat_file, train_data_dir, \"train\"))\n",
        "\n",
        "        # Load original test data\n",
        "        test_mat_file = os.path.join(self.iiit5k_dir, \"testdata.mat\")\n",
        "        test_data_dir = os.path.join(self.iiit5k_dir, \"test\")\n",
        "        if os.path.exists(test_mat_file):\n",
        "            all_samples.extend(self._load_mat_data(test_mat_file, test_data_dir, \"test\"))\n",
        "\n",
        "        print(f\"Total samples loaded: {len(all_samples)}\")\n",
        "\n",
        "        # Shuffle all samples for random split\n",
        "        random.shuffle(all_samples)\n",
        "\n",
        "        # Create custom train/test split\n",
        "        total_needed = train_samples + test_samples\n",
        "        if len(all_samples) < total_needed:\n",
        "            print(f\"⚠️ Warning: Only {len(all_samples)} samples available, but {total_needed} requested\")\n",
        "            train_samples = min(train_samples, len(all_samples) - test_samples)\n",
        "            test_samples = len(all_samples) - train_samples\n",
        "\n",
        "        if split == 'train':\n",
        "            self.samples = all_samples[:train_samples]\n",
        "            print(f\"✅ Created training set with {len(self.samples)} samples\")\n",
        "        else:  # test\n",
        "            self.samples = all_samples[train_samples:train_samples + test_samples]\n",
        "            print(f\"✅ Created test set with {len(self.samples)} samples\")\n",
        "\n",
        "        if self.samples:\n",
        "            sample_texts = [t for _, t in self.samples[:10]]\n",
        "            lengths = [len(t) for _, t in self.samples]\n",
        "            print(f\"Sample texts: {sample_texts}\")\n",
        "            print(f\"Text lengths: min={min(lengths)}, max={max(lengths)}, avg={np.mean(lengths):.1f}\")\n",
        "            print(f\"Vocabulary size: {self.num_classes}\")\n",
        "\n",
        "        # Enhanced transforms with augmentation\n",
        "        if self.augment:\n",
        "            self.transform = T.Compose([\n",
        "                T.ToPILImage(),\n",
        "                T.Resize((img_height, img_width), antialias=True),\n",
        "                T.Grayscale(),\n",
        "                # Data augmentation\n",
        "                T.RandomApply([T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))], p=0.3),\n",
        "                T.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "                T.RandomApply([T.RandomRotation(degrees=2)], p=0.2),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize((0.5,), (0.5,))  # [-1, 1]\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = T.Compose([\n",
        "                T.ToPILImage(),\n",
        "                T.Resize((img_height, img_width), antialias=True),\n",
        "                T.Grayscale(),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize((0.5,), (0.5,))  # [-1, 1]\n",
        "            ])\n",
        "\n",
        "    def _load_mat_data(self, mat_file, data_dir, original_split):\n",
        "        \"\"\"Load data from .mat file and return list of (img_path, text) tuples\"\"\"\n",
        "        samples = []\n",
        "\n",
        "        try:\n",
        "            mat_data = scipy.io.loadmat(mat_file)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load {mat_file}: {e}\")\n",
        "            return samples\n",
        "\n",
        "        data_key = f\"{original_split}data\"\n",
        "        if data_key not in mat_data:\n",
        "            available = [k for k in mat_data.keys() if not k.startswith('__')]\n",
        "            print(f\"❌ Key '{data_key}' not found in {mat_file}. Available: {available}\")\n",
        "            return samples\n",
        "\n",
        "        data = mat_data[data_key]\n",
        "        N = data.shape[1] if data.shape[0] == 1 else data.shape[0]\n",
        "        print(f\"Processing {N} samples from {original_split} data...\")\n",
        "\n",
        "        for i in range(N):\n",
        "            try:\n",
        "                sample = data[0, i] if data.shape[0] == 1 else data[i, 0]\n",
        "\n",
        "                # Extract image path\n",
        "                img_name = self._safe_extract_string(sample[0])\n",
        "                if not img_name:\n",
        "                    img_filename = f\"sample_{i}.png\"\n",
        "                else:\n",
        "                    img_filename = os.path.basename(img_name.strip())\n",
        "                img_path = os.path.join(data_dir, img_filename)\n",
        "\n",
        "                # Extract text\n",
        "                text = self._safe_extract_string(sample[3])\n",
        "                text = self._clean_text(text)\n",
        "\n",
        "                if os.path.exists(img_path) and 1 <= len(text) <= 23:\n",
        "                    samples.append((img_path, text))\n",
        "\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def _safe_extract_string(self, data):\n",
        "        \"\"\"Robustly extract string from .mat field (handles str, numeric array, object array)\"\"\"\n",
        "        try:\n",
        "            if isinstance(data, str):\n",
        "                return data.strip()\n",
        "\n",
        "            if isinstance(data, np.ndarray):\n",
        "                # Case 1: Numeric array (ASCII codes)\n",
        "                if np.issubdtype(data.dtype, np.number):\n",
        "                    chars = []\n",
        "                    for c in data.flatten():\n",
        "                        try:\n",
        "                            c_int = int(c)\n",
        "                            if 32 <= c_int <= 126:  # Printable ASCII\n",
        "                                chars.append(chr(c_int))\n",
        "                        except (ValueError, TypeError):\n",
        "                            continue\n",
        "                    return ''.join(chars).strip()\n",
        "\n",
        "                # Case 2: String array (U/S dtype)\n",
        "                elif data.dtype.kind in ['U', 'S']:\n",
        "                    return str(data.flatten()[0]).strip() if data.size > 0 else \"\"\n",
        "\n",
        "                # Case 3: Object array (common in scipy.io.loadmat)\n",
        "                elif data.dtype == np.object_:\n",
        "                    item = data.item() if data.size == 1 else data[0]\n",
        "                    if isinstance(item, str):\n",
        "                        return item.strip()\n",
        "                    return self._safe_extract_string(item)\n",
        "\n",
        "            return str(data).strip()\n",
        "        except Exception as e:\n",
        "            return \"\"\n",
        "\n",
        "    def _clean_text(self, text):\n",
        "        \"\"\"Keep only valid characters in full ASCII set\"\"\"\n",
        "        return ''.join(c for c in text if c in self.chars).strip()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, text = self.samples[idx]\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            print(f\"⚠️ Warning: Failed to load image {img_path}, using blank\")\n",
        "            img = np.ones((self.img_height, self.img_width), dtype=np.uint8) * 255\n",
        "\n",
        "        # Additional noise augmentation for training\n",
        "        if self.augment and random.random() < 0.2:\n",
        "            noise = np.random.normal(0, 10, img.shape).astype(np.uint8)\n",
        "            img = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
        "\n",
        "        text_indices = [self.char_to_idx[char] for char in text if char in self.char_to_idx]\n",
        "        img_tensor = self.transform(img)\n",
        "        return img_tensor, text_indices, text\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 2. ENHANCED CRNN MODEL WITH ATTENTION\n",
        "# ======================\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "class EnhancedDeepCRNN(nn.Module):\n",
        "    def __init__(self, img_height=32, num_classes=96, hidden_size=256, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Enhanced CNN backbone with residual connections\n",
        "        self.cnn = nn.Sequential(\n",
        "            # Stage 1\n",
        "            nn.Conv2d(1, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout2d(0.1),\n",
        "\n",
        "            # Stage 2\n",
        "            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout2d(0.1),\n",
        "\n",
        "            # Stage 3\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 1), (2, 1)),\n",
        "            nn.Dropout2d(0.1),\n",
        "\n",
        "            # Stage 4\n",
        "            nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 1), (2, 1)),\n",
        "            nn.Dropout2d(0.1),\n",
        "\n",
        "            # Stage 5\n",
        "            nn.Conv2d(512, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 1), (2, 1)),\n",
        "        )\n",
        "\n",
        "        # Enhanced RNN with more layers and higher capacity\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=512,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=3,  # Increased from 2\n",
        "            bidirectional=True,\n",
        "            batch_first=False,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_size * 2,\n",
        "            num_heads=8,\n",
        "            dropout=dropout,\n",
        "            batch_first=False\n",
        "        )\n",
        "\n",
        "        # Positional encoding for attention\n",
        "        self.pos_encoding = PositionalEncoding(hidden_size * 2)\n",
        "\n",
        "        # Classification layers with residual connection\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, num_classes)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.LSTM):\n",
        "                for name, param in m.named_parameters():\n",
        "                    if 'weight' in name:\n",
        "                        nn.init.xavier_uniform_(param)\n",
        "                    elif 'bias' in name:\n",
        "                        nn.init.constant_(param, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN feature extraction\n",
        "        conv = self.cnn(x)  # [B, 512, 1, W]\n",
        "        b, c, h, w = conv.size()\n",
        "        conv = conv.view(b, c * h, w).permute(2, 0, 1)  # [W, B, 512]\n",
        "\n",
        "        # RNN processing\n",
        "        rnn_out, _ = self.rnn(conv)  # [W, B, hidden_size*2]\n",
        "        rnn_out = self.dropout(rnn_out)\n",
        "\n",
        "        # Add positional encoding and apply attention\n",
        "        rnn_out_pe = self.pos_encoding(rnn_out)\n",
        "        attended_out, _ = self.attention(rnn_out_pe, rnn_out_pe, rnn_out_pe)\n",
        "\n",
        "        # Residual connection\n",
        "        attended_out = attended_out + rnn_out\n",
        "        attended_out = self.dropout(attended_out)\n",
        "\n",
        "        # Classification\n",
        "        output = self.classifier(attended_out)\n",
        "        return F.log_softmax(output, dim=2)\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 3. ENHANCED CTC UTILITIES WITH BEAM SEARCH\n",
        "# ======================\n",
        "def ctc_collate_fn(batch):\n",
        "    images, text_indices_list, raw_texts = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "    targets = []\n",
        "    target_lengths = []\n",
        "    for text_indices in text_indices_list:\n",
        "        if len(text_indices) > 0:\n",
        "            targets.extend(text_indices)\n",
        "            target_lengths.append(len(text_indices))\n",
        "        else:\n",
        "            targets.append(0)\n",
        "            target_lengths.append(1)\n",
        "    return images, torch.tensor(targets), torch.tensor(target_lengths), raw_texts\n",
        "\n",
        "def beam_search_decode(log_probs, idx_to_char, beam_width=5, blank_idx=0):\n",
        "    \"\"\"Beam search CTC decoding for better accuracy\"\"\"\n",
        "    seq_len, batch_size, num_classes = log_probs.shape\n",
        "    predictions = []\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        probs = log_probs[:, b, :].exp().cpu().numpy()  # Convert to probabilities\n",
        "\n",
        "        # Initialize beam\n",
        "        beam = [([], 0.0)]  # (sequence, log_prob)\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            new_beam = []\n",
        "\n",
        "            for seq, log_prob in beam:\n",
        "                for c in range(num_classes):\n",
        "                    new_log_prob = log_prob + np.log(probs[t, c] + 1e-8)\n",
        "\n",
        "                    if c == blank_idx:\n",
        "                        # Blank - no character added\n",
        "                        new_beam.append((seq, new_log_prob))\n",
        "                    else:\n",
        "                        # Character\n",
        "                        if len(seq) == 0 or seq[-1] != c:\n",
        "                            # New character or different from previous\n",
        "                            new_seq = seq + [c]\n",
        "                            new_beam.append((new_seq, new_log_prob))\n",
        "                        else:\n",
        "                            # Same as previous - don't add\n",
        "                            new_beam.append((seq, new_log_prob))\n",
        "\n",
        "            # Keep top beam_width candidates\n",
        "            beam = sorted(new_beam, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "\n",
        "        # Get best sequence\n",
        "        best_seq = beam[0][0]\n",
        "        decoded_text = ''.join([idx_to_char.get(idx, '') for idx in best_seq if idx in idx_to_char])\n",
        "        predictions.append(decoded_text)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def ctc_decode(log_probs, idx_to_char, blank_idx=0, use_beam_search=False, beam_width=5):\n",
        "    \"\"\"Enhanced CTC decoding with optional beam search\"\"\"\n",
        "    if use_beam_search:\n",
        "        return beam_search_decode(log_probs, idx_to_char, beam_width, blank_idx)\n",
        "\n",
        "    # Standard greedy decoding\n",
        "    seq_len, batch_size, num_classes = log_probs.shape\n",
        "    predictions = []\n",
        "    for b in range(batch_size):\n",
        "        pred_indices = log_probs[:, b, :].argmax(dim=1).cpu().numpy()\n",
        "        decoded = []\n",
        "        prev_idx = blank_idx\n",
        "        for idx in pred_indices:\n",
        "            if idx != blank_idx and idx != prev_idx:\n",
        "                if idx in idx_to_char and idx_to_char[idx] != '<BLANK>':\n",
        "                    decoded.append(idx_to_char[idx])\n",
        "            prev_idx = idx\n",
        "        predictions.append(''.join(decoded))\n",
        "    return predictions\n",
        "\n",
        "def calculate_metrics(pred_texts, true_texts):\n",
        "    \"\"\"Calculate word and character accuracy\"\"\"\n",
        "    if not pred_texts or not true_texts:\n",
        "        return 0.0, 0.0\n",
        "    word_acc = sum(p == t for p, t in zip(pred_texts, true_texts)) / len(true_texts)\n",
        "    total_chars = sum(max(len(p), len(t)) for p, t in zip(pred_texts, true_texts))\n",
        "    if total_chars == 0:\n",
        "        return word_acc, 0.0\n",
        "    correct_chars = sum(p[i] == t[i] for p, t in zip(pred_texts, true_texts) for i in range(min(len(p), len(t))))\n",
        "    char_acc = correct_chars / total_chars\n",
        "    return word_acc, char_acc\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 4. ENHANCED TRAINING WITH EARLY STOPPING AND MIXED PRECISION\n",
        "# ======================\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=20, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_score):\n",
        "        if self.best_score is None:\n",
        "            self.best_score = val_score\n",
        "        elif val_score < self.best_score + self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = val_score\n",
        "            self.counter = 0\n",
        "\n",
        "def train_enhanced_deep_ocr():\n",
        "    print(\"🚀 ENHANCED DEEP OCR TRAINING WITH IMPROVEMENTS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # CONFIGURATION\n",
        "    dataset_root = \"/content/iiit5k_dataset\"\n",
        "\n",
        "    # Verify dataset exists\n",
        "    print(f\"🔍 Checking dataset root: {dataset_root}\")\n",
        "    print(f\"📁 Path exists: {os.path.exists(dataset_root)}\")\n",
        "\n",
        "    if not os.path.exists(dataset_root):\n",
        "        alternative_paths = [\"./iiit5k_dataset\", \"/content/iiit5k_dataset\"]\n",
        "        for alt_path in alternative_paths:\n",
        "            if os.path.exists(alt_path):\n",
        "                dataset_root = alt_path\n",
        "                print(f\"✅ Found dataset at alternative path: {dataset_root}\")\n",
        "                break\n",
        "        else:\n",
        "            print(f\"❌ Dataset root not found at any location\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"✅ Dataset root found: {dataset_root}\")\n",
        "\n",
        "    # Verify IIIT5K subdirectory structure\n",
        "    iiit5k_path = os.path.join(dataset_root, \"IIIT5K\")\n",
        "    print(f\"🔍 Checking IIIT5K path: {iiit5k_path}\")\n",
        "    print(f\"📁 IIIT5K exists: {os.path.exists(iiit5k_path)}\")\n",
        "\n",
        "    if os.path.exists(iiit5k_path):\n",
        "        contents = os.listdir(iiit5k_path)\n",
        "        print(f\"📊 IIIT5K contents: {contents}\")\n",
        "        required_items = ['train', 'test', 'traindata.mat', 'testdata.mat']\n",
        "        missing_items = [item for item in required_items if item not in contents]\n",
        "        if missing_items:\n",
        "            print(f\"❌ Missing required items: {missing_items}\")\n",
        "            return None\n",
        "        else:\n",
        "            print(\"✅ All required dataset components found!\")\n",
        "    else:\n",
        "        print(f\"❌ IIIT5K subdirectory not found at: {iiit5k_path}\")\n",
        "        return None\n",
        "\n",
        "    # Enhanced hyperparameters\n",
        "    batch_size = 32\n",
        "    max_epochs = 200  # Reduced since we have early stopping\n",
        "    learning_rate = 2e-3  # Slightly higher for OneCycle\n",
        "    train_samples = 4500\n",
        "    test_samples = 500\n",
        "    hidden_size = 256  # Increased capacity\n",
        "    dropout = 0.3\n",
        "\n",
        "    print(f\"Enhanced configuration:\")\n",
        "    print(f\"  Custom split: {train_samples} train, {test_samples} test\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    print(f\"  Max epochs: {max_epochs}\")\n",
        "    print(f\"  Learning rate: {learning_rate}\")\n",
        "    print(f\"  Hidden size: {hidden_size}\")\n",
        "    print(f\"  Dropout: {dropout}\")\n",
        "\n",
        "    # Load enhanced datasets with augmentation\n",
        "    print(\"\\nCreating enhanced datasets with augmentation...\")\n",
        "    try:\n",
        "        train_dataset = EnhancedCustomSplitIIIT5KDataset(\n",
        "            dataset_root, 'train', 32, 128, train_samples, test_samples, augment=True\n",
        "        )\n",
        "        test_dataset = EnhancedCustomSplitIIIT5KDataset(\n",
        "            dataset_root, 'test', 32, 128, train_samples, test_samples, augment=False\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Dataset creation failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    if len(train_dataset) == 0 or len(test_dataset) == 0:\n",
        "        print(\"❌ No valid data loaded.\")\n",
        "        return None\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                              collate_fn=ctc_collate_fn, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                             collate_fn=ctc_collate_fn, num_workers=2, pin_memory=True)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"\\nDevice: {device}\")\n",
        "\n",
        "    # Enhanced model\n",
        "    model = EnhancedDeepCRNN(32, train_dataset.num_classes, hidden_size, dropout).to(device)\n",
        "    criterion = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
        "\n",
        "    # OneCycle learning rate scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = OneCycleLR(optimizer, max_lr=learning_rate,\n",
        "                          steps_per_epoch=len(train_loader), epochs=max_epochs)\n",
        "\n",
        "    # Mixed precision training\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping = EarlyStopping(patience=25, min_delta=0.001)\n",
        "\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(f\"Training batches: {len(train_loader)}\")\n",
        "    print(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "    best_word_acc = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_word_acc = 0.0\n",
        "        num_train_batches = 0\n",
        "\n",
        "        print(f\"\\n📈 Epoch {epoch+1}/{max_epochs}\")\n",
        "        pbar = tqdm(train_loader, desc=\"Training\")\n",
        "\n",
        "        for images, targets, target_lengths, raw_texts in pbar:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            targets = targets.to(device, non_blocking=True)\n",
        "            target_lengths = target_lengths.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Mixed precision forward pass\n",
        "            with autocast():\n",
        "                log_probs = model(images)\n",
        "                input_lengths = torch.full((images.size(0),), log_probs.size(0),\n",
        "                                         device=device, dtype=torch.long)\n",
        "                loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
        "\n",
        "            # Mixed precision backward pass\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy every 20 batches\n",
        "            if num_train_batches % 20 == 0:\n",
        "                pred_texts = ctc_decode(log_probs.cpu(), train_dataset.idx_to_char)\n",
        "                word_acc, _ = calculate_metrics(pred_texts, raw_texts)\n",
        "                train_word_acc += word_acc\n",
        "                pbar.set_postfix({\"loss\": f\"{loss.item():.3f}\", \"word_acc\": f\"{word_acc:.3f}\"})\n",
        "\n",
        "            num_train_batches += 1\n",
        "\n",
        "        train_loss /= num_train_batches\n",
        "        train_word_acc /= (num_train_batches // 20 + 1)\n",
        "\n",
        "        # Validation with beam search\n",
        "        model.eval()\n",
        "        val_preds, val_truths = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, targets, target_lengths, raw_texts in test_loader:\n",
        "                images = images.to(device, non_blocking=True)\n",
        "                with autocast():\n",
        "                    log_probs = model(images)\n",
        "                # Use beam search for validation\n",
        "                pred_texts = ctc_decode(log_probs.cpu(), test_dataset.idx_to_char,\n",
        "                                      use_beam_search=True, beam_width=3)\n",
        "                val_preds.extend(pred_texts)\n",
        "                val_truths.extend(raw_texts)\n",
        "\n",
        "        val_word_acc, val_char_acc = calculate_metrics(val_preds, val_truths)\n",
        "\n",
        "        print(f\"\\n📊 Epoch {epoch+1} Summary:\")\n",
        "        print(f\"  Training Loss: {train_loss:.4f}\")\n",
        "        print(f\"  Training Word Acc: {train_word_acc:.4f}\")\n",
        "        print(f\"  Validation Word Acc: {val_word_acc:.4f}\")\n",
        "        print(f\"  Validation Char Acc: {val_char_acc:.4f}\")\n",
        "        print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_word_acc > best_word_acc:\n",
        "            best_word_acc = val_word_acc\n",
        "            patience_counter = 0\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_word_acc': val_word_acc,\n",
        "                'val_char_acc': val_char_acc,\n",
        "                'idx_to_char': train_dataset.idx_to_char,\n",
        "                'num_classes': train_dataset.num_classes,\n",
        "                'hidden_size': hidden_size\n",
        "            }, 'enhanced_deep_ocr_model.pth')\n",
        "            print(f\"  ✅ New best model saved! Word Acc: {best_word_acc:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping check\n",
        "        early_stopping(val_word_acc)\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"🛑 Early stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        # Sample predictions\n",
        "        print(f\"\\n🎯 Sample predictions (with beam search):\")\n",
        "        indices = np.random.choice(len(val_preds), min(5, len(val_preds)), replace=False)\n",
        "        for i in indices:\n",
        "            print(f\"  True: '{val_truths[i]}' | Pred: '{val_preds[i]}'\")\n",
        "\n",
        "    print(f\"\\n🎉 Training completed!\")\n",
        "    print(f\"Best validation word accuracy: {best_word_acc:.4f}\")\n",
        "    return best_word_acc\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 5. MODEL INFERENCE WITH BEAM SEARCH\n",
        "# ======================\n",
        "def load_and_test_model(model_path, test_images_dir=None):\n",
        "    \"\"\"Load trained model and test on new images\"\"\"\n",
        "    print(\"🔍 Loading trained model...\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "    # Recreate model\n",
        "    model = EnhancedDeepCRNN(\n",
        "        img_height=32,\n",
        "        num_classes=checkpoint['num_classes'],\n",
        "        hidden_size=checkpoint.get('hidden_size', 256)\n",
        "    ).to(device)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    idx_to_char = checkpoint['idx_to_char']\n",
        "\n",
        "    print(f\"✅ Model loaded successfully!\")\n",
        "    print(f\"   Validation Word Accuracy: {checkpoint['val_word_acc']:.4f}\")\n",
        "    print(f\"   Validation Char Accuracy: {checkpoint['val_char_acc']:.4f}\")\n",
        "\n",
        "    # Transform for inference\n",
        "    transform = T.Compose([\n",
        "        T.ToPILImage(),\n",
        "        T.Resize((32, 128), antialias=True),\n",
        "        T.Grayscale(),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    def predict_text(image_path):\n",
        "        \"\"\"Predict text from single image\"\"\"\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            return \"Error: Could not load image\"\n",
        "\n",
        "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with autocast():\n",
        "                log_probs = model(img_tensor)\n",
        "\n",
        "            # Use beam search for better accuracy\n",
        "            pred_texts = ctc_decode(log_probs.cpu(), idx_to_char,\n",
        "                                  use_beam_search=True, beam_width=5)\n",
        "            return pred_texts[0]\n",
        "\n",
        "    return predict_text\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 6. ADVANCED EVALUATION METRICS\n",
        "# ======================\n",
        "def detailed_evaluation(model, test_loader, idx_to_char, device):\n",
        "    \"\"\"Comprehensive model evaluation with detailed metrics\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_truths = []\n",
        "    char_confusion = {}\n",
        "    length_accuracy = {i: {'correct': 0, 'total': 0} for i in range(1, 21)}\n",
        "\n",
        "    print(\"🔍 Running detailed evaluation...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets, target_lengths, raw_texts in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "\n",
        "            with autocast():\n",
        "                log_probs = model(images)\n",
        "\n",
        "            # Get predictions with both greedy and beam search\n",
        "            greedy_preds = ctc_decode(log_probs.cpu(), idx_to_char, use_beam_search=False)\n",
        "            beam_preds = ctc_decode(log_probs.cpu(), idx_to_char, use_beam_search=True, beam_width=5)\n",
        "\n",
        "            all_preds.extend(beam_preds)\n",
        "            all_truths.extend(raw_texts)\n",
        "\n",
        "            # Length-based accuracy\n",
        "            for pred, truth in zip(beam_preds, raw_texts):\n",
        "                length = min(len(truth), 20)\n",
        "                length_accuracy[length]['total'] += 1\n",
        "                if pred == truth:\n",
        "                    length_accuracy[length]['correct'] += 1\n",
        "\n",
        "            # Character-level confusion analysis\n",
        "            for pred, truth in zip(beam_preds, raw_texts):\n",
        "                for i, (p_char, t_char) in enumerate(zip(pred, truth)):\n",
        "                    if t_char not in char_confusion:\n",
        "                        char_confusion[t_char] = {'correct': 0, 'total': 0, 'confused_with': {}}\n",
        "                    char_confusion[t_char]['total'] += 1\n",
        "                    if p_char == t_char:\n",
        "                        char_confusion[t_char]['correct'] += 1\n",
        "                    else:\n",
        "                        if p_char not in char_confusion[t_char]['confused_with']:\n",
        "                            char_confusion[t_char]['confused_with'][p_char] = 0\n",
        "                        char_confusion[t_char]['confused_with'][p_char] += 1\n",
        "\n",
        "    # Calculate overall metrics\n",
        "    word_acc, char_acc = calculate_metrics(all_preds, all_truths)\n",
        "\n",
        "    print(f\"\\n📊 Detailed Evaluation Results:\")\n",
        "    print(f\"   Overall Word Accuracy: {word_acc:.4f}\")\n",
        "    print(f\"   Overall Character Accuracy: {char_acc:.4f}\")\n",
        "\n",
        "    # Length-based accuracy\n",
        "    print(f\"\\n📏 Accuracy by text length:\")\n",
        "    for length in range(1, 11):  # Show first 10 lengths\n",
        "        if length_accuracy[length]['total'] > 0:\n",
        "            acc = length_accuracy[length]['correct'] / length_accuracy[length]['total']\n",
        "            print(f\"   Length {length}: {acc:.3f} ({length_accuracy[length]['correct']}/{length_accuracy[length]['total']})\")\n",
        "\n",
        "    # Most confused characters\n",
        "    print(f\"\\n🔤 Most problematic characters:\")\n",
        "    char_errors = []\n",
        "    for char, stats in char_confusion.items():\n",
        "        if stats['total'] > 5:  # Only consider characters that appear frequently\n",
        "            error_rate = 1 - (stats['correct'] / stats['total'])\n",
        "            char_errors.append((char, error_rate, stats['total']))\n",
        "\n",
        "    char_errors.sort(key=lambda x: x[1], reverse=True)\n",
        "    for char, error_rate, total in char_errors[:10]:\n",
        "        print(f\"   '{char}': {error_rate:.3f} error rate ({total} samples)\")\n",
        "        # Show top confusions\n",
        "        if char in char_confusion and char_confusion[char]['confused_with']:\n",
        "            top_confusions = sorted(char_confusion[char]['confused_with'].items(),\n",
        "                                  key=lambda x: x[1], reverse=True)[:3]\n",
        "            confusion_str = ', '.join([f\"'{conf_char}'({count})\" for conf_char, count in top_confusions])\n",
        "            print(f\"      → Often confused with: {confusion_str}\")\n",
        "\n",
        "    return word_acc, char_acc\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 7. MAIN EXECUTION WITH ENHANCED OPTIONS\n",
        "# ======================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"⚡ ENHANCED DEEP OCR SYSTEM\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nChoose option:\")\n",
        "        print(\"1. Train enhanced model with improvements\")\n",
        "        print(\"2. Load and test existing model\")\n",
        "        print(\"3. Detailed evaluation of existing model\")\n",
        "        print(\"4. Exit\")\n",
        "\n",
        "        choice = input(\"Choice: \")\n",
        "\n",
        "        if choice == \"1\":\n",
        "            print(\"\\n🚀 Starting enhanced training...\")\n",
        "            accuracy = train_enhanced_deep_ocr()\n",
        "            if accuracy is not None:\n",
        "                print(f\"\\n🏆 Final result: {accuracy:.4f} word accuracy\")\n",
        "                print(\"✅ Model saved as 'enhanced_deep_ocr_model.pth'\")\n",
        "            else:\n",
        "                print(\"\\n❌ Training failed. Check error messages above.\")\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            model_path = input(\"Enter model path (default: enhanced_deep_ocr_model.pth): \")\n",
        "            if not model_path:\n",
        "                model_path = \"enhanced_deep_ocr_model.pth\"\n",
        "\n",
        "            if not os.path.exists(model_path):\n",
        "                print(f\"❌ Model file not found: {model_path}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                predict_fn = load_and_test_model(model_path)\n",
        "\n",
        "                while True:\n",
        "                    image_path = input(\"\\nEnter image path (or 'back' to return): \")\n",
        "                    if image_path.lower() == 'back':\n",
        "                        break\n",
        "\n",
        "                    if not os.path.exists(image_path):\n",
        "                        print(f\"❌ Image not found: {image_path}\")\n",
        "                        continue\n",
        "\n",
        "                    result = predict_fn(image_path)\n",
        "                    print(f\"🎯 Predicted text: '{result}'\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error loading model: {e}\")\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            model_path = input(\"Enter model path (default: enhanced_deep_ocr_model.pth): \")\n",
        "            if not model_path:\n",
        "                model_path = \"enhanced_deep_ocr_model.pth\"\n",
        "\n",
        "            if not os.path.exists(model_path):\n",
        "                print(f\"❌ Model file not found: {model_path}\")\n",
        "                continue\n",
        "\n",
        "            # Load test dataset for evaluation\n",
        "            dataset_root = \"/content/iiit5k_dataset\"\n",
        "            try:\n",
        "                test_dataset = EnhancedCustomSplitIIIT5KDataset(\n",
        "                    dataset_root, 'test', 32, 128, 4500, 500, augment=False\n",
        "                )\n",
        "                test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
        "                                       collate_fn=ctc_collate_fn, num_workers=2)\n",
        "\n",
        "                # Load model\n",
        "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "                checkpoint = torch.load(model_path, map_location=device)\n",
        "                model = EnhancedDeepCRNN(\n",
        "                    img_height=32,\n",
        "                    num_classes=checkpoint['num_classes'],\n",
        "                    hidden_size=checkpoint.get('hidden_size', 256)\n",
        "                ).to(device)\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "                # Run detailed evaluation\n",
        "                detailed_evaluation(model, test_loader, checkpoint['idx_to_char'], device)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error during evaluation: {e}\")\n",
        "\n",
        "        elif choice == \"4\":\n",
        "            print(\"Goodbye! 👋\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"❌ Invalid choice. Please try again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEVGsp3BTp4t",
        "outputId": "19a0f191-9a17-4877-d2be-97bafc2022a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚡ ENHANCED DEEP OCR SYSTEM\n",
            "==================================================\n",
            "\n",
            "Choose option:\n",
            "1. Train enhanced model with improvements\n",
            "2. Load and test existing model\n",
            "3. Detailed evaluation of existing model\n",
            "4. Exit\n",
            "Choice: 2\n",
            "Enter model path (default: enhanced_deep_ocr_model.pth): /content/deep_ocr_custom_split_model.pth\n",
            "🔍 Loading trained model...\n",
            "❌ Error loading model: Error(s) in loading state_dict for EnhancedDeepCRNN:\n",
            "\tMissing key(s) in state_dict: \"cnn.3.weight\", \"cnn.3.bias\", \"cnn.4.running_mean\", \"cnn.4.running_var\", \"cnn.17.weight\", \"cnn.17.bias\", \"cnn.17.running_mean\", \"cnn.17.running_var\", \"cnn.24.weight\", \"cnn.24.bias\", \"cnn.25.weight\", \"cnn.25.bias\", \"cnn.25.running_mean\", \"cnn.25.running_var\", \"cnn.27.weight\", \"cnn.27.bias\", \"cnn.28.weight\", \"cnn.28.bias\", \"cnn.28.running_mean\", \"cnn.28.running_var\", \"cnn.32.weight\", \"cnn.32.bias\", \"cnn.33.weight\", \"cnn.33.bias\", \"cnn.33.running_mean\", \"cnn.33.running_var\", \"rnn.weight_ih_l2\", \"rnn.weight_hh_l2\", \"rnn.bias_ih_l2\", \"rnn.bias_hh_l2\", \"rnn.weight_ih_l2_reverse\", \"rnn.weight_hh_l2_reverse\", \"rnn.bias_ih_l2_reverse\", \"rnn.bias_hh_l2_reverse\", \"attention.in_proj_weight\", \"attention.in_proj_bias\", \"attention.out_proj.weight\", \"attention.out_proj.bias\", \"pos_encoding.pe\", \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"cnn.5.weight\", \"cnn.5.bias\", \"cnn.5.running_mean\", \"cnn.5.running_var\", \"cnn.5.num_batches_tracked\", \"cnn.15.weight\", \"cnn.15.bias\", \"cnn.16.running_mean\", \"cnn.16.running_var\", \"cnn.16.num_batches_tracked\", \"classifier.weight\", \"classifier.bias\". \n",
            "\tsize mismatch for cnn.4.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "\tsize mismatch for cnn.4.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "\tsize mismatch for cnn.8.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n",
            "\tsize mismatch for cnn.8.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cnn.9.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cnn.9.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cnn.9.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cnn.9.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cnn.11.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "\tsize mismatch for cnn.11.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cnn.12.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cnn.12.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cnn.12.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cnn.12.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cnn.16.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n",
            "\tsize mismatch for cnn.16.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for cnn.19.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "\tsize mismatch for cnn.19.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for cnn.20.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for cnn.20.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for cnn.20.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for cnn.20.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
            "\tsize mismatch for rnn.weight_hh_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n",
            "\tsize mismatch for rnn.bias_ih_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for rnn.bias_hh_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for rnn.weight_ih_l0_reverse: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
            "\tsize mismatch for rnn.weight_hh_l0_reverse: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n",
            "\tsize mismatch for rnn.bias_ih_l0_reverse: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for rnn.bias_hh_l0_reverse: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for rnn.weight_ih_l1: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
            "\tsize mismatch for rnn.weight_hh_l1: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n",
            "\tsize mismatch for rnn.bias_ih_l1: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for rnn.bias_hh_l1: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for rnn.weight_ih_l1_reverse: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
            "\tsize mismatch for rnn.weight_hh_l1_reverse: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n",
            "\tsize mismatch for rnn.bias_ih_l1_reverse: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for rnn.bias_hh_l1_reverse: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\n",
            "Choose option:\n",
            "1. Train enhanced model with improvements\n",
            "2. Load and test existing model\n",
            "3. Detailed evaluation of existing model\n",
            "4. Exit\n",
            "Choice: 4\n",
            "Goodbye! 👋\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test  the model\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# ======================\n",
        "# 1. DEEP CRNN MODEL DEFINITION (MUST BE INCLUDED!)\n",
        "# ======================\n",
        "class DeepCRNN(nn.Module):\n",
        "    def __init__(self, img_height=32, num_classes=96, hidden_size=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d((2, 1), (2, 1)),\n",
        "            nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(), nn.MaxPool2d((2, 1), (2, 1)),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(), nn.MaxPool2d((2, 1), (2, 1)),\n",
        "        )\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=512,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=2,\n",
        "            bidirectional=True,\n",
        "            batch_first=False,\n",
        "            dropout=0.3\n",
        "        )\n",
        "        self.classifier = nn.Linear(hidden_size * 2, num_classes)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv = self.cnn(x)  # [B, 512, 1, W]\n",
        "        b, c, h, w = conv.size()\n",
        "        conv = conv.view(b, c * h, w).permute(2, 0, 1)  # [W, B, 512]\n",
        "        rnn_out, _ = self.rnn(conv)\n",
        "        rnn_out = self.dropout(rnn_out)\n",
        "        output = self.classifier(rnn_out)\n",
        "        return F.log_softmax(output, dim=2)\n",
        "\n",
        "# ======================\n",
        "# 2. CTC DECODE FUNCTION\n",
        "# ======================\n",
        "def ctc_decode(log_probs, idx_to_char, blank_idx=0):\n",
        "    \"\"\"Greedy CTC decoding\"\"\"\n",
        "    pred_indices = log_probs.argmax(dim=2).squeeze(1).cpu().numpy()  # [T]\n",
        "    decoded = []\n",
        "    prev_idx = blank_idx\n",
        "    for idx in pred_indices:\n",
        "        if idx != blank_idx and idx != prev_idx:\n",
        "            if idx in idx_to_char and idx_to_char[idx] != '<BLANK>':\n",
        "                decoded.append(idx_to_char[idx])\n",
        "        prev_idx = idx\n",
        "    return ''.join(decoded)\n",
        "\n",
        "# ======================\n",
        "# 3. INFERENCE SETUP\n",
        "# ======================\n",
        "model_path = \"/content/deep_ocr_custom_split_model.pth\"\n",
        "image_path = \"/content/OCR_Hamed5.jpg\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Image transform\n",
        "transform = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Resize((32, 128), antialias=True),\n",
        "    T.Grayscale(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# ======================\n",
        "# 4. LOAD MODEL\n",
        "# ======================\n",
        "print(\"🚀 Loading trained model...\")\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "num_classes = checkpoint['num_classes']\n",
        "idx_to_char = checkpoint['idx_to_char']\n",
        "\n",
        "# Now we can create the model\n",
        "model = DeepCRNN(img_height=32, num_classes=num_classes, hidden_size=128).to(device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(f\"✅ Model loaded successfully with {num_classes} classes.\")\n",
        "\n",
        "# ======================\n",
        "# 5. LOAD AND PREPROCESS IMAGE\n",
        "# ======================\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Cannot load image at {img_path}\")\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)  # To 3-channel for ToPILImage\n",
        "    return transform(img).unsqueeze(0)  # Add batch dim\n",
        "\n",
        "print(f\"🖼️  Preprocessing image: {image_path}\")\n",
        "image_tensor = preprocess_image(image_path).to(device)\n",
        "\n",
        "# ======================\n",
        "# 6. RUN INFERENCE\n",
        "# ======================\n",
        "print(\"🔍 Running inference...\")\n",
        "with torch.no_grad():\n",
        "    log_probs = model(image_tensor)  # [T, 1, num_classes]\n",
        "    predicted_text = ctc_decode(log_probs, idx_to_char)\n",
        "\n",
        "# ======================\n",
        "# 7. OUTPUT RESULT\n",
        "# ======================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🎯 INFERENCE RESULT\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Image: {image_path}\")\n",
        "print(f\"Predicted Text: '{predicted_text}'\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwCyRFZLiIOf",
        "outputId": "41a640ba-1b8d-4336-f398-6c3dcf15ddfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Loading trained model...\n",
            "✅ Model loaded successfully with 95 classes.\n",
            "🖼️  Preprocessing image: /content/OCR_Hamed5.jpg\n",
            "🔍 Running inference...\n",
            "\n",
            "==================================================\n",
            "🎯 INFERENCE RESULT\n",
            "==================================================\n",
            "Image: /content/OCR_Hamed5.jpg\n",
            "Predicted Text: 'HRERRO'\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}